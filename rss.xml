<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Satellytes]]></title><description><![CDATA[Passionate experts that strive to build the best possible and above all right solution for our clients and customers.]]></description><link>https://satellytes.com</link><image><url>https://satellytes.com/sy-share-image.jpg</url><title>Satellytes</title><link>https://satellytes.com</link></image><generator>GatsbyJS</generator><lastBuildDate>Mon, 20 Mar 2023 16:20:09 GMT</lastBuildDate><item><title><![CDATA[A Semantic Approach to Buttons (& More)]]></title><description><![CDATA[A guide about primary, secondary and tertiary buttons & interactive elements, their forgotten purpose and their impact on the quality of your UX and UI.]]></description><link>https://satellytes.com/blog/post/a-semantic-approach-to-buttons-and-more/</link><guid isPermaLink="false">https://satellytes.com/blog/post/a-semantic-approach-to-buttons-and-more/</guid><pubDate>Thu, 09 Mar 2023 00:00:00 GMT</pubDate><content:encoded>&lt;img src=&quot;https://satellytes.com/_gatsby/image/0f59ed74995c2737d0b2bd689645a254/049e3d39284577572c92b7db90eb3e09/1.png?eu=ed69f73e47a4451171d8c670d733fdff6e561518d40d8cab602bbd16ca54dc37e0a514d5a2cf8037fb34b8fad6c9b36cdafc43ce77e1512c9a3b503bbfdf8025bc25e00b4bc4edd5c93bf7213b0b172574cb0cc2f2e949695d79465e4fec77894802719c4cbb5845ebf5c4319b4de74a575e6322f41efa768f65d4a32e7b4866a39c24867b904076a1269d3878d85814230b1ff322be130be7010184205e3e5ff28a32b01e2b852759d34883bae3b5fd8b46ec8cd3a83b274eada7c91cd3e9905a0ab04076dd8cf18b09193a47192e43e822abbf4892c852&amp;amp;a=w%3D1440%26h%3D760%26fm%3Dpng%26q%3D75&amp;amp;cd=2023-03-10T14%3A10%3A02.289Z&quot; alt=&quot;&quot;/&gt; &lt;p&gt;A guide about primary, secondary and tertiary buttons &amp;amp; interactive elements, their forgotten purpose and their impact on the quality of your UX and UI.&lt;/p&gt;&lt;p&gt;When you read 10 articles about buttons, you get 10 slightly different answers. Is a CTA a button? Is a primary button a CTA? Are secondary and tertiary buttons also CTAs — or do they call too silently for a user’s interaction to be labelled “call to action”?&lt;/p&gt;&lt;p&gt;I recently had a &lt;a href=&quot;https://medium.com/design-bootcamp/tokens-studio-for-figma-quickstart-8d3ca9ae6585&quot;&gt;live-talk about “Tokens Studio for Figma”&lt;/a&gt; and I got a lot of positive feedback for some of the things I said in the talk and in discussions afterwards, so I decided to write an article about buttons and how I was able to really holistically reapproach them, thanks to the requirements of token taxonomy and syntax.&lt;/p&gt;&lt;p&gt;When creating a component library with a &lt;a href=&quot;https://bootcamp.uxdesign.cc/design-tokens-future-of-design-systems-ccdb15ee2db&quot;&gt;design token system&lt;/a&gt; — especially a multi-branded and multi-themed one — you can’t simply define a few colors and rules, draw primary, secondary and tertiary buttons and their states and you are done. You have to think a lot more about hierarchies, behaviour, flexibility, expandability, distinguishability and a lot mor -ilities.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;//images.ctfassets.net/54dnxp2417nl/2g2GxY8XXA99gHAxPaWdQv/03a6a7c16ebd29adc2b1e4074c425d33/1_p_OuEXO5VgXPXEsOniXlRw.webp&quot; alt=&quot;&quot;/&gt;&lt;figcaption&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Especially the semantic tier of tokens reveals some hidden constraints and opportunities that we otherwise (maybeee) would have followed intuitively, but it’s nice to intentionally expose and celebrate them.&lt;/p&gt;&lt;h2&gt;Semantic Tokens&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;https://uxdesign.cc/naming-design-tokens-9454818ed7cb#&quot;&gt;Semantic naming&lt;/a&gt; — and in the context of tokenization “semantic tokens” — give a core layer of tokens — the “option tokens” — &lt;b&gt;a meaning by implementing a design decision.&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Those option tokens are basically a massive (but well thought-through) collection of colors, sizes, spaces, typography variants, etc. that one might need in a design system to cover the needs of all interactive touchpoints (devices, screen sizes, brands, themes).&lt;/p&gt;&lt;p&gt;On top of those option tokens, you define sets of semantic tokens (one per theme, e.g. brandA-web-light theme, brandB-app-dark theme, smartTV theme), that give those option tokens a purpose in their respective themes.&lt;/p&gt;&lt;p&gt;Here are some exemplary design decisions:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;core.color.romanticblue.40 → brandA.web.light.color.selectable.primary.bg&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;core.color.bloodburst.80 → brandB.app.dark.color.selectable.error.canvas&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;core.dimension.150 → app.space.container.inset.m&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;core.font-size.300 → app.typography.title.xxxl&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;core.dimension.100 → global.size.icon.s&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;More to be found in my &lt;a href=&quot;https://www.figma.com/community/file/1216013561345845651&quot;&gt;Figma template&lt;/a&gt;. You’ll need the &lt;a href=&quot;https://www.figma.com/community/plugin/843461159747178978/Tokens-Studio-for-Figma-(Figma-Tokens)&quot;&gt;Tokens Studio plugin&lt;/a&gt; to see the tokens.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;The goal and also biggest benefit of semantic tokens are:
&lt;b&gt;They implement generic design decisions that can be mapped to several components&lt;/b&gt; on “component token” level — meaning one semantic token can be used in more than one or even a lot of components.&lt;/p&gt;&lt;p&gt;Why is that so cool? Because &lt;b&gt;you will get more consistency, clarity, simplicity, distinguishability and thus a lower &lt;/b&gt;&lt;a href=&quot;https://www.nngroup.com/articles/minimize-cognitive-load/&quot;&gt;&lt;b&gt;cognitive load&lt;/b&gt;&lt;/a&gt;&lt;b&gt;, more patient, more successful and happier users and in the end — a better conversion.&lt;/b&gt; Besides changes to one design decisions will bulk-change all of its attached components.&lt;/p&gt;&lt;p&gt;Before we dive into the diverse colorful world of buttons, let’s get an overview where to find them.&lt;/p&gt;&lt;h2&gt;Buttons — where are you?&lt;/h2&gt;&lt;p&gt;In general, there are three types of pages (in the world (wide web), haha, bold!):&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Overview pages &lt;/b&gt;which contain collections of topics or teasers for the users to choose from. Usually they are take-off points into flows/funnels. Examples: “Homepages” and sub-homes in general, category and list pages of online shops, dashboards. They can also be called navigation pages. They don’t have that one CTA, they rather have a lot of quieter call to actions or offerings for the user.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Funnel pages &lt;/b&gt;inside flows. Those try to focus the users attention on one task to finish in one or more steps. Sounds like they have that one primary CTA and maybe some quieter secondary elements to complete the task.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Information pages &lt;/b&gt;which are neither overview pages nor pages inside a funnel — however they can be the final page at the end of a funnel. Examples: A user searches or filters a list of articles/contents and lands on the article/content page. Sounds like they don’t have many CTAs at all. The “action” those pages expect from the users are consuming information. And afterwards they may be offering more similar pages or flows (“you might also be interested in”, “related”).&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Since overview pages and information pages don‘t sound like the most complex scenarios for buttons, let’s focus on “funnel pages” and the other types will be self-explaining then. Funnel pages are typically pages with some kind of lead/conversion at the end, e.g. subscribing to a service, buying a product, closing a contract or sending a simple message.&lt;/p&gt;&lt;p&gt;Ok, we found them, let’s look into what buttons and their other tribe members are.&lt;/p&gt;&lt;h2&gt;Buttons — what are you?&lt;/h2&gt;&lt;p&gt;Buttons are interactive elements. There are large and complex interactive elements like (in &lt;a href=&quot;https://atomicdesign.bradfrost.com/chapter-2/&quot;&gt;atomic design&lt;/a&gt;) organisms and molecules — and small ones like atoms, part of which are buttons.&lt;/p&gt;&lt;p&gt;Other atoms are e.g. any type of &lt;b&gt;components for forms like checkboxes, dropdowns, input fields, segmented buttons, radio buttons, several others and also any type of buttons like floating action buttons, chips, tabs, etc.&lt;/b&gt;&lt;/p&gt;&lt;p&gt;What do you use those small interactive elements for? To solve tasks. You &lt;b&gt;make selections&lt;/b&gt; with radio buttons, segmented buttons and checkboxes, you &lt;b&gt;change contexts&lt;/b&gt; with segmented buttons (aka tab groups) or dropdowns, you &lt;b&gt;specify information&lt;/b&gt; with input fields … and you &lt;b&gt;send/save something to a server&lt;/b&gt; with a button. Sounds like all of them do the job together, right?&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;//images.ctfassets.net/54dnxp2417nl/3fxRCuOGZrqMr4wBn6hES9/bf28671164720f8a90a06d4c682391ca/CleanShot_2023-03-10_at_14.10.27_2x.png&quot; alt=&quot;&quot;/&gt;&lt;figcaption&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;So why lift buttons above everything else? Why not &lt;b&gt;group all of those little helpers in primary, secondary and tertiary&lt;/b&gt;, depending on how essential they are for the user to complete a task and &lt;b&gt;style them all consistently&lt;/b&gt;?&lt;/p&gt;&lt;p&gt;Larger elements (molecules and organisms) consist of atoms, so if we solve the scenario with atoms, we automatically solve it for all larger elements as well.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Thesis: One style for all primary atoms, one for all secondary, one for all tertiary.&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Nooo, why would you do something like this?&lt;/p&gt;&lt;h2&gt;More Consistency, Clarity, Simplicity, Distinguishability&lt;/h2&gt;&lt;p&gt;&lt;b&gt;If you minimize the amount of different font sizes, spacings, colors and other characteristics/tokens&lt;/b&gt; needed to create correct visual hierarchies and intuitive components, you maximize consistency, clarity, simplicity and distinguishability. This will result in the &lt;b&gt;lowest possible &lt;/b&gt;&lt;a href=&quot;https://www.google.com/search?client=safari&amp;rls=en&amp;q=cognitive+load+ux&amp;ie=UTF-8&amp;oe=UTF-8&quot;&gt;&lt;b&gt;cognitive load&lt;/b&gt;&lt;/a&gt;&lt;b&gt;, in more patient, more successful and happier users and in the end — a better conversion. (Yes, I copied that from above. Let it sink, let it stick.)&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Ok, let’s minimize the amount of tokens now to maximize all of the above with the use of semantic token naming.&lt;/p&gt;&lt;h2&gt;Atomic Semantic Tokens&lt;/h2&gt;&lt;p&gt;Atomic, because we are talking about small interactive elements: atoms. Semantic tokens, because we want to tokenize design decisions and apply them to all related elements equally so they convey the same signals, priorities, feelings of belonging.&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.figma.com/community/file/1216013561345845651&quot;&gt;Here is a link to a Figma template&lt;/a&gt; with all of the tokens I describe below. Play around with it, it’s a lot easier to understand like this.
You’ll need the &lt;a href=&quot;https://www.figma.com/community/plugin/843461159747178978/Tokens-Studio-for-Figma-(Figma-Tokens)&quot;&gt;Tokens Studio plugin&lt;/a&gt; to see the tokens.&lt;/p&gt;&lt;h3&gt;Primary Elements&lt;/h3&gt;&lt;p&gt;The most important category of interactive elements are “primary”.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;//images.ctfassets.net/54dnxp2417nl/R44prezZDd6CQZQV21Fl2/32816929aac26e7791ee5b41d92fc384/Frame_4.png&quot; alt=&quot;&quot;/&gt;&lt;figcaption&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Since a user should only have &lt;b&gt;one task per step/page (or in general: context)&lt;/b&gt; in a conversion funnel, the primary action should be used to &lt;b&gt;submit/send/save the completed step&lt;/b&gt;. This results in one primary action which is in most cases the primary call to action aka the primary button. The primary button has several states (hover, pressed, focused, inactive), but &lt;b&gt;no selected state&lt;/b&gt;. When the button is invoked, the task is sent to validation and either returns an error or success with a new context (step/page). To signal the user where to complete the step, we should reserve a special color for the primary action, the primary color.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Conclusion: Each page in a conversion funnel should ideally have exactly one topic with one task and therefore exactly one indispensible primary element — the call to action in the primary color.&lt;/b&gt;&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;//images.ctfassets.net/54dnxp2417nl/6VVp84ld3Z8w5NHPvUtYpL/af00267a718c0414b660768a27543843/CleanShot_2023-03-10_at_14.16.13_2x.png&quot; alt=&quot;&quot;/&gt;&lt;figcaption&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;In Tokens Studio: Create one primary color and a contrast color as semantic tokens and assign them to all components as component tokens that will be used as primary elements (hint: most likely only buttons).&lt;/b&gt;&lt;/p&gt;&lt;p&gt;I know, no real news until here …&lt;/p&gt;&lt;h3&gt;Secondary Elements&lt;/h3&gt;&lt;p&gt;This is where it might get a little fresher. What are secondary elements? They are less important than that one primary element, but mostly necessary for a user to complete a certain task. The user should spot them, understand them as elements providing vital functions — and put them all in the same drawer that is labelled: “I need to consider those for completing my task.”&lt;/p&gt;&lt;p&gt;This way &lt;b&gt;the user can scan a page with very little cognitive load&lt;/b&gt; and understand: &lt;b&gt;This is my task&lt;/b&gt;, &lt;b&gt;this is the primary call to action&lt;/b&gt; to submit my task and all of &lt;b&gt;those secondary elements are vital to complete the task&lt;/b&gt;.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;//images.ctfassets.net/54dnxp2417nl/2Iq9TAk7LjK2PbwlvmMfr4/143fa08b1a2ac0f96741d02234b31a64/CleanShot_2023-03-10_at_14.10.39_2x.png&quot; alt=&quot;&quot;/&gt;&lt;figcaption&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Examples: text buttons, icon buttons, chips, menu items, radio buttons, segmented buttons (tabs), sliders, switches and checkboxes, date/time pickers, dropdowns (basically text fields with an icon on the right opening a menu) and even text fields, yes, text fields (depending on how you style them in comparison to secondary buttons).&lt;/p&gt;&lt;p&gt;All of them have several states (hover, pressed, focused, inactive) and (in contrary to the primary element) &lt;b&gt;also a selected version with the same states&lt;/b&gt;.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;//images.ctfassets.net/54dnxp2417nl/2Fv2T28bB8ZVlgowOZPvRi/e673c943e71b67cb64664f9b73bd4c9b/CleanShot_2023-03-10_at_14.16.29_2x.png&quot; alt=&quot;&quot;/&gt;&lt;figcaption&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Scenarios: a step in a process where a user has to fill out a form, configure a product, customize a setting or submit comment.&lt;/p&gt;&lt;p&gt;&lt;b&gt;So if all those secondary elements have the same importance — why not style them the same way?&lt;/b&gt; You probably did it intuitively, but creating your components consciously with that in mind will reduce the number of design decisions and tokens and make your design &lt;b&gt;easier to understand for users and even other designers working with your design system.&lt;/b&gt;&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;//images.ctfassets.net/54dnxp2417nl/14etZ8qEA8OpsAiO5Zv3dc/f28a7a6bc9b9e5a8eb212b18a2bbdabf/CleanShot_2023-03-10_at_14.16.49_2x.png&quot; alt=&quot;&quot;/&gt;&lt;figcaption&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;In Tokens Studio: Create two secondary background colors as semantic tokens, one unselected and one selected state, create a border and a contrasting foreground color for each state that “could” be used on top of the background colors and use these semantic colors in all components that will be used as secondary elements. On component level, you can assign those semantic tokens to whichever part of a component (background, border, foreground, text, icons) you want. If a color you need seems not to be defined as secondary semantic, it might be higher up in the semantic hierarchy (fg-default, fg-weak, bg, canvas). When you are unsure what semantic colors to assign, think about dark mode or a colored mode (Spotify-style) with colored text and components, e.g. pink background, brown text, that might help.&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://flow.tokens.studio/?id=687bf48c-27ca-4c81-9635-65327e735159&quot;&gt;Open Token Flow&lt;/a&gt; and type “secondary” into the search field to get the diagram below. There you can see how semantic tokens can be assigned flexibly to component parts.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;//images.ctfassets.net/54dnxp2417nl/5XxEHnYqzFPGHcWnpbHewh/3d9297d73aed310cdfbf8caedd27be17/CleanShot_2023-03-10_at_14.12.17_2x.png&quot; alt=&quot;&quot;/&gt;&lt;figcaption&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;(All of the above applies to “funnel pages”. On non-funnel pages (overview pages, information pages), since there is not that one primary element, you could say that the most important category of interactive elements are secondary.)&lt;/p&gt;&lt;h3&gt;Tertiary Elements&lt;/h3&gt;&lt;p&gt;The last category are “tertiary” elements. Tertiary interactive elements are most of the time contextual and optional functions on any type of page. Visually they are mostly ghost buttons (no border/background), so text and/or icon buttons.&lt;/p&gt;&lt;p&gt;Examples: share, like, star, heart, bookmark, download/save, sort/filter, duplicate, more, vertical ellipsis or chevron (with a context menu).&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;//images.ctfassets.net/54dnxp2417nl/7luqMoEPrl4Y9hFDrGWhCh/9367892cd84754cc3e03988c2f70a5d7/Frame_5.png&quot; alt=&quot;&quot;/&gt;&lt;figcaption&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;These elements don’t have to be seen and interpreted by users when quickly scanning a page and its purpose. They are there when a user wants to interact with an element, mostly with molecules and organisms. They even shouldn’t be too prominent, since they will increase the visual noise and compete with everything else (more important) on a page.&lt;/p&gt;&lt;p&gt;&lt;b&gt;In Tokens Studio: The setup is identical to the secondary buttons. Depending on the function of the element it might have a selected state (e.g. star/unstar) or not (e.g. share).&lt;/b&gt;&lt;/p&gt;&lt;h1&gt;Disclaimer&lt;/h1&gt;&lt;p&gt;The Tokens Studio template file is the easiest version you can do. If you have a very complex or colorful UI, the minimalist approach might be just not enough. Then try to define one or two more semantically named colors for primary, secondary, tertiary and assign them to whatever part of components you need. That should be enough. I also skipped creating interactive states. If you are interested in where to put them, check out this file and my talk.&lt;/p&gt;&lt;h1&gt;Conclusion&lt;/h1&gt;&lt;p&gt;Maybe all of this wasn’t all that new to you. Maybe you already did everything intuitively like that. Good for you. My goal with this article was to improve your awareness to be really conscious about your design decisions. Making intentional design decisions, especially when you are able to consolidate and take things away, really improves the performance of your application.&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;b&gt;“Perfection is achieved, not when there is nothing more to add, but when there is nothing left to take away.”&lt;/b&gt; — Antoine de Saint-Exupéry, Airman’s Odyssey&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;In the beginning I said: When you read 10 articles about buttons, you get 10 different answers. This was the 11th one. 😄 I hope you liked it. Let me hear in the comments.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Talk to ChatGPT using Siri on your iPhone]]></title><description><![CDATA[Use your iPhone and Siri to talk with ChatGPT from OpenAI. This is a tutorial how to set it up including several iOS shortcuts that perfectly integrate ChatGPT into your iPhone.]]></description><link>https://satellytes.com/blog/post/talk-to-chatgpt-using-siri-on-your-iphone/</link><guid isPermaLink="false">https://satellytes.com/blog/post/talk-to-chatgpt-using-siri-on-your-iphone/</guid><pubDate>Tue, 24 Jan 2023 00:00:00 GMT</pubDate><content:encoded>&lt;img src=&quot;https://satellytes.com/_gatsby/image/dd92bdd86291b58f3a3e9f6bdf8ad895/049e3d39284577572c92b7db90eb3e09/Group%203.png?eu=b969a43214f01014738ac0748034f6aa335114168252d9a73274bf119857d537b5f71783f8948534a465ecf4d69ee63d8df6469a7ce9537c9e33546ae2de8720e972b3094ec2e9dac33ff72365501021709e5995f5ef1d3d5f2f455c11e0379f5b4378d007b30647e8a2d57ac90fb0191e457222f743ae3cd4238cf62d704338f2dc73d0668f0a3383789c2d59993873745050c444c11452ed0c4ae238006a29bad848da721bdb675ca41bb08cb9f9be9f0aba8684a26a701ffdac981883f5ef1e07f1084dda95b88657&amp;amp;a=w%3D1440%26h%3D760%26fm%3Dpng%26q%3D75&amp;amp;cd=2023-01-24T10%3A52%3A37.495Z&quot; alt=&quot;&quot;/&gt; &lt;p&gt;It takes 10 minutes to setup ChatGPT on your iPhone. You will need an OpenAI account, a credit card with a few euros a month and an iOS shortcut.&lt;/p&gt;&lt;h1&gt;Setup OpenAI account&lt;/h1&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;Create an OpenAI account at &lt;a href=&quot;https://openai.com/api/login/&quot;&gt;https://openai.com/api/login/&lt;/a&gt;. You will need a smartphone to confirm your account.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Add a payment method at &lt;a href=&quot;https://beta.openai.com/account/billing/payment-methods&quot;&gt;https://beta.openai.com/account/billing/payment-methods&lt;/a&gt;. &lt;b&gt;You need to have a paid account. Remaining free credits won’t work.&lt;/b&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Configure soft/hard limits at &lt;a href=&quot;https://beta.openai.com/account/billing/limits&quot;&gt;https://beta.openai.com/account/billing/limits&lt;/a&gt;. A good limit for starters is 5$ soft limit and a 10$ hard limit. I used it every day for a month now and used up only 5$. Currently the &lt;a href=&quot;https://openai.com/api/pricing/&quot;&gt;costs&lt;/a&gt; are around 0.02$ per 1000 tokens. 1 token is about 1 word.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Create an API key at &lt;a href=&quot;https://beta.openai.com/account/api-keys&quot;&gt;https://beta.openai.com/account/api-keys&lt;/a&gt;. You can create as many keys as you want. I suggest to create one for each friend or family member, so you can remove one’s access by deleting the API key whenever necessary. Make sure to write down who uses which key.&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;(The above links might change one day. If so, go into your profile and navigate to the respective pages.)&lt;/p&gt;&lt;h1&gt;Install iOS Shortcut&lt;/h1&gt;&lt;p&gt;&lt;b&gt;Make sure you have iOS 16.3 (or newer) installed. It’s out since Jan 24th 2023.&lt;/b&gt;&lt;/p&gt;&lt;p&gt;I’m german and I’m sharing the shortcut with family and friends, that’s why the shortcut is in german. Instructions to change it to your preferred language are below.&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;Copy your API key you just created above into your clipboard (so you can paste it in the next step). It starts with “sk-…”.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Install and configure the shortcut from &lt;a href=&quot;https://www.icloud.com/shortcuts/018d3a738039472b80080ceef709d41b&quot;&gt;https://www.icloud.com/shortcuts/018d3a738039472b80080ceef709d41b&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;You will be asked to paste your API key (sk-…). Delete the complete text in the text field until empty. then paste the key in there.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;You will also be asked to enter a short phrase that Siri will say to signal/prompt you when it’s ready to listen to the next question. In german “Ich höre” makes sense, in english it could be “Go ahead” or “I’m listening” or “Shoot” – get creative!&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;If you are non-german-speaking, you should also rename the shortcut itself from “Eine Frage” to something like “One question” or “Ask smartass” – whatever you like. This will be your Siri trigger, see next section. To do so, long-press the shortcut and select “Rename”.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Start (Play) the shortcut and allow all requests from the app (connect to openai.com, speech recognition, clipboard). If you don’t accept, it won’t work. If you accidentally declined, you can long-press the shortcut, select “Details” and update the security/privacy allowances.&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Everything is installed and configured now … and your shortcut already ran for the first time.&lt;/p&gt;&lt;h1&gt;Use it&lt;/h1&gt;&lt;p&gt;There are 3 ways to use the shortcut:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Talk to Siri:&lt;/b&gt; Say “Hey Siri, eine Frage” (or the name of your shortcut) to trigger it. Alternatively press the power button on your phone until Siri starts and only say “Eine Frage”. It replies with “Ich höre” (or your renamed phrase). Now ask a really smart question. Siri/ChatGPT will answer and end with “Ich höre” so you can ask follow-up questions. Depending on your sound and Siri settings, the answer will be spoken out loud or only displayed on the screen.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Create a home screen shortcut:&lt;/b&gt; Go into the iOS shortcuts app, long-press our shortcut, select “Share” and select “Add to home screen”. It will look like a regular app on your home screen and start in text-input mode.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;If your phone is unlocked (or on the home screen), you can also swipe down to open search and &lt;b&gt;search for our shortcut&lt;/b&gt;. Also text-input mode.&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;One more cool feature I implemented: Your whole conversation is automatically copied into your clipboard, so you can paste it into any application (iMessage, WhatsApp, Mail, Notes, …) afterwards.&lt;/p&gt;&lt;h1&gt;Side Notes&lt;/h1&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;This shortcut also works on iPad, on your Mac, on your Apple Watch and even in your car if you use Apple CarPlay.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Currently ChatGPT is trained until 2021, so it’s still in the middle of the pandemic and doesn’t cover any present topics.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;If you speak to Siri, it only works in the language you set Siri up for (since Siri is only there to transcribe/convert your voice into text). You can change it in your phone’s settings. If you “write” with the shortcut/ChatGPT though (ways 2 and 3 from the section above), ChatGPT can handle any language. Pretty amazing.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h1&gt;Encore&lt;/h1&gt;&lt;p&gt;I did a few more shortcuts for available endpoints of the API. Here they are:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Text variieren:
&lt;/b&gt;&lt;a href=&quot;https://www.icloud.com/shortcuts/d599ee218b4244d2999a23de8cba3183&quot;&gt;https://www.icloud.com/shortcuts/d599ee218b4244d2999a23de8cba3183&lt;/a&gt;
This talks to the “edits” endpoint with “text-davinci-edit-001”. It can be used for translations, grammar/spelling mistakes, changing the tone of a text. Copy a text into your clipboard, then enter how you would like to modify the text. (You can change the german instructions if you edit the shortcut. Long-press “Edit”, remember?)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Bild erstellen: 
&lt;/b&gt;&lt;a href=&quot;https://www.icloud.com/shortcuts/a2ca21807d064eb6bebdde42064b91cd&quot;&gt;https://www.icloud.com/shortcuts/a2ca21807d064eb6bebdde42064b91cd&lt;/a&gt;
Not as crazily impressive as &lt;a href=&quot;https://midjourney.com/&quot;&gt;Midjourney&lt;/a&gt;, but it will still create a cool image from text input. Clarification: It won&amp;#39;t search for a picture that matches on the internet, it really generates a new one. (talks to “images/generations”)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Bild variieren:
&lt;/b&gt;&lt;a href=&quot;https://www.icloud.com/shortcuts/91abcb20f2124fb6a16490b087ac48ba&quot;&gt;https://www.icloud.com/shortcuts/91abcb20f2124fb6a16490b087ac48ba&lt;/a&gt;
Funny proof of concept rather than really usable. Try it with photos of you and your friends. It will simply change faces and other elements of the picture you provide.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Feedback to this article and my shortcuts are welcome. You can find me on &lt;a href=&quot;https://www.linkedin.com/in/eric-singhartinger/&quot;&gt;LinkedIn&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Be aware that Chat GPT is still in beta and even if it gets out of beta some day: It’s AI, based on a model trained from content on the internet. Whatever it tells you, don’t take it as a fact. You don’t know the source of the information, do your research before you rely on those infos.&lt;/b&gt;&lt;/p&gt;&lt;h1&gt;One more thing&lt;/h1&gt;&lt;p&gt;My shortcut is free. Share it with anyone you like. Apps on the AppStores doing less currently cost around 8$ a week! A week! No need to use those.&lt;/p&gt;&lt;p&gt;Rather consider donating some euros/dollars to a charity of your liking. It really helps. It really, really helps. It really does.&lt;/p&gt;&lt;p&gt;And if you are on any social media platform, stand up for social justice, share content, give those courageous protesters, risking their lives, a voice. Let them be heard. It matters.&lt;/p&gt;&lt;p&gt;Thank you.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[We Created a Tool to Plan Our Breakfasts]]></title><description><![CDATA[Learn how we built a tool with AWS Amplify and React to easily plan meals together]]></description><link>https://satellytes.com/blog/post/weisswurst-planer/</link><guid isPermaLink="false">https://satellytes.com/blog/post/weisswurst-planer/</guid><pubDate>Fri, 18 Nov 2022 00:00:00 GMT</pubDate><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://satellytes.com/_gatsby/image/feb9172c239989a92c1b2d34ba4e328c/4be445bf02c55418e404abd8f2a1a674/phil-hei-6XvN2bN6P8o-unsplash.jpg?eu=ea60f73b47f7421774df9476d66caaaf3a53454dd45588f9637bbe139c05dc67ebf216d5ab998530f834bca18498be68dcf0419a76e5582b9d380a38ecd78674eb73e10b4ec6e0d5c06ba27560531076269e5897a7b9186b0229435a12b974d21f0173c611bc5f13baffc362c91eec1019426725be42ef30cd6ddea73a30583ca68931946d97562cbc6d877239c3094e3f1555b721bd4c50a65e17fd2f161448b3f936af143b99015fe213a5a8dbbca49a50bf86d4f53e7b4fa9a5cf4883ea98080ebc4a74dbdffdda08126916192f4fa236ece70acfce50330ad25e962c35eefe770587149d9a0bbb464522fefdeedc8b90&amp;amp;a=w%3D1440%26h%3D760%26fm%3Djpg%26q%3D75&amp;amp;cd=2022-09-29T09%3A30%3A48.859Z&quot; alt=&quot;&quot;/&gt;&lt;figcaption&gt;&lt;a href=&quot;https://unsplash.com/photos/6XvN2bN6P8o&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Image by Phil Hei&lt;/a&gt;&lt;/figcaption&gt;&lt;/figure&gt; &lt;p&gt;Breakfast with your friends and colleagues always involves a certain amount of organization. After a date has finally been found that works for everyone, there are still some things that need to be arranged:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Figure out who attends&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Ask everyone what and how much they want to eat and drink&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Communicate pricing to your guests&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Collect money and check if everyone has paid&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Write a shopping list&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Typically, this is then organized in a WhatsApp group or in a Slack channel and quickly becomes confusing. These problems are solved by our app &lt;a href=&quot;https://main.d16cjpwppya7y7.amplifyapp.com/&quot;&gt;Weißwurst Planer&lt;/a&gt;, which supports its users in organizing meals together. The following describes how we have tried to implement the requirements for the project in such a way that it is as easy and data-saving to use as possible.&lt;/p&gt;&lt;figure&gt;&lt;video preload=&quot;auto&quot; autoplay=&quot;&quot; loop=&quot;&quot; muted=&quot;&quot; width=&quot;100%&quot;&gt;&lt;source src=&quot;//videos.ctfassets.net/54dnxp2417nl/4xkSd9U9bwfqPfbYc2cdMT/70c20d91f103f0630c7e0611cd0fe4dc/order_process.webm&quot; type=&quot;video/webm&quot;/&gt;&lt;/video&gt;&lt;figcaption&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;Requirements&lt;/h2&gt;&lt;p&gt;It was important to us that the app is as simple and straightforward to use as possible, which is why we decided to use only the most necessary data from users for breakfast planning. As a template, we used the scheduling app &lt;a href=&quot;https://doodle.com/&quot;&gt;Doodle&lt;/a&gt;, except that instead of scheduling it is about organizing breakfasts. For this purpose, we have considered the following requirements, which are also implemented by the app in this way:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;There is an event host that can add an event. After creating the event, he receives an individual link that he can send to all guests, who can then add their orders.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Besides the organizational data (date, time, event name, description), the host can individualize the product range. For this purpose, he can either use the products suggested by us or add his own products with a price to the event. This allows users to plan other shared meals, such as dinner.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Guests can add their order under the event link. To make it as easy as possible for the guests, they only need their name (and no account). Nevertheless, they can still view, edit or delete their order at a later time, as the necessary data is stored in the guests&amp;#39; localStorage.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Unlike the guests, the event host has an account in the Weißwurst Planer app. This ensures that he can access and manage the data of his created events in any case.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;The host can edit or delete all orders if a user loses access to his order.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;After the order acceptance is closed by the host, he can view the shopping list. In addition, there is a checklist with all participants on which can be tracked who have already paid.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;The app selects one person from all participants to purchase the order.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;figure&gt;&lt;video preload=&quot;auto&quot; autoplay=&quot;&quot; loop=&quot;&quot; muted=&quot;&quot; width=&quot;100%&quot;&gt;&lt;source src=&quot;//videos.ctfassets.net/54dnxp2417nl/3mKkwk50WMEdSxRBLinHbt/a8fa0a5621326980b8809ba649bcbd5b/event.webm&quot; type=&quot;video/webm&quot;/&gt;&lt;/video&gt;&lt;figcaption&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;How We Used Amplify for the Backend of Our App&lt;/h2&gt;&lt;p&gt;The requirements for the backend consist of the connection to the database, user authentication, and the implementation of the business logic. To keep the effort and development time of the project as low as possible, we decided to use backend as a service. We implemented this with &lt;a href=&quot;https://aws.amazon.com/de/amplify/&quot;&gt;AWS Amplify&lt;/a&gt;, which generates most of the code needed to communicate with the backend (e.g. GraphQL queries) automatically. Besides Amplify, there are also alternatives, such as Firebase. Amplify is considered a bit more flexible compared to Firebase and also offers a GraphQL API in addition to a REST API. The following describes how we used the various AWS services to implement our project with some code examples.&lt;/p&gt;&lt;h3&gt;User Authentication with Cognito&lt;/h3&gt;&lt;p&gt;Amplify uses Amazon Cognito for user authentication. In addition to the login via the email address or the Amazon account, logins via Apple and Google are also accepted. For our project, we only use the login methods email and Google Account. For this, we first added auth to our app via the Amplify CLI using the &lt;code&gt;amplify add auth&lt;/code&gt; command. For authentication handling in the frontend, Amplify offers two options: You can use the pre-built UI components or call the authentication APIs manually. In our project, we use both options.&lt;/p&gt;&lt;p&gt;For log-in and sign-up handling, we use pre-built UI components from Amplify. For this, Amplify provides a &lt;code&gt;withAuthenticator&lt;/code&gt; higher-order component (HoC) in React projects, which wraps the corresponding components. This ensures that when the component wrapped with the HoC is mounted, the log-in/sign-up screen is shown if the user is not logged in. In addition, the &lt;code&gt;withAuthenticator&lt;/code&gt; HoC passes the props &lt;code&gt;user&lt;/code&gt; and &lt;code&gt;signOut&lt;/code&gt; to the wrapped component.&lt;/p&gt;&lt;p&gt;To access the user&amp;#39;s data in other components we use the API provided by the &lt;code&gt;Auth&lt;/code&gt; class. This provides over 30 methods, such as &lt;code&gt;changePassword&lt;/code&gt; or &lt;code&gt;signOut&lt;/code&gt;. For easier access to the methods relevant to us, we have created a custom React hook:&lt;/p&gt;
            &lt;figure&gt;
              &lt;pre&gt;&lt;code class=&quot;tsx language-tsx&quot;&gt;import { useEffect, useState } from &apos;react&apos;;
import { Auth } from &apos;aws-amplify&apos;;
import { User } from &apos;../../models&apos;;
import { useNavigate } from &apos;react-router-dom&apos;;

export interface LoginStatus {
  loginStatusLoaded: boolean;
  user: User | null;
  isLoggedIn: boolean;
}

export const useCognitoLoginStatus = () =&amp;gt; {
  const [user, setUser] = useState&amp;lt;User | null&amp;gt;(null);
  const [loginStatusLoaded, setLoginStatusLoaded] = useState(false);
    const navigate = useNavigate();

  useEffect(() =&amp;gt; {
    Auth.currentUserInfo().then((userData) =&amp;gt; {
      userData
        ? setUser({
            mail: userData?.attributes?.email,
            id: userData?.id,
            name: userData?.username,
          })
        : setUser(null);
      setLoginStatusLoaded(true);
    });
  }, []);

  const logOut = () =&amp;gt; {
    Auth.signOut().then(() =&amp;gt; {
      setUser(null);
      setLoginStatusLoaded(false);
      navigate(&apos;/&apos;);
    });
  };

  return { loginStatusLoaded, user, isLoggedIn: Boolean(user), logOut };
};
&lt;/code&gt;&lt;/pre&gt;
              use-cognito-login-status.tsx
            &lt;/figure&gt;
          &lt;p&gt;In addition, the current login state is stored in the React context to avoid waiting time to access the API.&lt;/p&gt;&lt;h3&gt;Data Management with AWS Lambda, AppSync and DynamoDB&lt;/h3&gt;&lt;p&gt;To connect an API and a database to the app, the Amplify CLI provides the &lt;code&gt;amplify add api&lt;/code&gt; command. After configuring the API in the CLI, the GraphQL schema is autogenerated in the app. This schema can then be edited and deployed using the &lt;code&gt;amplify push&lt;/code&gt; command. Alternatively, one can use the graphical editor in the Amplify Studio web interface for this purpose. In addition to the GraphQL schema, various mutations, subscriptions, and queries are also generated.&lt;/p&gt;&lt;p&gt;To access the API in the frontend, the &lt;code&gt;API&lt;/code&gt; class of &lt;code&gt;aws-amplify&lt;/code&gt; and the GraphQL operations (e.g. &lt;code&gt;getEventsOfAdmin&lt;/code&gt; from the autogenerated &lt;code&gt;../../graphql/queries&lt;/code&gt; folder) must be imported. Then the &lt;code&gt;graphql&lt;/code&gt; method of the API class can be called with the corresponding query and input parameters. The following example shows the fetching of all events of an event host with its unique ID (= &lt;code&gt;adminId&lt;/code&gt;):&lt;/p&gt;
            &lt;figure&gt;
              &lt;pre&gt;&lt;code class=&quot;tsx language-tsx&quot;&gt;//...
import { API } from &apos;aws-amplify&apos;;
import { getEventsOfAdmin } from &apos;../../graphql/queries&apos;;

const fetchEvents = async () =&amp;gt; {
    //...
    const eventData = await API.graphql({
      query: getEventsOfAdmin,
      variables: { adminId: user.id },
    });
    //...
}
&lt;/code&gt;&lt;/pre&gt;
              admin-events-context.tsx
            &lt;/figure&gt;
          &lt;p&gt;Of course, the autogenerated GraphQL queries, subscriptions, and mutations cannot cover all use cases. Therefore we added lambda functions to our project. This works with the Amplify CLI command &lt;code&gt;amplify add function&lt;/code&gt;. After that, you can customize the properties of the lambda function, like the name or the access rights to the API. To access the lambda function in the frontend, it must be added to the GraphQL schema under the appropriate type (&lt;code&gt;Query&lt;/code&gt;, &lt;code&gt;Mutation&lt;/code&gt; or &lt;code&gt;Subscription&lt;/code&gt;) using the &lt;code&gt;@function&lt;/code&gt; directive. This looks like this in the example of the &lt;code&gt;getEventsOfAdmin&lt;/code&gt; query used above:&lt;/p&gt;
            &lt;figure&gt;
              &lt;pre&gt;&lt;code class=&quot;graphql language-graphql&quot;&gt;type Query {
  getEventsOfAdmin(adminId: ID!): [Event] @function(name: &quot;getEventsOfAdmin-${env}&quot;)
  # ...
}
&lt;/code&gt;&lt;/pre&gt;
              schema.graphl
            &lt;/figure&gt;
          &lt;p&gt;Inside the lambda, we can then also (if configured when adding the lambda) use the AppSync GraphQL API. Within the lambda, we can then access the GraphQL endpoint with &lt;code&gt;process.env.API_&amp;lt;YOUR_API_NAME&amp;gt;_GRAPHQLAPIENDPOINTOUTPUT&lt;/code&gt; and the API key with &lt;code&gt;process.env.API_&amp;lt;YOUR_API_NAME&amp;gt;_GRAPHQLAPIKEYOUTPUT&lt;/code&gt;. This looks like this in the example of our &lt;code&gt;getEventsOfAdmin&lt;/code&gt; lambda:&lt;/p&gt;
            &lt;figure&gt;
              &lt;pre&gt;&lt;code class=&quot;jsx language-jsx&quot;&gt;import { default as fetch, Request } from &apos;node-fetch&apos;;

const GRAPHQL_ENDPOINT =
  process.env.API_WEISSWURSTPLANER_GRAPHQLAPIENDPOINTOUTPUT;
const GRAPHQL_API_KEY = process.env.API_WEISSWURSTPLANER_GRAPHQLAPIKEYOUTPUT;

const getEventQuery = /* GraphQL */ `
  query LIST_EVENTS(
    $filter: ModelEventFilterInput
    $limit: Int
    $nextToken: String
  ) {
    listEvents(filter: $filter, limit: $limit, nextToken: $nextToken) {
      items {
        id
        name
        description
        # ...
    }
  }
`;

/**
 * @type {import(&apos;@types/aws-lambda&apos;).APIGatewayProxyHandler}
 */
export const handler = async (event, context, callback) =&amp;gt; {
  const adminId = event?.arguments?.adminId;

  /** @type {import(&apos;node-fetch&apos;).RequestInit} */
  const options = {
    method: &apos;POST&apos;,
    headers: {
      &apos;x-api-key&apos;: GRAPHQL_API_KEY,
    },
  };

  const getEventsRequest = new Request(GRAPHQL_ENDPOINT, {
    ...options,
    body: JSON.stringify({ query: getEventQuery }),
  });

  let requestedEvents;
  try {
    if (!adminId) {
      throw new Error(&apos;adminId is undefined&apos;);
    }

    const getEventsResponse = await fetch(getEventsRequest);
    const getEventsBody = await getEventsResponse.json();
    requestedEvents = getEventsBody.data.listEvents?.items;

        //business logic
        //...
  } catch (error) {
    callback(error.message, null);
  }
  callback(null, requestedEvents);
};
&lt;/code&gt;&lt;/pre&gt;
              getEventsOfAdmin.js
            &lt;/figure&gt;
          &lt;p&gt;Amplify also provides the ability to mock and test changes locally. This is possible for the API, the storage, and the lambda functions. This makes it very easy to test and debug changes locally. The lambda described above could then be tested with the command &lt;code&gt;amplify mock function getEventsOfAdmin&lt;/code&gt; for example. The input parameters must be added to a JSON file, which is generated by default when creating a new lambda inside the &lt;code&gt;src&lt;/code&gt; folder.&lt;/p&gt;&lt;h2&gt;How We Made the Frontend&lt;/h2&gt;&lt;p&gt;If you look at the package.json you will notice that besides the dependencies directly related to React or Amplify there are only the following entries:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://styled-components.com/&quot;&gt;styled-components&lt;/a&gt;: Helps to style the project at the component level with a mixture of JavaScript and CSS&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://date-fns.org/&quot;&gt;date-fns&lt;/a&gt;: Provides helpful functions to simplify the handling of dates in JavaScript&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://reactrouter.com/&quot;&gt;react-router-dom&lt;/a&gt;: Provides client-side handling of the routing&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://react-hook-form.com/&quot;&gt;react-hook-form&lt;/a&gt;: Helps to deal with forms in JavaScript. This helped us with the implementation of the CreateEventForm.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/nfl/react-helmet&quot;&gt;react-helmet&lt;/a&gt;: Enables dynamic modification of the document head&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Everything else we implemented ourselves. This also applies to the state and context management for which we used the &lt;a href=&quot;https://reactjs.org/docs/context.html&quot;&gt;React Context API&lt;/a&gt;.&lt;/p&gt;&lt;h2&gt;Conclusion&lt;/h2&gt;&lt;p&gt;To sum up, we could realize all the predefined requirements with Amplify&amp;#39;s help. In doing so, most of the services used by Amplify could be configured either directly in the CLI or in Amplify Studio. Everything else we were able to set up fairly easily on the individual services&amp;#39; pages in the AWS console. In addition, there is now also a relatively large community that can usually answer any questions about Amplify related to smaller projects.
We would be happy if you remember our app the next time you plan a breakfast with your friends and colleagues and we can help you organize it.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Creating & Crafting a Design Token System]]></title><description><![CDATA[Creating and crafting a design token system for any modern multi-brand design system with covered topics like controlled vocabulary, typography, spacings, paddings, color palette, accessibility, A11y]]></description><link>https://satellytes.com/blog/post/creating-and-crafting-a-design-token-system/</link><guid isPermaLink="false">https://satellytes.com/blog/post/creating-and-crafting-a-design-token-system/</guid><pubDate>Tue, 01 Nov 2022 00:00:00 GMT</pubDate><content:encoded>&lt;img src=&quot;https://satellytes.com/_gatsby/image/6bbab9b549c932d29a6227292c88918b/049e3d39284577572c92b7db90eb3e09/2.png?eu=ef65a56915f24544758d952dd967f8ff33524818d7068cfd3229ec11cc0adc33e1a547d2fe998067af66bda6d49ae3688af610c97db7532d9a6f573bbadfd07aeb72ef5c4497ba8e953fa32560574476729e0fc3f2e81a380b79475c49bc71d3195475cf49e80f15b8a4c3659c48e1195d06746eb75af438996d83aa3d6a4b3bfac76d8e65824267a12690296a961e53221114ad7eef5613bc594ad8135f6028ba8c118e694b8c202bc9449198fe8ddd8d2cdaf1faff12371ad1ddd61c85bf900a09bc1d71d18efcdc031b6b411e774feb22b1bb03d0c0566a43d730cf5029fcde26&amp;amp;a=w%3D1440%26h%3D760%26fm%3Dpng%26q%3D75&amp;amp;cd=2022-10-27T14%3A13%3A59.684Z&quot; alt=&quot;&quot;/&gt; &lt;p&gt;In my &lt;a href=&quot;https://satellytes.com/blog/post/installing-and-syncing-figma-design-tokens/&quot;&gt;last article&lt;/a&gt;, I talked about how to do the roundtrip of one single design token from Figma to code and back – and why this is so significant in the design-development-process and the goal of a single source of truth.&lt;/p&gt;&lt;p&gt;Obviously though, one token is never enough. It’s rather a complex hierarchy of dozens of design tokens with a very strict, &lt;a href=&quot;https://boxesandarrows.com/what-is-a-controlled-vocabulary/&quot;&gt;controlled vocabulary&lt;/a&gt; and syntax. To help you develop such a “Design Token System”, this article covers the creating and crafting of a design token system for a(ny) modern multi-brand design system.&lt;/p&gt;&lt;h2&gt;Our Case&lt;/h2&gt;&lt;p&gt;Let’s say we have two brands: Brand X (bx) and Brand Y (by). They have different look-&amp;amp;-feeling online shops with different corporate identities and style guides including own colors, typography, handling of whitespace, aesthetics, round vs. angular, flat vs. 3dimensional, outlined vs. filled, …&lt;/p&gt;&lt;p&gt;On top of two different corporate identities, modern websites nowadays are offered in light and dark themes, depending on the user’s preference and time of the day. So in total we have 4 themes: bx light &amp;amp; dark, by light &amp;amp; dark. And as a consequence, we’ll have to deliver most of the components for their design systems in these 4 themes.&lt;/p&gt;&lt;p&gt;But where do we start? How do we craft exhaustive and maintainable components? Is there a main theme from which all other themes are derived? Is there a neutral base theme that can be transformed into our 4 themes? Let’s have a look …&lt;/p&gt;&lt;p&gt;&lt;code&gt;&lt;b&gt;🤓 Disclaimer: &lt;/b&gt;&lt;/code&gt;&lt;code&gt;This article would be 100 pages long if I would deep-dive into every topic it scratches. So instead of writing 100 pages about everything, I’ll focus on the “Design Token System” part, but give you awareness about many other important aspects, by mentioning them.&lt;/code&gt;&lt;/p&gt;&lt;h2&gt;Crafting Components&lt;/h2&gt;&lt;p&gt;A good strategy is to create base components with maximum complexity. Let’s say a product card that includes all possible badges, banners, price tags and specifications – aka the “worst case” complexity. The reason for this is, that in instances (and variants) of components, you can remove items, but not add them. So if you need a maximum of 3 badges in a component (NEW, SPECIAL PRICE, FEATURED), you have to add all 3 in the base component. Removing some or all will work, but adding won’t.&lt;/p&gt;&lt;h3&gt;Themed vs. Neutral Base Components&lt;/h3&gt;&lt;p&gt;All of those base components can either be done in the main theme or in a neutral style.&lt;/p&gt;&lt;p&gt;A neutral style could be created by using one of the brand’s neutral looking font faces, neutral greyscale colors and average metrics (margins, paddings, elevation, borders, shadows, roundness, …). It might end up looking like wireframing components.&lt;/p&gt;&lt;p&gt;The advantage is that you treat all of the 4 themes equally and wireframing and developing new features and flows with those components will have a better focus on UX, rather than distract with its UI.&lt;/p&gt;&lt;p&gt;The disadvantage of a neutral theme is that you produce overhead, so in total 5 themes.&lt;/p&gt;&lt;h2&gt;Creating Design Tokens&lt;/h2&gt;&lt;p&gt;When creating design tokens for a brand, you should have the brand’s style guide ready to hand where colors, typography and the general aesthetics and use of whitespace are defined. You can interpret the use of whitespace for defining metric tokens (margins, paddings, elevation, borders, shadows, roundness, …). Depending on the quality of the style guide, you might even have semantic colors (background colors, text colors, badge colors, …) ready to use. Throw in a number of shades and a cascading set of typography scales and you are half way there.&lt;/p&gt;&lt;p&gt;Going into every single aspect of transforming a style guide into a comprehensive design tokens would blow up this article, so instead, I’ll hand out to you a hierarchical dictionary of common design tokens for you to use. This way you can play a game of “connect the dots”: You have your style guide on the one side and a hierarchy of possible design tokens on the other.&lt;/p&gt;&lt;p&gt;I recommend creating a spreadsheet (like the one below) and testing out a few dozens of tokens to get a feeling if you are heading into the right direction. But first …&lt;/p&gt;&lt;h3&gt;Types of Design Tokens&lt;/h3&gt;&lt;p&gt;Let’s have a look at possible types of design tokens. What types are needed to define a brand’s look and feel?&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Color:&lt;/b&gt; When defining color palettes, a good start is to choose one of the strategies below:
&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Rainbow Palette:&lt;/b&gt; An evenly spread palette of a full rainbow of colors, similar to the well-known &lt;a href=&quot;https://material.io/design/color/the-color-system.html#tools-for-picking-colors&quot;&gt;2014 Material Design color palette&lt;/a&gt; with roughly 19 tones with 14 shades each. This palette mainly existed to give all brands and designers in the world (slight exaggeration) enough colors to choose from. Too many for your project, so it’s wiser to choose another strategy …&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Focused Palette:&lt;/b&gt; A limited palette of colors with a fixed set of hues and saturations that reflect your brand. For example 5-10 hues in vibrant, pastel or subtle tones and 10 lightness shades each. This is based on the rainbow palette, but with fewer selected colors.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Here is an example for a blue tone with a hue of 210: &lt;/p&gt;&lt;p&gt;&lt;code&gt;$colors.blue._hue: 210;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;To define shades of blue, you have to choose a saturation and a number of lightness values. In code, it would look something like this: &lt;code&gt;hsla($colors.blue._hue, $s, $l, 1)&lt;/code&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;$s&lt;/code&gt;: Fixed or variable saturations: Vibrant → 100%, pastel → ~40%, subtle → ~10%&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;$l&lt;/code&gt;: Full range from 100 to 900 and 90 to 10% in lightness&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;So you might end up with 5-10 different hues with a fixed saturation (&lt;code&gt;$s&lt;/code&gt;) each and for each of those 5-10 colors a number of shades (&lt;code&gt;$l&lt;/code&gt;), so in total 50-100 colors. It’s less colors than the full rainbow palette above, but still: Some of the lightness shades won’t be used so it’s kind of useless and reckless to have them in your palette, because: If a color is defined, it might be used by your designers.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Limited palette:&lt;/b&gt; The best strategy might be to only define a very limited palette of colors that are really needed. The downside of this is: You’ll have to think everything through before you define all colors. You’ll have to go through all cases and combinations regarding aesthetics and accessibility (btw: I love &lt;a href=&quot;https://contrast-grid.eightshapes.com/&quot;&gt;https://contrast-grid.eightshapes.com/&lt;/a&gt; and &lt;a href=&quot;http://www.myndex.com/APCA/&quot;&gt;http://www.myndex.com/APCA/&lt;/a&gt;). Where should you start? Define some meaningful semantic color tokens such as (page-bg, card-bg, primary-selectable-bg, secondary-selectable-bg, heading, body, …) in your light theme, place all on a page to see if they work and evolve from there.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Cool tools to create color palettes: &lt;a href=&quot;https://colorbox.io/&quot;&gt;https://colorbox.io/&lt;/a&gt;, &lt;a href=&quot;https://contrast-grid.eightshapes.com/&quot;&gt;https://contrast-grid.eightshapes.com/&lt;/a&gt;, &lt;a href=&quot;https://meodai.github.io/fettepalette/&quot;&gt;https://meodai.github.io/fettepalette/&lt;/a&gt;, &lt;a href=&quot;https://leonardocolor.io/&quot;&gt;https://leonardocolor.io/&lt;/a&gt;, &lt;a href=&quot;https://color.adobe.com/&quot;&gt;https://color.adobe.com/&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Typography:&lt;/b&gt; There is a lot to say about typography, but above all there is one basic rule: Keep it simple and distinguishable. Same as for tokens: Only introduce a new font style if you really need it. Common typography parameters are: Font family, weight, size, letter/word/line/paragraph spacing, case, decoration. Cool tools to create type scales: &lt;a href=&quot;https://type-scale.com&quot;&gt;https://type-scale.com&lt;/a&gt;, &lt;a href=&quot;https://www.layoutgridcalculator.com/type-scale/&quot;&gt;https://www.layoutgridcalculator.com/type-scale/&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Sizing, Spacing, Border Radius, Border Width:&lt;/b&gt; All of these metrics can either be defined in pixels or rem. rem is a base size used in HTML and equals 16 px. And 16 px is actually a good value, since body text and basic spacing is often 16 px. To use it, define &lt;code&gt;rem = 16&lt;/code&gt; and add it to the “sizing” section in Figma Tokens. Whenever you are defining spacings, margins and paddings now, you can now use “rem” instead of “px” which might make it easier for you and your developers in discussions. Border radius and width are fine in “px”.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Opacity, Elevation, Shadow:&lt;/b&gt; These parameters add hierarchy and focus to your design (same does size, contrast, whitespace), so use them wisely.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Beyond all of the above tokens you could even define some for things like: &lt;b&gt;Breakpoints, Touch, Time/Animation/Duration, … But again: Keep it as simple as possible.&lt;/b&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h4&gt;REM &amp;amp; SCALE &amp;amp; scale&lt;/h4&gt;&lt;p&gt;To be more flexible and able to play around with my tokens, I like to add multipliers to some of my tokens. Here are a few examples:&lt;/p&gt;&lt;p&gt;Add a global &lt;code&gt;REM = 16&lt;/code&gt; token and add it to your font-size tokens as &lt;code&gt;font-size-abc: $REM/16 * xyz&lt;/code&gt;so you can change all font-sizes by simply changing the global REM.&lt;/p&gt;&lt;p&gt;Add a global &lt;code&gt;SCALE = 16&lt;/code&gt; token and add it to all of your size-related tokens like sizing/spacing/dimensions in the same manner as for REM, so you can change all other non-font-size-related sizes.&lt;/p&gt;&lt;p&gt;Add a local &lt;code&gt;scale = 16&lt;/code&gt; to other groups like border-roundness or border-width so you can easily change the look of your design by applying a different scale to relevant groups of tokens.&lt;/p&gt;&lt;p&gt;You might have asked yourself up there why I didn’t define the base text size for body as 1 reminstead of 16 px. I’m a fan of integers and getting a 14 px font size from a multiple of 1 rem is simply nasty. And I got used to specifying font sizes as 12, 14, 16, 20, … plus they will be tokenized anyways and get their semantic names like xs, s, m, ml, … &lt;b&gt;Adding base scale multipliers to cascading tokens is quite nice in general and helps with flexibility.&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;Layers of Design Tokens&lt;/h2&gt;&lt;p&gt;When talking about design tokens, there are basically 3 different categories. A lot of designers have different names for these three layers, but all of them are talking about the same 3 categories:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Option Tokens&lt;/b&gt; (aka &lt;b&gt;Core Tokens&lt;/b&gt;): These are the most fundamental layer of tokens. They don’t have any meaning, function or design decision implemented into their names, e.g. &lt;code&gt;$color-blue-500&lt;/code&gt; or &lt;code&gt;$size-8&lt;/code&gt;. It’s like &lt;code&gt;man&lt;/code&gt;  or &lt;code&gt;lemon&lt;/code&gt;. vs. &lt;code&gt;father&lt;/code&gt; or &lt;code&gt;vitamines&lt;/code&gt;. Think of them like all possible basic ingredients.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Semantic Tokens&lt;/b&gt; (aka &lt;b&gt;Alias/Base/Brand/Decision/Theme Tokens&lt;/b&gt;): Use them to define global meaning/function/appearance aka a design decision, e.g. &lt;code&gt;bx-selectable-primary: $color-blue-500;&lt;/code&gt; or &lt;code&gt;bx-base-typography-heading-xl: $bx-base-typography-heading-m * 2;&lt;/code&gt;. Think of them like a global brand style or a base component (vs. an instance).&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Component Tokens&lt;/b&gt;: These are the most specific ones, the top layer of tokens. Use them to apply your generic design decisions (from semantic tokens) to specific parts of your components, e.g. &lt;code&gt;bx-light-web-selectable-color-bg-primary-hover.&lt;/code&gt; Think of them like an instance of a semantic token. You can use a semantic token (similar to a base component) in many different places, but depending where you use it, it will have a different purpose.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;Here is an example:&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Let’s say we have a palette of colors for our brand. One of them is a standard blue: &lt;code&gt;$color-blue-500&lt;/code&gt; with a hex-value of &lt;code&gt;#0000FF&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;This blue is also the primary color for our light theme design (besides probably black text, a few greyscales and a white background). To define a semantic token for this we say: &lt;code&gt;bx-light-color-primary: $color-blue-500;&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Coincidentally, blue is also a good color to highlighting links and buttons, so we create a component token for it to be used in Brand X’s light theme: &lt;code&gt;bx-light-selectable-color-primary: $bx-light-color-primary;&lt;/code&gt; So now, whenever we need the primary interaction color, we simply use: &lt;code&gt;$bx-light-selectable-color-primary&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;Should the brand’s blue value change one day, we would change it’s option token: &lt;code&gt;$color-blue-500: #3300FF;&lt;/code&gt; and all uses of blue are automatically updated. Should the brand’s color palette stay the same, but a designer decides to use the brand’s purple instead as the primary interaction color, we reassign the component token: &lt;code&gt;bx-light-color-primary: $color-purple-500;&lt;/code&gt;&lt;/p&gt;&lt;p&gt;What if we have different colors for our interactions for different states though? Let’s define a component token: &lt;code&gt;bx-light-selectable-color-primary-default: $bx-color-primary;&lt;/code&gt; This means that in the light theme of our Brand X, whenever there is a primary selectable (like a text link or button) then it’s blue.&lt;/p&gt;&lt;p&gt;And when we hover over it? &lt;code&gt;bx-color-primary-hover: $color-blue-600;&lt;/code&gt; and &lt;code&gt;bx-light-selectable-color-primary-hover: $bx-color-primary-hover;&lt;/code&gt;&lt;/p&gt;&lt;p&gt;This is a very simple example, but it shows two interesting things:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;It’s nice to have meaningful names for tokens to understand design decisions.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;It’s super convenient to change design decisions and all dependencies are automatically updated (if done well).&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;Hierarchy &amp;amp; Syntax of Design Tokens&lt;/h2&gt;&lt;p&gt;Now, let’s have a deeper look into the names of these tokens. Design tokens are structured in a tree (similar to folders or indented bullet-point-lists) by using “-” as separators. Common variables for tokens are:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;A blue color token: &lt;code&gt;color-blue-500&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;A primary brand color token for Brand X: &lt;code&gt;bx-brand-color-primary&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;A large heading for Brand X: &lt;code&gt;bx-base-typography-title-xl&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;A hover color for a primary button for the light theme of Brand X: &lt;code&gt;bx-light-button-color-bg-primary-hover&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;To give you a feeling of what’s possible, study the table below:&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;The first line&lt;/b&gt; are the top-categories (Namespace, Object, Base, Modifier).&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;The second line&lt;/b&gt; are the sub-categories (System, Theme, Domain, …).&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;The third line&lt;/b&gt; are examples for possible elements.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;All lines below&lt;/b&gt; are examples for tokens. Read them from left to right and imagine “-” between the variables, similar to the examples above.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;The red columns&lt;/b&gt; are mandatory (or recommended to be mandatory), black columns are optional.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;figure&gt;&lt;img src=&quot;//images.ctfassets.net/54dnxp2417nl/RQoP4ILTy0fCkiVvnzZKQ/e3a133bd1f208dc368269a06a507f302/CleanShot_2022-12-19_at_16.53.28.png&quot; alt=&quot;&quot;/&gt;&lt;figcaption&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;a href=&quot;https://docs.google.com/spreadsheets/d/1sLrQOS0gEASL8dY1gIQ-pZCflxLleo70E8gYTqirAQo/edit?usp=sharing&quot;&gt;→ Open Google Sheet Template&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Now that you have an idea how tokens can be named and structured, let’s look into the details of each category.&lt;/p&gt;&lt;p&gt;This set is a “Best of” and “Remix” of a lot of articles and videos about Design Tokens. Probably the most comprehensive one was written by Nathan Curtis: &lt;a href=&quot;https://medium.com/eightshapes-llc/naming-tokens-in-design-systems-9e86c7444676&quot;&gt;Naming Tokens in Design Systems&lt;/a&gt;. You should definitely have a look at it. It has a lot more details on this topic.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Namespace&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;System&lt;/b&gt;: &lt;code&gt;bx&lt;/code&gt;, &lt;code&gt;by&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;(Optional) &lt;b&gt;Theme&lt;/b&gt;: &lt;code&gt;light&lt;/code&gt;, &lt;code&gt;dark&lt;/code&gt;, &lt;code&gt;image&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;(Optional) &lt;b&gt;Domain&lt;/b&gt;: &lt;code&gt;web&lt;/code&gt;, &lt;code&gt;app&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Object&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Group/Concept&lt;/b&gt;: &lt;code&gt;brand, base&lt;/code&gt; (alternatively if you don&amp;#39;t have a &lt;code&gt;brand&lt;/code&gt;),  &lt;code&gt;navigation&lt;/code&gt;, &lt;code&gt;content&lt;/code&gt;, &lt;code&gt;selectable&lt;/code&gt;, &lt;code&gt;form&lt;/code&gt;, &lt;code&gt;footer&lt;/code&gt;, …&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;(Optional) &lt;b&gt;Component&lt;/b&gt;: &lt;code&gt;button&lt;/code&gt;, &lt;code&gt;dropdown&lt;/code&gt;, &lt;code&gt;feedback&lt;/code&gt;, &lt;code&gt;success&lt;/code&gt;, &lt;code&gt;deliveryStatus&lt;/code&gt;, …&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;(Optional) &lt;b&gt;Variant&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;primary&lt;/code&gt;, &lt;code&gt;secondary&lt;/code&gt;, &lt;code&gt;tertiary&lt;/code&gt; (aka &lt;code&gt;ghost&lt;/code&gt;)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;success&lt;/code&gt; (aka &lt;code&gt;confirmation&lt;/code&gt;, &lt;code&gt;positive&lt;/code&gt;)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;error&lt;/code&gt; (aka &lt;code&gt;alert&lt;/code&gt;, &lt;code&gt;critical&lt;/code&gt;)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;info&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;warning&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;new&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;(Optional) &lt;b&gt;State&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;default&lt;/code&gt;, &lt;code&gt;hover&lt;/code&gt;, &lt;code&gt;press&lt;/code&gt;, &lt;code&gt;active&lt;/code&gt;, &lt;code&gt;visited&lt;/code&gt;, &lt;code&gt;focus&lt;/code&gt;, &lt;code&gt;disabled&lt;/code&gt;, &lt;code&gt;error&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Type&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Category&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;color&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;typography&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;size &lt;/code&gt;(aka &lt;code&gt;sizing&lt;/code&gt;), &lt;code&gt;spacing&lt;/code&gt;, &lt;code&gt;border radius&lt;/code&gt;, &lt;code&gt;border width&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;opacity&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;elevation&lt;/code&gt; (aka &lt;code&gt;shadow&lt;/code&gt;, &lt;code&gt;depth&lt;/code&gt;)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;breakpoints&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;touch&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;time&lt;/code&gt; (aka &lt;code&gt;animation&lt;/code&gt;, &lt;code&gt;duration&lt;/code&gt;)&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;(Optional) &lt;b&gt;Property&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;For color: &lt;code&gt;notification&lt;/code&gt;, &lt;code&gt;success&lt;/code&gt;, &lt;code&gt;fg&lt;/code&gt;, &lt;code&gt;unavailable&lt;/code&gt;, …&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;For typography: &lt;code&gt;heading-xl&lt;/code&gt;, &lt;code&gt;body-s&lt;/code&gt;, &lt;code&gt;size&lt;/code&gt;, &lt;code&gt;caption&lt;/code&gt;, …&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;For sizes: &lt;code&gt;size&lt;/code&gt;, &lt;code&gt;border&lt;/code&gt;, …&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;(Optional) &lt;b&gt;Modifier&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;(Optional) &lt;b&gt;Scale&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Enumerated&lt;/b&gt; values like heading levels &lt;code&gt;1&lt;/code&gt;, &lt;code&gt;2&lt;/code&gt;, &lt;code&gt;3&lt;/code&gt;, &lt;code&gt;4&lt;/code&gt; and &lt;code&gt;5&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Ordered&lt;/b&gt; values like &lt;a href=&quot;https://material.io/resources/color/&quot;&gt;Google Material color levels&lt;/a&gt; of &lt;code&gt;50&lt;/code&gt;, &lt;code&gt;100&lt;/code&gt;, …, &lt;code&gt;900&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Bounded&lt;/b&gt; scales like HSL’s 0 to 100 lightness value &lt;code&gt;teal-10&lt;/code&gt; (dark), &lt;code&gt;teal-50 &lt;/code&gt;(medium), &lt;code&gt;teal-100&lt;/code&gt; (light)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Proportion&lt;/b&gt;, often establishing a base &lt;code&gt;1-x&lt;/code&gt; and growing (&lt;code&gt;2-x&lt;/code&gt;, &lt;code&gt;4-x&lt;/code&gt;, …) and shrinking (&lt;code&gt;half-x&lt;/code&gt;, &lt;code&gt;quarter-x&lt;/code&gt;, …) relatively&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;T-shirt sizes&lt;/b&gt;, starting with &lt;code&gt;small&lt;/code&gt; (aka &lt;code&gt;s&lt;/code&gt;), &lt;code&gt;medium&lt;/code&gt; (aka &lt;code&gt;m&lt;/code&gt;, &lt;code&gt;standard&lt;/code&gt;, &lt;code&gt;default&lt;/code&gt;) and &lt;code&gt;large&lt;/code&gt; (aka &lt;code&gt;l&lt;/code&gt;) and expanding to &lt;code&gt;xl&lt;/code&gt;, &lt;code&gt;xs&lt;/code&gt;, and &lt;code&gt;xxxl&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;(Optional) &lt;b&gt;Mode&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;on-light&lt;/code&gt;, &lt;code&gt;on-dark&lt;/code&gt;, &lt;code&gt;on-image&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;Guidelines&lt;/h2&gt;&lt;p&gt;Some of the above tokens and their use is quite obvious, some will only make sense once you have developed your first umpteen components. Here are a few basic guidelines for creating tokens:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;Use the above tokens list as a dictionary and only pick the ones you really need multiple times. You won’t need all of them.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Start with a small list of:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Colors&lt;/b&gt; (page-bg, card-bg, primary-selectable-bg, secondary-selectable-bg, headings, body)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Typography&lt;/b&gt; (heading-l, body-l, body-m, body-s)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Spacings&lt;/b&gt; (4 px, 8 px, 16 px, 24 px, 32 px, 48 px, 80 px)&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;All semantic tokens are derived from option tokens.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;All component tokens are derived from semantic tokens.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Don’t use option tokens in your designs, only semantic and component tokens.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Use semantic tokens (for more generic design decisions, like e.g. your primary interaction color) and component tokens (derived from semantic tokens) for how and where to apply to which parts and stated of components.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Add base global “REM”, global “SCALE” and local “scale”s multipliers early in your project. Adding them later is error-prone and cumbersome.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Start with a really holistic option token set covering all brands, themes and interface sizes (devices and breakpoints), adding option tokens later won’t work.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;It’s ok to drag columns left and right in the tokens table to change the order of your syntax. Some orders might be better readable (&lt;code&gt;bx-light-button-color-bg-primary-hover&lt;/code&gt;), some more hierarchically “correct” (&lt;code&gt;bx-light-button-primary-bg-color-hover&lt;/code&gt;) and some will make your notation and variety slimmer than others. Also some orders make more or less sens for option, semantic and component tokens. Play around a bit and use the one that feels best for you.&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;Wrap Up&lt;/h2&gt;&lt;p&gt;That’s it. Now you have some good fundamental knowledge of how to set up your “Design Token System”. Like with every new language, it takes time and practice. Allow yourself to play around (the table is really good for it), test a lot, explore new looks and styles just by changing REW, SCALE and scales.&lt;/p&gt;&lt;p&gt;Depending on your use case, different tokens and hierarchies will work better or worse than others and it’s almost impossible to be right about all decisions until the end.&lt;/p&gt;&lt;p&gt;If you have the possibility, talk to your design and development team openly about all the pros and cons of different variants, you need to get everyone on board so your “Design Token System” will be understood and used.&lt;/p&gt;&lt;p&gt;💫&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Installing & Syncing Design Tokens]]></title><description><![CDATA[Define a design token in code, create a repository on GitHub, install VS Code, NVM, Node.js, NPM packages, use Terminal, push, pull and merge changes in GitHub,  sync design tokens between Figma and a web page]]></description><link>https://satellytes.com/blog/post/installing-and-syncing-figma-design-tokens/</link><guid isPermaLink="false">https://satellytes.com/blog/post/installing-and-syncing-figma-design-tokens/</guid><pubDate>Thu, 27 Oct 2022 00:00:00 GMT</pubDate><content:encoded>&lt;img src=&quot;https://satellytes.com/_gatsby/image/1bd4f24d22b24fd418a4609a4d63751b/049e3d39284577572c92b7db90eb3e09/1.png?eu=ef63f03e1aa1421f2388c771d666aaab3903454d8402d9fb3675b610cd56d234b0a547d0ab9b8130fc65b0f2d69ab26cdff247cb21e554789d3a036ce9828772e820e3591ec4e8d5c83fa5716054162377990491f7e8156d082f435d13b8738d1b5621cf1eec5d44bba29660cc4de348575e6322f41efa768f65d4a32e7b4866a39c24867b904076a1269d3878d85814230b1ff322be130be70101875f45176ee2d91197152a862859a54ca0dedbbaee8946ba8082a168261ea9f4cf19d4eecd5550b141248cdaf08b53123d1b4a264feb7eabbf4892c852&amp;amp;a=w%3D1440%26h%3D760%26fm%3Dpng%26q%3D75&amp;amp;cd=2022-10-27T08%3A52%3A13.493Z&quot; alt=&quot;&quot;/&gt; &lt;p&gt;Back in the 90s, the main challenge was to create web pages smaller than 40 kb, because the internet was slow. Websites were made from basic HTML, CSS and PHP. As a designer, it felt like drawing in Microsoft Paint – few colors, few tools. It was more about creativity than complexity.&lt;/p&gt;&lt;p&gt;Then in 2000, Flash changed the world (wide web). A lot of the big brand’s websites and almost every micro site were made with Flash. The beauty of it was: It was an animation tool, a design tool, had a script language that could talk to backends and even stream content to make up for still slow internet connections. It was a single creative tool to build complex interfaces, a single source of truth. In the 2000s, I built flash sites for: Coca-Cola, Swarovski, Montblanc, Mercedes Benz, BMW, Volkswagen, Mazda, Vitra, Deutsche Post and more. It was a blast. Until …&lt;/p&gt;&lt;p&gt;The late 2000s. The mobile era changed the internet (and our daily lives) dramatically. Suddenly everything had to be responsive (R.I.P. &lt;a href=&quot;https://960.gs&quot;&gt;960.gs&lt;/a&gt; → Hello &lt;a href=&quot;https://getbootstrap.com/&quot;&gt;Twitter Bootstrap&lt;/a&gt;), tech evolved at the speed of light and everything became a lot more complex. Designers designed in Adobe Photoshop, programmers programmed in Macromedia Dreamweaver and suddenly it wasn’t one beautiful, creative tool anymore, but a design environment and a development environment. Not to talk about browsers … Netscape, IE, Opera, Safari, Firefox, and later Chrome, … what a mess.&lt;/p&gt;&lt;p&gt;So now, roughly 20 years later, two decades of designers fighting for their designs to be brought online pixel perfect and developers fighting for feasibility, performance, stable, clean code and still with IE11, the two worlds are moving closer together again – inter alia thanks to Figma Tokens.&lt;/p&gt;&lt;h2&gt;Figma Tokens&lt;/h2&gt;&lt;p&gt;&lt;b&gt;A single source truth again – finally&lt;/b&gt;&lt;/p&gt;&lt;p&gt;We all love Figma, don’t we!? Multiuser, blazingly fast and stable, global styles and component libraries, auto layout and  3rd party plugin API access. The latter made Figma Tokens possible and is bringing designers and developers closer together than anything else in the last decade.&lt;/p&gt;&lt;p&gt;Figma Tokens enables us to define design tokens other than color and typography (which Figma natively supports). It is finally possible to create tokens such as spacings, paddings, sizes, scales, shadows, gradients, … store them in markup and export them into whatever format you need, including CSS.&lt;/p&gt;&lt;p&gt;Why is this so significant? We now have synced design tokens in Figma and code, components built from the same design tokens in Figma and code and in the end complete page layouts of auto-layouted Figma components which look and scale similar to a coded web page.&lt;/p&gt;&lt;p&gt;Again, what’s the significancy? Consistency – and a real single source of truth – finally again! So now it’s possible to define design tokens, use them to build components and use those to build web pages.&lt;/p&gt;&lt;p&gt;If I change a design token in Figma Tokens, it changes the affected components in Figma, changes the tokens file, changes the CSS, changes the web page. End to end happiness. It’s even possible the other way around: If an engineer changes a value in CSS, it changes the tokens file which changes the component, which finally changes the design in Figma.&lt;/p&gt;&lt;p&gt;What do you need? Figma, the Figma Tokens plugin, Github, a code editor like Microsoft’s popular VS Code and some scripts. Sounds like a lot, but don’t panic …&lt;/p&gt;&lt;p&gt;If you know what Figma is, you’ll be fine, I’ll explain the rest. Let’s go!&lt;/p&gt;&lt;h2&gt;Installation (Modern Macs only)&lt;/h2&gt;&lt;p&gt;&lt;code&gt;🤓 &lt;/code&gt;&lt;code&gt;&lt;b&gt;Disclaimer: &lt;/b&gt;&lt;/code&gt;&lt;code&gt;I’m not a developer, I’m a designer. Some things I explain or do might not be best practice – but simple. My goal is to enable designers like me to experience the magic of Figma Tokens with as little development knowledge as possible/me.
However, if something is wrong and could be done better, please approach me, I’m happy to update this article.&lt;/code&gt;&lt;/p&gt;&lt;h3&gt;In Figma&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Install the Figma Tokens plugin: &lt;a href=&quot;https://www.figma.com/community/plugin/843461159747178978/Figma-Tokens&quot;&gt;https://www.figma.com/community/plugin/843461159747178978/Figma-Tokens&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;On your Mac&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Install Microsoft’s VS Code: &lt;a href=&quot;https://code.visualstudio.com/download&quot;&gt;https://code.visualstudio.com/download&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;In the Terminal&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Open the Terminal app on your Mac.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;First, let’s see what shell your Terminal is using. Run &lt;code&gt;echo $0&lt;/code&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;If the output says “-zsh”, you good to go, otherwise:&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;If the output says “-bash”, then run &lt;code&gt;chsh -s /bin/zsh&lt;/code&gt;, type in your password and close and re-open the Terminal. Run &lt;code&gt;echo $0&lt;/code&gt; again → Now it will say “-zsh” (This solely changed the default shell of your Terminal (the script language of your Terminal) and you can always switch back to BASH if you would want for any reason with &lt;code&gt;chsh -s /bin/bash&lt;/code&gt;)&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;With ZSH running, do the following:&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Run &lt;code&gt;curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.1/install.sh | bash&lt;/code&gt;&lt;/p&gt;&lt;p&gt; → This downloads and installs NVM (Node Version Manager) on your Mac that enables you to easily install Node.js. It will take a few minutes, but when it’s finished, you’ll see a message to close and re-open the Terminal to use it.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;⚠️ Attention now: Copy&lt;/b&gt; these lines to your clipboard (not into Terminal!): &lt;/p&gt;&lt;p&gt;&lt;code&gt;export NVM_DIR=&amp;quot;$([ -z &amp;quot;${XDG_CONFIG_HOME-}&amp;quot; ] &amp;amp;&amp;amp; printf %s &amp;quot;${HOME}/.nvm&amp;quot; || printf %s &amp;quot;${XDG_CONFIG_HOME}/nvm&amp;quot;)&amp;quot; [ -s &amp;quot;$NVM_DIR/nvm.sh&amp;quot; ] &amp;amp;&amp;amp; \\. &amp;quot;$NVM_DIR/nvm.sh&amp;quot;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;With the above in your clipboard, &lt;b&gt;type&lt;/b&gt; the following in Terminal and run: &lt;code&gt;pbpaste &amp;gt;&amp;gt; ~/.zshrc&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;⚠️ Don’t copy-paste, you need the above text in your clipboard) → This creates a hidden file called “.zshrc” in your user’s home directory with the code you just copied into your clipboard. It tells Terminal to load NVM on startup.&lt;/b&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;To check if it worked. go into Finder and navigate into your home folder (or press “Command + Shift + H” on your keyboard) then press “Command + Shift + .” to display hidden files. There you should see your newly created hidden “.zshrc” file. (Press “Command + Shift + .”  to hide hidden files again)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Close and re-open the Terminal so it refreshes, then run &lt;code&gt;nvm install 16&lt;/code&gt; → This installs Node.js Version 16 – very easy thanks to NVM.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Check if NVM and Node.js are installed by running &lt;code&gt;nvm --version&lt;/code&gt; and afterwards &lt;code&gt;node --version&lt;/code&gt; → This should return version numbers formatted like X.X.X.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Phew, you’re done in Terminal. 😅 For troubleshooting on all of the above commands: &lt;a href=&quot;https://github.com/nvm-sh/nvm#install--update-script&quot;&gt;https://github.com/nvm-sh/nvm#install--update-script&lt;/a&gt; or &lt;a href=&quot;https://cheatcode.co/tutorials/how-to-install-node-js-and-manage-versions-with-nvm#installing-nvm-node-version-manager&quot;&gt;https://cheatcode.co/tutorials/how-to-install-node-js-and-manage-versions-with-nvm#installing-nvm-node-version-manager&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;Setup&lt;/h2&gt;&lt;h3&gt;On GitHub&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Create an account on &lt;a href=&quot;https://github.com&quot;&gt;https://github.com&lt;/a&gt;, if you don’t have one yet.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Create a new GitHub repository. Let’s name it: “My Figma Tokens Test”. (GitHub will replace the spaces with dashes, that’s ok.)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;⚠️ Select the option “Add a README file”.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;You can leave the rest of the available options like they are.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Scroll down and hit “Create repository”.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;In Figma&lt;/h3&gt;&lt;p&gt;&lt;code&gt;This will be the most simple project you’ve ever created. Its focus is syncing one single design token between Figma and a web page. Nothing more. In my next articles, I’ll cover how to build a “Design Token System” for a multi-brand design system and how to work together in a team using the Figma Tokens plugin. (Oh, pressure is on now! 😅)&lt;/code&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;In a new Figma file, create a simple button with a text-label and a background.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Open the Figma Tokens plugin (FT from now on) and add one single design token. For our example we only need one color token. In the “Colors” category, click “+”, name it “bg” and give it a nice color. &lt;b&gt;🚫 Do not convert colors or typography into Figma styles, this will not work! (at least not with the FT free version)&lt;/b&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Select the background of your button and click on the “bg” token you just created in FT. This will apply the color to your button’s bg.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Now let’s connect FT to GitHub. In the FT, navigate to the “Settings” tab, then to the “GitHub” tab and “Add new credentials”:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;//images.ctfassets.net/54dnxp2417nl/4CrUOOQszhtj85x5QbkxOR/aade1b222c9668c117c8c69260cf840e/ft1-01.png&quot; alt=&quot;&quot;/&gt;&lt;figcaption&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Name:&lt;/b&gt; Irrelevant, choose one you like.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Personal Access Token:&lt;/b&gt; You can get it in your GitHub settings. This link should work: &lt;a href=&quot;https://github.com/settings/tokens&quot;&gt;https://github.com/settings/tokens&lt;/a&gt;.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Click the button “Generate a token” in the top right corner&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Enter anything as a “Note” .e.g. “My Figma Tokens Test Token”&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Set “Expiration” to “No expiration”&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Select the “repo” checkbox (This will also select its 5 children)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Click “Generate token” on the bottom of the page.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;From the confirmation page, copy the token and paste it into the FT GitHub settings (see screen above)&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Repository:&lt;/b&gt; This is a combo of your GitHub username then ”/” then the repository name. Navigate to your repository and copy the username/repository part of the URL.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Default Branch: &lt;/b&gt;Keep it “main”.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;File Path:&lt;/b&gt; “tokens.json”. It could basically have any name, but it has to match the Token Transformer action (explained later).&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;baseURL:&lt;/b&gt; Irrelevant.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Click “Save” and in the appearing overlay: Enter a “Commit message” like “My first commit” and click “Push”.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;figure&gt;&lt;img src=&quot;//images.ctfassets.net/54dnxp2417nl/6VVk8Q9uiRSLJN9BoA1O4G/f53638251515017fbefbe0c8960804a0/ft1-02.png&quot; alt=&quot;&quot;/&gt;&lt;figcaption&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;It will suggest to create a pull request. A pull request (PR) would basically be a request from you to the owner of the repository to pull (and merge) your changes into the “main” repository). Since we work directly on the “main” branch and not on another branch called e.g. “color-tests”, all of our PRs will directly be committed and merged with the “main” branch. So a PR is actually not needed (in our very simple example).&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;You just published your first tokens file! You can see it in your repository on GitHub. “tokens.json” is there, next to the &amp;quot;README.md”. Now it’s time to use it in code …&lt;/p&gt;&lt;h3&gt;In VS Code&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Click on the link and install the GitHub extension in VS Code: &lt;a href=&quot;https://code.visualstudio.com/docs/editor/github&quot;&gt;https://code.visualstudio.com/docs/editor/github&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;After you’ve installed it, the infamous GitHub cat icon appears in the left pane. Click it and sign in to GitHub.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Then press “Command + Shift + P” to open the commands browser and type “clone”. From the list select “Git: Clone”, then click your way through to your Figma Tokens Test repository. Select a folder on your Mac where to store your repository. A modal is appearing in the bottom right corner asking you where to open it. Basically irrelevant. Select “Open”.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Create an empty file named “.gitignore” in your project’s root folder (right-click → New File or in the menu: File → New File …), type &lt;code&gt;node_modules&lt;/code&gt; in the first line and save it → This will prevent to sync the huge “node_modules” folder with GitHub. It’s only needed locally, so it can be excluded from up- and downloads.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;//images.ctfassets.net/54dnxp2417nl/4uUHGwNMtSMnZ9W99kdVO/a5f6fe2d941953ec5f0d3c22239aeead/ft1-03.png&quot; alt=&quot;&quot;/&gt;&lt;figcaption&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Create another empty file in your project’s root folder and name it “index.html”. In the “index.html”, create a simple button:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;//images.ctfassets.net/54dnxp2417nl/6Zxi5pQHjqAGmgIq9Odyo3/deecb9d264555743450d69909f2414ee/ft1-04.png&quot; alt=&quot;&quot;/&gt;&lt;figcaption&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;/p&gt;
            &lt;figure&gt;
              &lt;pre&gt;&lt;code class=&quot;html language-html&quot;&gt;&amp;lt;!DOCTYPE html&amp;gt;
&amp;lt;html&amp;gt;
    &amp;lt;head&amp;gt;
        &amp;lt;link rel=&quot;stylesheet&quot; href=&quot;build/css/_variables.css&quot;&amp;gt;
    &amp;lt;/head&amp;gt;
    &amp;lt;body&amp;gt;
        &amp;lt;style&amp;gt;
            button {
                background-color: var(--bg);
                color: white;
            }
        &amp;lt;/style&amp;gt;
        &amp;lt;button&amp;gt;Hello&amp;lt;/button&amp;gt;
    &amp;lt;/body&amp;gt;
&amp;lt;/html&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
              &lt;figcaption&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
          &lt;/li&gt;&lt;li&gt;&lt;p&gt;Navigate to your project folder on your Mac and find the “index.html”. Double click it. This will only show the outline of the button since we do not have yet defined the variable “—bg”, which will come from the FT file.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h4&gt;Install Token Transformer&lt;/h4&gt;&lt;p&gt;&lt;a href=&quot;https://www.npmjs.com/package/token-transformer&quot;&gt;Token Transformer&lt;/a&gt; converts the FT markup file into a format that Style Dictionary (see next section) can work with.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Open a new terminal inside VS Code (Menu: Terminal → New Terminal). Look into the top right menu bar in the Terminal window and make sure you are running “zsh”. If it says “bash”, click the little “+” and open a “zsh” window.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Run these commands one after another:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;npm install token-transformer&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;npx token-transformer tokens.json output.json&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;This converted all values form “tokens.json” into a new file called “output.json” and eliminated all variables, so “Style Dictionary” (see below) understands them.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;You just installed your first NPM package and ran it!&lt;/p&gt;&lt;h4&gt;Install Style Dictionary&lt;/h4&gt;&lt;p&gt;&lt;a href=&quot;https://amzn.github.io/style-dictionary/#/quick_start&quot;&gt;Style Dictionary&lt;/a&gt; finally converts “output.json” (from above) into CSS.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Open a new terminal window (you can find it in the menu)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Run these commands one after another:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;npm install -g style-dictionary&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;style-dictionary init basic&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Configure config.json&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Find the “config.json” file either in the “style-dictionary” or root folder of your project&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;As “source”, we use “output.json” which was the output file for our Token Transformer action (see a few lines above)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Then find the part where you see a few “scss” and rename them to “css” to create a CSS not a SCSS file. Style Dictionary can create all kinds of different formats for iOS, Android and many more, but we only need CSS.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;//images.ctfassets.net/54dnxp2417nl/1yejpi2lES9e24mWR1NTBW/8f715cd6678f88f9d81a332c5956404b/ft1-05.png&quot; alt=&quot;&quot;/&gt;&lt;figcaption&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Run: &lt;code&gt;npx style-dictionary build&lt;/code&gt; → This creates a few standard files and folders. Later, these files will be overwritten with your design token styles you defined in Figma. Exciting!&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h4&gt;Setup Automation&lt;/h4&gt;&lt;p&gt;Because we are lazy, let’s setup an automation that runs two scripts (Token Transformer &amp;amp; Style Dictionary) whenever we download (&lt;code&gt;git pull&lt;/code&gt;) an updated version of the FT file from Github onto our Mac.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Run: &lt;code&gt;npm set-script build &amp;quot;token-transformer tokens.json output.json &amp;amp;&amp;amp; npx style-dictionary build&amp;quot; &lt;/code&gt;This creates an alias named “build” that triggers two scripts (Token Transformer &amp;amp;&amp;amp; Style Dictionary).&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;//images.ctfassets.net/54dnxp2417nl/3SMBQmWUJUa29pWhHdmmUD/df97236fb95df59d97836e8deccdc6ba/ft1-06.png&quot; alt=&quot;&quot;/&gt;&lt;figcaption&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h4&gt;Optional: Install Husky (Git Hook)&lt;/h4&gt;&lt;p&gt;If you are a fan of NPM packages now (like me), you can optionally install &lt;a href=&quot;https://github.com/typicode/husky&quot;&gt;Husky&lt;/a&gt;, which will automate your workflow a little bit. It creates an automation that runs “build” each time you download updates from GitHub by entering &lt;code&gt;git pull&lt;/code&gt;. Yes, a very tiny automization, but it’s a bit magical seeing it happen.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Run: &lt;code&gt;npm install husky&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Run: &lt;code&gt;npx husky add .husky/post-merge &amp;quot;npm run build&amp;quot;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Run: &lt;code&gt;git add .husky/post-merge&lt;/code&gt; This adds the hook to react to Git.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Now every time you run &lt;code&gt;git pull&lt;/code&gt; in your VS Code’s Terminal window, it checks if there is an update on GitHub. If there is an update, it pulls (downloads) all changes and afterwards automatically triggers the Git Hook and runs &lt;code&gt;npm run build&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;Workflow&lt;/h2&gt;&lt;p&gt;Now for the easy and fun part:&lt;/p&gt;&lt;h3&gt;Figma to Code&lt;/h3&gt;&lt;p&gt;This describes how changes of design tokens in FT change the affected components in Figma and then propagate over GitHub to CSS and in the end to your HTML page:&lt;/p&gt;&lt;p&gt;&lt;b&gt;In Figma&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Make changes on a token in FT, maybe the bg-color we use in our button (right-click on the color token and “Edit Token”), which will change the bg-color of your button obviously → This will show a little blue notification dot next to the “Push to GitHub” button in the bottom-left corner.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Click “Push to GitHub” and in the overlay enter a “Commit message” before hitting the “Push” button.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;In VS-Code&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Git-Pull the changes, by running &lt;code&gt;git pull&lt;/code&gt; in the Terminal of your VS Code project.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;If: Husky’s Git hooks are installed, our little “build” script runs automatically.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Otherwise: Run Token Transformer and Style Dictionary by typing: &lt;/p&gt;&lt;p&gt;&lt;code&gt;npm run build&lt;/code&gt; (see “Setup Automation” chapter above), then reload HTML page&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;BOOM! 🤩&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;Code to Figma&lt;/h3&gt;&lt;p&gt;This describes how changes in code propagate over GitHub to FT in Figma and finally change the design of affected components in Figma.&lt;/p&gt;&lt;p&gt;&lt;code&gt;😇 To be honest, this direction is not as end-to-end as it could be, since our two converters (Token Transformer and Style Dictionary) were only built to run in one direction: from Figma to CSS. In a larger project, you would probably store your tokens in Style Dictionary and use something like Backlight alongside.&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;In VS Code&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Change a token in “tokens.json”, maybe the bg-color we use in our button by replacing the number value to something like 100, 500 or 900. The {brackets} you see in the file are variables/references to values in the same file.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Open the 3rd tab &amp;quot;SOURCE CONTROL&amp;quot; on the left side (see screenshot)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Click the little “+” left of the yellow number to stage all your changes → This marks the files that will be committed to your Git repository with the next update&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;//images.ctfassets.net/54dnxp2417nl/7pdUxn1I5FfXrvulXyT83O/d0607b5d430d2b1c9b459e9450291468/ft1-07.png&quot; alt=&quot;&quot;/&gt;&lt;figcaption&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Write a commit message like “Changed the button bg-color” and click “Commit” → This will create a “package” with the marked files together with a message so you (and your team) see what has changed&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;//images.ctfassets.net/54dnxp2417nl/N2jcrWnAxn9RewjK47AUp/1286bc5025ad6a8bc18621c5250e5cbe/ft1-08.png&quot; alt=&quot;&quot;/&gt;&lt;figcaption&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Click “Sync Changes” → This finally uploads the “package” to your “My Figma Tokens Test” Git repository&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;//images.ctfassets.net/54dnxp2417nl/7CGFvzelUmHaoEB7FRZ7VT/8b44de4a87e7690bc1f5c3b1d463be08/ft1-09.png&quot; alt=&quot;&quot;/&gt;&lt;figcaption&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;In Figma&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Click “Pull from GitHub” in the bottom-left corner of FT&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;BOOM! 🤩&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;Bonus Points&lt;/h2&gt;&lt;p&gt;Syncing the background color of our button was obviously only the start. You could now try to add tokens for foreground color, typography for your button label, paddings and corner roundness – maybe even define different states for the button. And add all of these tokens to your button. Look &lt;a href=&quot;https://www.w3schools.com/css/css3_buttons.asp&quot;&gt;here&lt;/a&gt; or &lt;a href=&quot;https://moderncss.dev/css-button-styling-guide/&quot;&gt;there&lt;/a&gt; for a start.&lt;/p&gt;&lt;p&gt;Or with a little more trial and error, type a single letter directly in VS Code and see what code-completion offers you.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;//images.ctfassets.net/54dnxp2417nl/7iD6aO55WmVcZPE4ThGAET/4b4099731a4262059eaa1a35c9e3c85d/ft1-10.png&quot; alt=&quot;&quot;/&gt;&lt;figcaption&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;Look Mom!&lt;/h2&gt;&lt;p&gt;Look what you’ve learned … You defined your first design token in code, created a new repository on GitHub, installed VS Code, NVM, Node.js and a few NPM packages, ran several lines of code in the Terminal, pushed, pulled and merged changes in GitHub like a maniac and ultimately synced design tokens between Figma and a web page.&lt;/p&gt;&lt;p&gt;Xzibit would say (90s meme! Watch out!): “You’ve officially been pimped!” You are now ready to create a full set of design tokens to use in components, create light and dark themes for your design system and (purple tentacle would say (again: 90s meme!)) “ready to conquer the world”. How?&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://satellytes.com/blog/post/creating-and-crafting-a-design-token-system/&quot;&gt;My next article is about &amp;quot;Creating &amp;amp; Crafting a Design Token System”&lt;/a&gt; for a multi-brand design system.&lt;/p&gt;&lt;p&gt;💫&lt;/p&gt;&lt;p&gt;&lt;b&gt;This is my first article ever. If you have any feedback, please feel free or even encouraged to &lt;/b&gt;&lt;a href=&quot;https://www.linkedin.com/in/eric-singhartinger-75a95a1/&quot;&gt;&lt;b&gt;let me know&lt;/b&gt;&lt;/a&gt;&lt;b&gt;. What could be improved? What did work and what didn’t? What’s missing? Thank you for your time.&lt;/b&gt;&lt;/p&gt;</content:encoded></item><item><title><![CDATA[How to Run a Local Database Using Docker]]></title><description><![CDATA[Easy to follow examples on how to start Redis or PostgreSQL on your local machine using Docker containers.]]></description><link>https://satellytes.com/blog/post/how-to-run-a-local-database-using-docker/</link><guid isPermaLink="false">https://satellytes.com/blog/post/how-to-run-a-local-database-using-docker/</guid><pubDate>Tue, 13 Sep 2022 00:00:00 GMT</pubDate><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://satellytes.com/_gatsby/image/3fda5a6b64f0417714dca44b04754903/4be445bf02c55418e404abd8f2a1a674/taylor-vick-M5tzZtFCOfs-unsplash.jpg?eu=be64a56812a1171370de94248236f8ae695e414d8d50dbfc602bbb449f04d535e2ff17d6f99fd735a932edf187cce268daf343c974b350799e3c573dbd838474e974b25e4894ecdd936ca22c32514326229f0c91a4ed4e3e0d2a415c11e0379f5b4378d007b30647e8a2d57ac90fb0191e457222f743ae3cd4238cf62d704338f2dc73d0668f0a3680639839759127663d132aef26e65b74c01d69f12100662bee8b4c84764cdc620aa619e5d5e9faee9f5fb1d3d1a26d204cafadcf1dd7f5dc0d11e81760c4cda18b5b074717096c2df900c7c100918b403454946a81116fa2da3132&amp;amp;a=w%3D1440%26h%3D760%26fm%3Djpg%26q%3D75&amp;amp;cd=2022-09-08T11%3A37%3A01.873Z&quot; alt=&quot;&quot;/&gt;&lt;figcaption&gt;&lt;a href=&quot;https://unsplash.com/photos/M5tzZtFCOfs&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Image by Talyor Vick&lt;/a&gt;&lt;/figcaption&gt;&lt;/figure&gt; &lt;p&gt;So, you are working on your side project and the time has come and you need a database? Awesome!

In this article we want to show you how simple it is to start a database on your local machine, using Docker.&lt;/p&gt;&lt;h4&gt;⚠️ Security Disclaimer&lt;/h4&gt;&lt;p&gt;This article will not go into any detail about how to properly secure your database. The commands provided are only meant to be executed in a safe, non-production environment, like your local development machine.
For ways to host a secure database, please have a look at the section &amp;quot;Ready to move into the cloud?&amp;quot; at the end of this article and do your own research.&lt;/p&gt;&lt;h3&gt;Which database to use?&lt;/h3&gt;&lt;p&gt;This is entirely up to you. There are a lot of different database types to choose from, and there is no right or wrong. It all depends on your specific use case.&lt;/p&gt;&lt;p&gt;This article includes examples for Redis and PostgreSQL. To figure out which database you should choose, please refer to other resources. I can recommend this &lt;a href=&quot;https://www.youtube.com/watch?v=cC6HFd1zcbo&quot;&gt;Video: &amp;quot;Did I Pick The Right Database?&amp;quot;&lt;/a&gt; (1h) from Theo Browne. It provides an excellent overview of the different types of databases and when to use them.&lt;/p&gt;&lt;p&gt;The most common databases are relational databases (&lt;a href=&quot;https://en.wikipedia.org/wiki/Relational_database&quot;&gt;Wikipedia: Relational Database&lt;/a&gt;). Most of them can be managed with a domain-specific language (DSL) called &amp;quot;SQL&amp;quot; (e.g. MySQL, PostgreSQL, MariaDB). In this article we will show how to start a PostgreSQL database locally.&lt;/p&gt;&lt;p&gt;Another set of popular &amp;quot;databases&amp;quot; are key-value data stores (e.g. Redis, Memcached). Most often these are not used as databases, but rather as a cache for other databases. Personally, I like to use them for small side projects because of how easy they are to set up and work with. This article will provide an example of how to start Redis.&lt;/p&gt;&lt;p&gt;There are more types of databases like non-relational/NoSQL databases (e.g. MongoDB, CouchDB). These won&amp;#39;t be covered in this article.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Prerequisites&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;&lt;b&gt;Docker&lt;/b&gt;&lt;/p&gt;&lt;p&gt;If you want to follow along with the commands and code snippets in this article, you need to have Docker installed on your machine. If you are unsure whether that&amp;#39;s the case, run the following command:&lt;/p&gt;&lt;p&gt;&lt;code&gt;docker -v&lt;/code&gt;&lt;/p&gt;&lt;p&gt;This will print the version of your installed Docker. In case you get an error, switch to &lt;a href=&quot;https://www.docker.com/&quot;&gt;docker.com&lt;/a&gt; and download and install Docker.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Deno&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Once we start a database, we want to verify that we can connect to it. There are a lot of ways to connect to a (local) database. In this article we are going to use the &lt;a href=&quot;https://deno.land/&quot;&gt;Deno&lt;/a&gt; JavaScript REPL (&lt;a href=&quot;https://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop&quot;&gt;Wikipedia:  REPL&lt;/a&gt;) to connect to the local database(s). This is entirely optional.
If you want to follow along with the code snippets to verify that the database can be connected to, you need to have Deno installed. If you are unsure if that&amp;#39;s the case, run the following command:&lt;/p&gt;&lt;p&gt;&lt;code&gt;deno -V&lt;/code&gt;&lt;/p&gt;&lt;p&gt;This will print the version of your installed &lt;code&gt;deno&lt;/code&gt; CLI. In case you get an error, head over to &lt;a href=&quot;https://deno.land&quot;&gt;deno.land&lt;/a&gt; to download and install Deno.&lt;/p&gt;&lt;h3&gt;Example: Redis&lt;/h3&gt;&lt;p&gt;Redis is a key-value data store that uses the system memory to store data. Since it does not need to perform time-consuming I/O disk operations, it is extremely fast. The amount of data you can store in it is restricted by the size of your memory, though.&lt;/p&gt;&lt;p&gt;Redis comes with an official Docker image in the &lt;a href=&quot;https://hub.docker.com/_/redis&quot;&gt;Docker Hub&lt;/a&gt;. We are going to use this image to run Redis on our local machine.&lt;/p&gt;&lt;p&gt;Run the following command, and you&amp;#39;re good to go:&lt;/p&gt;&lt;p&gt;&lt;code&gt;docker run --name some-redis --publish 6379:6379 --detach redis&lt;/code&gt;

If everything worked, this command will respond with the container ID that it just created.&lt;/p&gt;&lt;p&gt;Let&amp;#39;s have a closer look at the command itself:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;docker run&lt;/code&gt;
takes an image, turns it into a container, and runs that container.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;--name some-redis&lt;/code&gt;
assigns the name &amp;#39;some-redis&amp;#39; to the created container. This will help to identify and control it later.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;--publish 6379:6379&lt;/code&gt;
publishes the container-internal TCP port 6379 to the outside world. This allows us to connect with Redis, which is listening at port 6379 by default.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;--detach&lt;/code&gt;
runs the container in &amp;quot;detached&amp;quot; mode. This means that you can happily close the terminal after you ran that command. The container will continue to run.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;redis&lt;/code&gt;
the name of the image that we want to use. This has to be the last argument to the command, otherwise the arguments would be passed to the entrypoint of that image.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;To verify that the container got created and is running, you can list your running docker containers with this command:&lt;/p&gt;&lt;p&gt;&lt;code&gt;docker container ls&lt;/code&gt;&lt;/p&gt;&lt;p&gt;The output of this command includes information about the running containers, such as the name &lt;code&gt;some-redis&lt;/code&gt; as well as the applied port mapping &lt;code&gt;0.0.0.0:6379-&amp;gt;6379/tcp&lt;/code&gt;.&lt;/p&gt;&lt;h4&gt;Verify that it works&lt;/h4&gt;&lt;p&gt;Now we want to verify that we can connect to Redis and use it as a database. Like discussed in the prerequisites, we chose the Deno runtime to do this. To connect to and interact with our database we need a &amp;quot;driver&amp;quot;. The Deno ecosystem provides a very convenient Redis driver, that we are going to use in our example script.&lt;/p&gt;&lt;p&gt;You can run this script in the Deno REPL, which you can enter by running &lt;code&gt;deno&lt;/code&gt; in your terminal. Now either copy the below code into the REPL all at once and execute it, or execute it line by line:&lt;/p&gt;
            &lt;figure&gt;
              &lt;pre&gt;&lt;code class=&quot;js language-js&quot;&gt;// download the Deno Redis driver and all its dependencies
import { connect } from &apos;https://deno.land/x/redis/mod.ts&apos;;

// connect to the database
const client = await connect({ hostname: &apos;localhost&apos;, port: 6379 });

// store the value &apos;bar&apos; at key &apos;foo&apos;
await client.set(&apos;foo&apos;, &apos;bar&apos;); // OK

// retrieve the value
await client.get(&apos;foo&apos;); // &apos;bar&apos;
&lt;/code&gt;&lt;/pre&gt;
              Verify that we can connect to Redis in Deno REPL
            &lt;/figure&gt;
          &lt;p&gt;Database drivers for Redis exist for almost all known programming languages, so feel free to search for a driver that fits your needs.&lt;/p&gt;&lt;h3&gt;Example: PostgreSQL&lt;/h3&gt;&lt;p&gt;Postgres (officially PostgreSQL), is a classical relational database. It is slightly less convenient to set up than Redis, but - to be fair - it&amp;#39;s a &amp;quot;proper&amp;quot; database. If you are familiar with SQL (or want to learn it), this is a great choice. It&amp;#39;s a well-established database with a huge community and a lot of online resources.&lt;/p&gt;&lt;p&gt;Postgres also comes with an &lt;a href=&quot;https://hub.docker.com/_/postgres&quot;&gt;official Docker image&lt;/a&gt; which we are going to use:&lt;/p&gt;&lt;p&gt;&lt;code&gt;docker run --name some-postgres -p 5432:5432 -d --env POSTGRES_USER=user --env POSTGRES_PASSWORD=password postgres:alpine&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Let&amp;#39;s take a closer look at this command:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;docker run&lt;/code&gt;
same as for the Redis command.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;--name some-postgres&lt;/code&gt;
similar to the Redis command, this assigns a name to the created container.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;-p 5432:5432&lt;/code&gt;
shorthand for &lt;code&gt;--publish 5432:5432&lt;/code&gt; (by default Postgres listens on port 5432).&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;-d&lt;/code&gt;
shorthand for &lt;code&gt;--detach&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;--env POSTGRES_USER=user --env POSTGRES_PASSWORD=password&lt;/code&gt;
provide environment variables that are passed to inside the container. Here we provide a default postgres username as &lt;code&gt;POSTGRES_USER&lt;/code&gt; (will be the superuser) and a password for that user as &lt;code&gt;POSTGRES_PASSWORD&lt;/code&gt;. These are made up, feel free to choose something else. Take a look at the linked Docker image for more details.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;postgres&lt;/code&gt;
the image that we want to use for the container. &lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h4&gt;Verify that it works&lt;/h4&gt;&lt;p&gt;Like before, we will use a Deno driver and the Deno REPL to verify that we can connect to this database. Start the Deno REPL by running &lt;code&gt;deno&lt;/code&gt;, and then execute this code in it (preferably a single command at a time):&lt;/p&gt;
            &lt;figure&gt;
              &lt;pre&gt;&lt;code class=&quot;js language-js&quot;&gt;// download the Deno Postgres driver and all its dependencies
import { Client } from &quot;https://deno.land/x/postgres/mod.ts&quot;;

// create a client
// username and password need to match the
// ones given in the &quot;docker run ...&quot; command
const client = new Client({
  user: &quot;user&quot;,
  password: &quot;password&quot;,
  database: &quot;user&quot;,
  hostname: &quot;localhost&quot;,
  port: 5432,
});

// connect the client to the database
await client.connect();

// create a table &apos;Companies&apos;
await client.queryObject(&quot;CREATE TABLE Companies ( Name varchar(255) )&quot;);

// insert a value
await client.queryObject(&quot;INSERT INTO Companies (Name) VALUES (&apos;Satellytes&apos;)&quot;);

// retrieve the value
await client.queryObject(&quot;SELECT Name FROM Companies&quot;); // { ..., rows: [{ name: &apos;Satellytes&apos; }] }
&lt;/code&gt;&lt;/pre&gt;
              Verify that we can connect to Postgres in Deno REPL
            &lt;/figure&gt;
          &lt;h3&gt;Persistence&lt;/h3&gt;&lt;p&gt;The databases started this way will lose their data if you remove, or even stop, the containers. To persist the data, you need to mount a file on your local hard drive where the data can be stored. If you are interested, you can take a look at the &lt;a href=&quot;https://docs.docker.com/storage/&quot;&gt;Docker Storage documentation&lt;/a&gt; on how to do so.&lt;/p&gt;&lt;p&gt;Unfortunately, each database stores its data differently, so there is no easy solution that fits all scenarios. Also note, that in the case of in-memory data stores like Redis you need to dump the memory-state to a file (&lt;a href=&quot;https://redis.io/docs/manual/persistence/&quot;&gt;Redis - Persistance documentation&lt;/a&gt;) to not lose it.&lt;/p&gt;&lt;h4&gt;Example: &amp;quot;Bind Mount&amp;quot; for Postgres Container&lt;/h4&gt;&lt;p&gt;An example for storing the data from Postgres on the host system using a &amp;quot;bind mount&amp;quot;, could look like this:&lt;/p&gt;&lt;p&gt;&lt;code&gt;docker run --name some-postgres -p 5432:5432 -d --env POSTGRES_USER=user --env POSTGRES_PASSWORD=password --mount type=bind,source=&amp;quot;$(pwd)&amp;quot;/postgres-data,target=/var/lib/postgresql/data postgres:alpine&lt;/code&gt;&lt;/p&gt;&lt;p&gt;This is the same command that we used before, but with one additional argument:&lt;/p&gt;&lt;p&gt;&lt;code&gt;--mount type=bind,source=&amp;quot;$(pwd)&amp;quot;/postgres-data,target=/var/lib/postgresql/data&lt;/code&gt;&lt;/p&gt;&lt;p&gt;This will mount the location at which Postgres stores its data (default: &lt;code&gt;/var/lib/postgresql/data&lt;/code&gt;) to a folder called &lt;code&gt;postgres-data&lt;/code&gt; in the current directory (&lt;code&gt;pwd&lt;/code&gt;) on the host system. If you always start the Postgres container with this command, your database data will persist, even when the container got removed. Note, that this directory on the host system will be owned exclusively by the user &amp;quot;&lt;code&gt;user&amp;quot;&lt;/code&gt; (as specified in the &lt;code&gt;POSTGRES_USER&lt;/code&gt; environment variable), so you can&amp;#39;t look at the file(s) in it.&lt;/p&gt;&lt;h3&gt;Ready to move into the cloud?&lt;/h3&gt;&lt;p&gt;You want to lift your project, including your database, up into the clouds (i.e. &amp;quot;deploy&amp;quot;)? There are great websites that offer affordable &amp;quot;Database as a Service&amp;quot; (DBaaS) services. Alongside the well-known and big SaaS providers like AWS, Azure, and Cloudflare, there are smaller projects emerging that focus more on usability. I want to emphasize the following two providers, that I&amp;#39;ve been using for private projects and am very happy with:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://planetscale.com/&quot;&gt;planetscale.com&lt;/a&gt;
Very fast, generous free tier&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://railway.app/&quot;&gt;railway.app&lt;/a&gt;
Free &amp;quot;Starter&amp;quot; plan in which you receive 5$ or 500 hours of usage per month (whichever limit is reached first)&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;These are no affiliate links, I&amp;#39;m just genuinely happy with their services.&lt;/p&gt;&lt;h3&gt;Conclusion&lt;/h3&gt;&lt;p&gt;Obviously there is a lot more to databases than what we talked about in this article. Two of the big remaining challenges are security and persistence. Depending on your application&amp;#39;s architecture and your system&amp;#39;s infrastructure these will need to be solved in very different ways.&lt;/p&gt;&lt;p&gt;However, to get started with databases, starting one on your local machine is a perfect first step. We hope that we were able to make this process less scary with this blog post, and we continue to wish you a pleasant journey 🙌&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Building a simple profile picture generator in React]]></title><description><![CDATA[A little tool for adding custom text to profile pictures, built using React and the HTML Canvas API.]]></description><link>https://satellytes.com/blog/post/profile-picture-generator-react/</link><guid isPermaLink="false">https://satellytes.com/blog/post/profile-picture-generator-react/</guid><pubDate>Fri, 26 Aug 2022 00:00:00 GMT</pubDate><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://satellytes.com/_gatsby/image/3fabedd7c580ae084efc0fb87d0ce904/4be445bf02c55418e404abd8f2a1a674/BF%20Blog.jpg?eu=bd67f23d40f14040718893218361fdf8380440198d0d8ffa357bba45ca54d732b6f441d5a294d062fb33edf6d69db36c8fa2439c75b2592bc23a0138e3d28771ef26b35e1c95ef8e9539a172320344232ece0497a1ea1b6c0c2042521ebc74de1c0724cc19ec0f10b6a69632c94ab34f55502235b45df9699a64cdb6396d0167ef812f866f86562cb17c953c7f840854344b09e664a51708ed0356c6591b632be5d750d0703991633ff21380a5c196dec831def88efc3c0b25b6a29f1884becd595ae51d27d989abd9524938411c254eb87fe6ba56849505391fcb44a63d45e0df267bd50bd7&amp;amp;a=w%3D1440%26h%3D760%26fm%3Djpg%26q%3D75&amp;amp;cd=2022-07-15T09%3A49%3A56.862Z&quot; alt=&quot;&quot;/&gt;&lt;figcaption&gt;&lt;a href=&quot;https://unsplash.com/photos/IBGqZJUDghM&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Image by Matthew Feeney (edited)&lt;/a&gt;&lt;/figcaption&gt;&lt;/figure&gt; &lt;p&gt;Few graphic elements found on social media these days convey first impressions as effectively as profile pictures do. These tiny, predominantly circular images often serve as a means of getting a rough idea of the outer appearance of a certain person. So why not put critical information in places that most of us take a look at first?&lt;/p&gt;&lt;p&gt;The small tool discussed in this post allows users to quickly add text label overlays to their profile pictures. Written in TypeScript using the &lt;a href=&quot;https://reactjs.org/&quot;&gt;React&lt;/a&gt; library, it runs locally in your browser and without any server-side processing of the user’s data. All image manipulations and compositions are implemented using the HTML &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/API/Canvas_API&quot;&gt;Canvas API&lt;/a&gt;. &lt;/p&gt;&lt;p&gt;In the following, we will mainly focus on the intricacies of integrating the canvas element with functional React components.&lt;/p&gt;&lt;p&gt;You can try out the application &lt;a href=&quot;https://badgeforge.satellytes.com/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;&lt;figure&gt;&lt;video preload=&quot;auto&quot; autoplay=&quot;&quot; loop=&quot;&quot; muted=&quot;&quot; width=&quot;100%&quot;&gt;&lt;source src=&quot;//videos.ctfassets.net/54dnxp2417nl/4pyxwWPqoqPM9MPMQgJNm4/2a4cf20890a96bf08ee37e0320d56cd3/demo.webm&quot; type=&quot;video/webm&quot;/&gt;&lt;/video&gt;&lt;figcaption&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;&lt;b&gt;Wiring up the canvas&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;To render the image according to the current parameters, an HTML canvas element is used, whose contents may then be captured into an image file for the user to save. In order to get to the desired visual result, most users will want to tweak these parameters until they see something they like. This, however, leads to frequent re-drawing of the canvas and thus asks for special treatment in the code to reduce possible lag to a minimum:&lt;/p&gt;
            &lt;figure&gt;
              &lt;pre&gt;&lt;code class=&quot;tsx language-tsx&quot;&gt;export const BadgeForge = () =&amp;gt; {

    [ ... ]

  const image = useMemo(() =&amp;gt; new Image(), []);
  image.src = selectedFile ? URL.createObjectURL(selectedFile) : placeholder;

  useEffect(() =&amp;gt; {
    const context = canvasRef.current?.getContext(&quot;2d&quot;);
    function drawAll() {
      if (context) {
        context.clearRect(0, 0, canvasHeight, canvasWidth);
        drawImage(context, image, 0, 0);
        drawDonut(context, canvasHeight, donutStroke, angle, donutColor);
        drawLabel([ ... ]);
      }
    }

    image.addEventListener(&quot;load&quot;, drawAll);

    return () =&amp;gt; image.removeEventListener(&quot;load&quot;, drawAll);
  }, [ ... ]);
}
&lt;/code&gt;&lt;/pre&gt;
              &lt;figcaption&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
          &lt;p&gt;As you can see by looking at the code above, the drawing of all canvas elements is blocked until the selected image file has finished loading. This prevents &lt;code&gt;drawImage(…)&lt;/code&gt; from being called before the referring image file has become available, ensuring that the elements are drawn in the right order. &lt;/p&gt;&lt;p&gt;Also note that, in order to maintain a reasonable level of responsiveness, we need to detach the event listener on every unmount and re-render of our React component. We can achieve this by having our &lt;code&gt;useEffect()&lt;/code&gt; hook return a cleanup callback that removes the previously attached event listener.&lt;/p&gt;&lt;p&gt;As mentioned earlier, the Canvas API provides a method called &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/API/HTMLCanvasElement/toDataURL&quot;&gt;&lt;code&gt;toDataURL(…)&lt;/code&gt;&lt;/a&gt; to get the current state as a &lt;code&gt;Data URL&lt;/code&gt; which returns the data of the desired file format in a &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Glossary/Base64&quot;&gt;Base64&lt;/a&gt; encoded string. In our case, we choose the PNG format as it preserves the transparency surrounding the output of our circular canvas. Finally, enabling the user to actually download this file involves one more step: We employ a makeshift anchor element with its &lt;code&gt;href&lt;/code&gt; property set to the image file we just created. Since this anchor is not part of the HTML DOM, the download action can be triggered by emulating an anchor click whenever the “Save image” button is clicked by the user:&lt;/p&gt;
            &lt;figure&gt;
              &lt;pre&gt;&lt;code class=&quot;tsx language-tsx&quot;&gt;export const RenderButton = () =&amp;gt; {
  const { canvasRef } = useContext(BadgeForgeContext);

  const handleClick = () =&amp;gt; {
    if (canvasRef.current) {
      const anchor = document.createElement(&quot;a&quot;);
      anchor.href = canvasRef.current.toDataURL(&quot;image/png&quot;);
      anchor.download = `profile-${new Date()
        .toISOString()
        .substring(0, 10)}.png`;
      anchor.click();
    }
  };

  return (
    &amp;lt;Button onClick={handleClick} title=&quot;Download as PNG file&quot;&amp;gt;
      &amp;lt;span&amp;gt;Save image&amp;lt;/span&amp;gt;
      &amp;lt;ButtonIcon&amp;gt;
        &amp;lt;Download /&amp;gt;
      &amp;lt;/ButtonIcon&amp;gt;
    &amp;lt;/Button&amp;gt;
  );
};
&lt;/code&gt;&lt;/pre&gt;
              &lt;figcaption&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
          &lt;p&gt;We use a React &lt;a href=&quot;https://reactjs.org/docs/context.html&quot;&gt;Context Provider&lt;/a&gt; to make references to the canvas element and parameters such as the label text accessible to other components throughout the application. The reference itself is set up via &lt;a href=&quot;https://reactjs.org/docs/hooks-reference.html#useref&quot;&gt;&lt;code&gt;useRef(…)&lt;/code&gt;&lt;/a&gt;  in the context provider component alongside all other canvas parameters: &lt;/p&gt;
            &lt;figure&gt;
              &lt;pre&gt;&lt;code class=&quot;tsx language-tsx&quot;&gt;export const BadgeForgeContextProvider = ({children}: [ ... ]) =&amp;gt; {
  const { colors } = useTheme();
  const canvasWidth = 800;
  const canvasHeight = canvasWidth;
  const canvasRef = useRef&amp;lt;HTMLCanvasElement&amp;gt;(null);
  const [selectedFile, setSelectedFile] = useState&amp;lt;File | null&amp;gt;(null);
  const [label, setLabel] = useState&amp;lt;string&amp;gt;(&quot;&quot;);
  const [donutColor, setDonutColor] = useState&amp;lt;string&amp;gt;(colors.purple400);
  const [donutStroke, setDonutStroke] = useState&amp;lt;number&amp;gt;(0.175 * canvasWidth);
  const [labelColor, setLabelColor] = useState&amp;lt;string&amp;gt;(colors.gray50);
  const [angle, setAngle] = useState&amp;lt;number&amp;gt;(-1);

  return (
    &amp;lt;BadgeForgeContext.Provider
      value={{
        canvasRef,
        canvasHeight,
        canvasWidth,
        donutColor,
        donutStroke,
        setDonutColor,
          [ ... ]
      }}
    &amp;gt;
      {children}
    &amp;lt;/BadgeForgeContext.Provider&amp;gt;
  );
};
&lt;/code&gt;&lt;/pre&gt;
              &lt;figcaption&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
          &lt;h3&gt;&lt;b&gt;Drawing the label text&lt;/b&gt;&lt;/h3&gt;&lt;figure&gt;&lt;img src=&quot;//images.ctfassets.net/54dnxp2417nl/3D5eXkgmjlYh82ralVvAha/cf46e482afd5b1ddba7ed9e6489be3e7/colors.png&quot; alt=&quot;&quot;/&gt;&lt;figcaption&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Unlike &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/SVG/Element/textPath&quot;&gt;SVG elements&lt;/a&gt;, the HTML canvas API doesn’t offer an out-of-the-box solution for drawing text along predefined paths such as circles or segments thereof. Left to our own devices, we define a bespoke function &lt;code&gt;drawLabel(…)&lt;/code&gt; that operates in the fashion of &lt;a href=&quot;https://en.wikipedia.org/wiki/Turtle_graphics&quot;&gt;turtle graphics&lt;/a&gt;:&lt;/p&gt;
            &lt;figure&gt;
              &lt;pre&gt;&lt;code class=&quot;tsx language-tsx&quot;&gt;export const drawLabel = (
  context: CanvasRenderingContext2D,
  label: string,
  size: number,
  radius: number,
  angle: number,
  color: string
) =&amp;gt; {
  label = label.length === 0 ? &quot;............&quot; : label;

  let len = label.length,
    glyph,
    letterAngle,
    totalWidth = 0,
    totalAngle = 0,
    letterSpacing = 0.65;

  context.save();
  context.textAlign = &quot;center&quot;;
  context.font = [ ... ];
  context.fillStyle = color;
  context.translate(size / 2, size / 2);
  context.rotate(angle + Math.PI / 2);

  totalWidth = label
    .split(&quot;&quot;)
    .map((char) =&amp;gt; context.measureText(char).width)
    .reduce((a, b) =&amp;gt; a + b, 0);
  totalWidth = 2 * letterSpacing * totalWidth;
  totalAngle = totalWidth / radius;
  context.rotate(-totalAngle / 2);

  for (var n = 0; n &amp;lt; len; n++) {
    glyph = label[n];
    let letterWidth = context.measureText(glyph).width;
    letterAngle = letterSpacing * (letterWidth / radius);

    context.rotate(letterAngle);
    context.save();

    context.translate(0, -radius);
    context.fillText(glyph, 0, 0);
    context.restore();

    context.rotate(letterAngle);
  }
  context.restore();
};
&lt;/code&gt;&lt;/pre&gt;
              &lt;figcaption&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
          &lt;p&gt;The overall idea is to draw a single line of the specified label text by printing one character at a time to the canvas. In order to keep the text centered at all times (and lengths), we first need to determine the total width of the label, including potential letter spacing. Using this information, we can offset the beginning of our label by half of its length to get to the desired center alignment. The corresponding &lt;code&gt;fillText(…)&lt;/code&gt; calls for each individual character are then interspersed with rotations and translations of the canvas origin along the text direction.&lt;/p&gt;&lt;p&gt;As we are successively drawing on top of the graphics already on the canvas, it is important to reset the canvas context to its state from before the translation of the origin, using &lt;code&gt;context.save()&lt;/code&gt; and &lt;code&gt;context.restore()&lt;/code&gt;.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Drawing the Donut&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;The colored gradient border (”Donut”) offers a visually pleasing way to separate the label text from the uploaded background image. The user can opt against this border altogether by setting the width to zero. Additionally, both the gradient center and its base color can be customized.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;//images.ctfassets.net/54dnxp2417nl/4iQrOgK4ZN3D5aRK8WzU2Q/08783ff902cc2c8097616c40c0b54d11/position.png&quot; alt=&quot;&quot;/&gt;&lt;figcaption&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;The corresponding function &lt;code&gt;drawDonut(…)&lt;/code&gt; thus takes various arguments:&lt;/p&gt;
            &lt;figure&gt;
              &lt;pre&gt;&lt;code class=&quot;tsx language-tsx&quot;&gt;export const drawDonut = (
  context: CanvasRenderingContext2D,
  size: number,
  donutStroke: number,
  angle: number,
  color: string
) =&amp;gt; {
  var gradient = context.createLinearGradient(0, 0, size, 0);
  gradient.addColorStop(0, `${color}FF`);
  gradient.addColorStop(0.6, `${color}09`);
  gradient.addColorStop(0.75, `${color}00`);

  context.save();

  context.translate(size / 2, size / 2);
  context.rotate(angle);
  context.translate(-size / 2, -size / 2);

  context.lineWidth = donutStroke * 2;
  context.strokeStyle = gradient;
  context.beginPath();
  context.arc(size / 2, size / 2, size / 2, 0, Math.PI * 2);
  context.stroke();

  context.restore();
};
&lt;/code&gt;&lt;/pre&gt;
              &lt;figcaption&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
          &lt;p&gt;Given that the outline stroke of any canvas element is aligned to the center of the referring path, we double the user-specified stroke width and draw the path along the circular border of the canvas. This way, half of the stroke’s effective width will be on the inside of our canvas, while the other half will be clipped away by a &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/API/CanvasRenderingContext2D/clip&quot;&gt;clipping path&lt;/a&gt; defined inside the &lt;code&gt;drawImage(…)&lt;/code&gt; function:&lt;/p&gt;
            &lt;figure&gt;
              &lt;pre&gt;&lt;code class=&quot;tsx language-tsx&quot;&gt;export const drawImage = ([ ... ]) =&amp;gt; {

    [ ... ]

  // crop to circle
  context.beginPath();
  context.arc(
    context.canvas.width / 2,
    context.canvas.height / 2,
    context.canvas.width / 2,
    0,
    Math.PI * 2
  );
  context.clip();

  [ ... ]

};
&lt;/code&gt;&lt;/pre&gt;
              &lt;figcaption&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
          &lt;p&gt;Since &lt;code&gt;drawImage(…)&lt;/code&gt; is always the first function to be called in our &lt;code&gt;useEffect()&lt;/code&gt; hook, the clipping mask stays in place for all subsequent canvas manipulations. Hence, note the absence of &lt;code&gt;context.save()&lt;/code&gt; and &lt;code&gt;context.restore()&lt;/code&gt; in this function.&lt;/p&gt;&lt;p&gt;In retrospect, building a canvas-centered app subject to frequent re-drawing greatly benefits from the React &lt;a href=&quot;https://reactjs.org/docs/context.html&quot;&gt;Context&lt;/a&gt; API, as it allows developers to selectively expose parameters to multiple components. Consequently, individual re-renders are mostly limited to components that either consume or modify values influencing the canvas content. In this rather small application, essentially all components share the same set of variables, so the Context Provider encases all of them. When it comes to projects of greater scope, however, the positive impact that using Context has on the overall performance grows more tangible.&lt;/p&gt;&lt;p&gt;Some parts of the code snippets have been omitted for brevity by means of &lt;code&gt;[ ... ]&lt;/code&gt;. If you wish to take a closer look at these details as well as other components and UI elements touched upon in this post, you can find the full source code &lt;a href=&quot;https://github.com/satellytes/badge-forge&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Relaunch FC Bayern Website]]></title><description><![CDATA[Our approach to develop a clear and modern concept and design for the web appearance of the FC Bayern - the legendary German champion.]]></description><link>https://satellytes.com/blog/post/fc-bayern-website-frontend-relaunched-by-satellytes/</link><guid isPermaLink="false">https://satellytes.com/blog/post/fc-bayern-website-frontend-relaunched-by-satellytes/</guid><pubDate>Wed, 27 Apr 2022 00:00:00 GMT</pubDate><content:encoded>&lt;img src=&quot;https://satellytes.com/_gatsby/image/4476315e28d424b577720118f42aa355/4be445bf02c55418e404abd8f2a1a674/fcb-case-1.jpg?eu=e863a43b16a5134773dec324826dadac6f55104c845280fc617db741c2068332e6a216d4ff9fd161ff35b0fb8a9db53a88f4449a75e555709e3f0a6ae9d58571ea24b20e19ceedd8c638a47131054123749b0f92a6eb1d6d022c14594abc728d18557bc74cbc0d45ecf29130931ee14d5e547162b108f93a92358da773764f3cb09b78c8278a4863b56d80736f830b41341602f763a44c59fd421b820f412a6cb98f4ed52816c7642fde5886dbc3afdcb01cb880c4f32e1407d2df9f1bcebf9a5b5ab04f778dddf1dc56196e1b197715b825b0bc038396066946d265d45628ead32378dc1ac38a48f9184333ea&amp;amp;a=w%3D1440%26h%3D760%26fm%3Djpg%26q%3D75&amp;amp;cd=2022-08-31T08%3A08%3A52.200Z&quot; alt=&quot;&quot;/&gt; &lt;p&gt;When you think of Munich, you think of the Oktoberfest, the Frauenkirche and, of course, FC Bayern München. The legendary German champion is the biggest sports club in the world and, in terms of football, a guarantor of absolute top class. To prevail at the top level nationally and internationally over decades only works if you move forward and think ahead. In today&amp;#39;s international competition, this no longer applies only on the pitch, but above all in the digital world.&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.fcbayern.com&quot;&gt;www.fcbayern.com&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;div&gt;&lt;div&gt;&lt;h3&gt;Team Size&lt;/h3&gt;&lt;p&gt;6 people&lt;/p&gt;&lt;br/&gt;&lt;/div&gt;&lt;div&gt;&lt;h3&gt;Start&lt;/h3&gt;&lt;p&gt;December 2018&lt;/p&gt;&lt;br/&gt;&lt;/div&gt;&lt;div&gt;&lt;h3&gt;End&lt;/h3&gt;&lt;p&gt;Ongoing&lt;/p&gt;&lt;br/&gt;&lt;/div&gt;&lt;/div&gt;&lt;h2&gt;The Mission&lt;/h2&gt;&lt;p&gt;In the course of the relaunch of the FC Bayern München website &lt;a href=&quot;https://fcbayern.com&quot;&gt;www.fcbayern.com&lt;/a&gt;, we were commissioned to develop a clear and modern concept and design. We were also awarded the contract for the implementation of the frontend while retaining the existing content management system (CMS).&lt;/p&gt;&lt;p&gt;Technologically, we were faced with the exciting challenge of providing a modern and expandable frontend platform that would meet future requirements and be available to users at all times.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;//images.ctfassets.net/54dnxp2417nl/7fD5qST2ogdoTXlhbYX1QS/b5fc64b5f51d6fd6125f962e9d7e2fbc/fcb-case-2-hq.png&quot; alt=&quot;&quot;/&gt;&lt;figcaption&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;&lt;b&gt;Our Approach&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Like every complex project, we started with an inventory of all applications and platforms that play a role in the club’s web presence. We also benchmarked the websites of other national and international sports clubs. Our goal: to make the FC Bayern site the best football club site in the world.&lt;/p&gt;&lt;p&gt;Our UX team analysed all the features and funnels of the original FC Bayern website before prioritising and restructuring them based on insights from interviews and analytics.&lt;/p&gt;&lt;p&gt;The development was carried out in close cooperation with all stakeholders according to the mobile-first approach. In the process, the website was optimised for the most important use cases so that fans can access the content relevant to them even more quickly and intuitively.&lt;/p&gt;&lt;p&gt;For a uniform look &amp;amp; feel, we created a design system that keeps all components and patterns as a “single source of truth” always up-to-date and available for all future digital products of FC Bayern. To guarantee the correct use and implementation of the innovations in the future, we provided Brand Guidelines.&lt;/p&gt;&lt;p&gt;Technologically, we worked with the headless CMS approach to be able to fulfil the requirement of a new frontend while keeping the existing CMS – without working into someone else’s project. The strict separation of CMS and frontend allows the efficient implementation of requirements that would be impossible or very expensive in classic CMS environments. The theoretical independence of CMS and frontend also enables the straightforward connection of additional channels to support FC Bayern München’s omnichannel/multichannel strategy.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;//images.ctfassets.net/54dnxp2417nl/2PcsybkXWmv64O57URk8yp/675bfc2dd04aada356737088f0b40510/fcb-case-3.jpg&quot; alt=&quot;&quot;/&gt;&lt;figcaption&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;&lt;b&gt;Technical Contribution&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;When choosing our technical basis, we weighed the use of React (without a framework), Next.js and Gatsby.js against each other as part of our detailed benchmarking process: the enormous number of static pages that will remain unchanged in the future ultimately convinced us to go with Gatsby.js. This framework allowed us to reduce the complexity of hosting while keeping React as the standard. Despite the focus on static content, this allowed us to provide dynamic components to implement content – such as breaking news, live tickers or real-time results.&lt;/p&gt;&lt;p&gt; &lt;/p&gt;&lt;p&gt;Other technological features that we added in the course of the project:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Implementation of a well-tested component UI library.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;The website was developed with the requirements of mobile devices in mind and is fully responsive in three different formats – including optimised images for every screen size.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;The development of a powerful theming system with light/dark support. Theming allows us to efficiently and cost-effectively implement changing colour schemes required by the various teams and companies within the FC Bayern universe.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Our more than 2,000 unit tests strengthened confidence in the entire project and the stability of the infrastructure.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Static generation of almost 100,000 HTML pages including fast, incremental updates.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Barrier-free accessibility according to WCAG 2.0 was naturally something we took very seriously. That is why we have implemented all components of the FC Bayern website in such a way that they can be used by everyone.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Our CI/CD is based on Bitbucket, Bamboo and Jenkins and is fully integrated into the existing on-site IT infrastructure. In addition to the regular deployments, we generate Docker-based preview links for the efficient coordination of code changes with designers or within peer reviews.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Compared to classic “coupled” CMS’s, headless CMS’s have the disadvantage that the preview function is usually not included. We have developed a lightweight and fast solution that automatically synchronises changes in the CMS to a preview server via Webhooks and visually prepares the content for the editors.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;figure&gt;&lt;img src=&quot;//images.ctfassets.net/54dnxp2417nl/20d5gp34QyvhYkhcu1u5Ey/b98180229bf05694c07dc418ead47818/fcb-case-4.jpg&quot; alt=&quot;&quot;/&gt;&lt;figcaption&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;Summary&lt;/h2&gt;&lt;p&gt;With this successful relaunch, Satellytes has designed and implemented a modern, fast and user-friendly website for FC Bayern within two years. We would like to thank FC Bayern München for the trust they have placed in us and for the great cooperation. &lt;/p&gt;&lt;p&gt;Are you planning your next digital project? Please contact us, we are happy to help: 
Eric Singhartinger, &lt;a href=&quot;mailto:eric.singhartinger@satellytes.com&quot;&gt;eric.singhartinger@satellytes.com&lt;/a&gt; &lt;/p&gt;</content:encoded></item><item><title><![CDATA[We work remotely!?]]></title><description><![CDATA[Vollzeit im Office? Nur noch Remote? Oder ein bisschen von beidem? Wir haben die Geschäftsführer von Satellytes gefragt.]]></description><link>https://satellytes.com/blog/post/we-work-remotely/</link><guid isPermaLink="false">https://satellytes.com/blog/post/we-work-remotely/</guid><pubDate>Thu, 24 Mar 2022 00:00:00 GMT</pubDate><content:encoded>&lt;img src=&quot;https://satellytes.com/_gatsby/image/c2d2d94e574b3e213094ae2c11bb5f62/4be445bf02c55418e404abd8f2a1a674/return-to-office-interview-header.jpg?eu=ef66f23c14a1121073d89323d134f7ad6d00131ed406dafe3774ba10c20b8630b7a51584ab9ed060fc6ebaf6d790e36bd7a744c826e50279cc3c046aba818426bc71ef594e95e0dbc63ef82d36004225749d0ac6a2b91b690170031e5bfb79c404592f9e4fbf1808ecb3c035d908b30c1e187933f042f56dc462c1b27b2a0a7fae846dd14cb65f689f659b0b76bd38501e2652e568db7159f042188f0e4d622aba891cd5751f8d600df34eb4dee8afef9a58b98d8ea468711bfbba8b4e95afda0245f0173f86ddae81534f274b136212ff30edeb11cfce503b438174ce0877eb&amp;amp;a=w%3D1440%26h%3D760%26fm%3Djpg%26q%3D75&amp;amp;cd=2022-03-25T10%3A53%3A12.521Z&quot; alt=&quot;&quot;/&gt; &lt;p&gt;Mit dem Ausklingen der verpflichtenden Corona-Maßnahmen endet in vielen Unternehmen die Home-Office-Pflicht – auch bei Satellytes. Und so freuen wir uns das neue Büro wieder für alle Mitarbeiter:innen öffnen zu können.&lt;/p&gt;&lt;p&gt;Jedoch haben die letzten beiden Jahre bei vielen Angestellten ein Umdenken in der Einstellung zum Verhältnis von Büroarbeit zu Home-Office bewirkt. Viele stellen sich die Frage: Muss ich bald wieder regelmäßig ins Büro oder kann ich weiter remote arbeiten?&lt;/p&gt;&lt;p&gt;Wir dachten, das ist genau der richtige Zeitpunkt unsere Geschäftsführer mal zu fragen: Wie steht ihr dazu? Do we work remotely? Wie wird die Zusammenarbeit nach Ende der Corona-Einschränkungen bei Satellytes aussehen?&lt;/p&gt;&lt;p&gt;&lt;b&gt;Fangen wir mal mit euch persönlich an: Wie plant ihr zukünftig euren eigenen Arbeitsalltag zu gestalten? Werdet ihr wieder täglich vom Büro aus arbeiten? Wird es Remote-Anteile geben?&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;Gholam:&lt;/b&gt; Ich plane wieder relativ häufig, wenn nicht sogar täglich, vom Office aus zu arbeiten. Ich habe festgestellt, dass meine Effektivität abnimmt, je länger ich gezwungen bin im Home-Office zu arbeiten. Mir hilft der regelmäßige Wechsel ins Office enorm, mich auf die Arbeit einzustellen. Es wird aber kein typischer Arbeitstag mit regulären Zeiten werden – das war es ja vor der Pandemie auch nicht. Mir war es schon immer wichtig, meine Arbeitszeiten im Einklang mit meiner Familie zu gestalten. Wenn ich z.B. meinen Sohn früh morgens in die Schule gebracht habe, hat mein Bürotag auch erst mal um 10 Uhr angefangen. Das war dann halt so. Und das war auch gut so.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Eric:&lt;/b&gt; Ich sehe das ganz ähnlich: Auch ich werde wieder größtenteils vom Büro aus arbeiten. Es wird aber auch Ausnahmen geben: Wenn ich mich bspw. auf ein komplexes, operatives Thema konzentrieren muss, werde ich auch in Zukunft von zu Hause aus arbeiten. Die letzten beiden Jahre haben mir gezeigt, dass es sehr effektiv sein kann Slack und Telefon für ein paar Stunden abzuschalten. Dieses &amp;quot;von der Außenwelt abschotten&amp;quot; ist im Büro natürlich nicht möglich, aber ich freue mich trotzdem sehr, wieder enger mit den Kolleg:innen im Büro arbeiten zu können.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Welche Vorteile seht ihr für euch, wenn ihr aus dem Büro arbeitet?&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;Gholam:&lt;/b&gt; Das Office bietet viele Kommunikationsformen an, die man nur sehr schwer remote nachbilden kann. Wenn ich z.B. jemanden, mit dem ich in letzter Zeit eher wenig Kontakt hatte, an der Kaffeetheke treffe, frage ich direkt mal nach: “Wie geht’s dir? Wo kann ich dir helfen?” So bekomme ich ein besseres Gefühl, wie es unseren Kolleg:innen geht. Das ist mir schwer gefallen remote in derselben Qualität abzubilden. Ich will auch sicherstellen, dass ich für alle bestmöglich verfügbar bin. Manche ziehen es auch aktuell vor täglich oder teilweise vom Büro aus zu arbeiten. Da sehe ich es als meine Pflicht an, dass ich auch für sie auf ihrem bevorzugten Kanal erreichbar bin.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Die letzten beiden Jahre waren ja sehr herausfordernd. Auch unsere Kunden haben unter den Einschränkungen gelitten, die sich dann natürlich auch auf uns ausgewirkt haben. Trotzdem haben wir das als Mitarbeiter:innen kaum gespürt. Wie seht ihr das selbst? Wie hat sich Satellytes in der Zeit entwickelt?&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;Eric:&lt;/b&gt; Trotz der Umstände, waren die beiden Jahre für uns als Firma positiv. Wir stehen finanziell solide da. Aber ja, wir haben es auch an einigen Stellen gespürt, dass es Einschränkungen in den Budgets unserer Kunden gab. Aber dennoch hat uns die Zeit gut getan. Wir konnten unsere Projekte und Kundenbeziehungen konsolidieren und haben uns auf persönlicher Ebene, aber auch als Firma, weiterentwickelt. Noch wichtiger war aber, dass wir es geschafft haben uns an die neuen Bedingungen anzupassen um damit den Kunden zu zeigen, dass wir auch unter diesen neuen Voraussetzungen sehr gute Ergebnisse liefern können.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Gholam:&lt;/b&gt; Ich fand die letzten beiden Jahre überragend. Wir haben als Firma und in den Teams sehr gut funktioniert. Wir haben alle unserer Projekte gestemmt und auch die Phasen, in denen in der Industrie große Unsicherheit bestanden hat, gut gemeistert. Auch in der Phase Anfang 2020 wo das Auftragsvolumen erst einmal deutlich eingebrochen ist, konnten wir relativ schnell wieder zu 100% Auslastung zurückkehren. Das lag vor allem auch an unseren Kolleg:innen, die auf die Situation gut reagiert haben. Top! Unser Konzept bei der Einstellung von Mitarbeiter:innen hat sich gerade in dieser Situation als absolut richtig erwiesen. Gerade weil wir durchweg Leute in der Firma haben, die eigenverantwortlich arbeiten, die über den Tellerrand hinaus schauen können, die mitdenken und aus eigenem Antrieb Anderen helfen, haben wir die herausfordernde Situation der letzten beiden Jahr so gut bewältigen können.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Wie produktiv war die Arbeit vom Home-Office aus? War das für euch befriedigend?&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;Eric:&lt;/b&gt; Die Produktivität in Bezug auf die Arbeit war sicher sehr gut. Aber befriedigend? Für mich persönlich war das teilweise total unbefriedigend … Weil man bei all den Erfolgen, die wir als Firma feiern konnten, nie die Gelegenheit hatten, im Team mal echte High-Fives zu verteilen und gebührend zu feiern (lacht).&lt;/p&gt;&lt;p&gt;&lt;b&gt;Gholam:&lt;/b&gt; Ich empfand die beiden Jahre auch sehr produktiv. Das liegt natürlich daran, dass der Anteil am produktiven Output im Verhältnis zur Arbeitszeit gestiegen ist. Einfach weil der Coffee-Talk häufiger weggefallen ist und man sich voll auf die Arbeit konzentrieren konnte. Ob das für den Einzelnen befriedigend war, kann man so eindeutig nicht beantworten. Auf der einen Seite war die Gesamtsituation natürlich sehr belastend. Auf der anderen Seite hat sich auch die Perspektive auf die Arbeit, auf Work-Life-Balance, auf Remote-Arbeit zum Besseren verändert.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Eric:&lt;/b&gt; Insgesamt würde ich die Frage ob “befriedigend” so auch nicht beantworten können. Die Jahre waren eben einfach herausfordernd. Man konnte sich nicht mehr auf bewährte Prozesse verlassen, sondern musste neue definieren. Das ist uns aber recht gut gelungen.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Neben der Frage, wie produktiv wir arbeiten, gibt es ja auch andere Faktoren, die ausmachen, ob und wie wir als Team gut funktionieren. Wie habt ihr die Entwicklung der Firmenkultur unter diesen Voraussetzungen empfunden? Das war doch sicher auch eine ganz spezielle Herausforderung?&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;Gholam:&lt;/b&gt; In der aktuellen Teamzusammensetzung war unsere Vorstellung von Kultur schon so weit verinnerlicht, dass diese beim Wechsel ins Home-Office einfach erhalten und weitergelebt werden konnte. Dabei geht es mir vor allem darum wie wir im Team miteinander umgegangen sind. Das hat auch remote sehr gut geklappt. Nur mal als Beispiel: Fabian hat sich bereit erklärt die Weihnachtsfeier zu planen und Jesús hat sich die Onboarding-Prozesse vorgenommen und optimiert. Das musste nicht von uns vorgegeben werden, sondern ist von den Kolleg:innen eigenverantwortlich vorangetrieben worden.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;//images.ctfassets.net/54dnxp2417nl/KvkwrGOyYlBrAYEJMRQJI/3e452f609957099295e756a58c543a0d/return-to-office-interview-christmas-party.png&quot; alt=&quot;Virtuelle Weihnachtsfeier bei Satellytes. Danke an Georgios und Fabian für die Organisation!&quot;/&gt;&lt;figcaption&gt;Virtuelle Weihnachtsfeier bei Satellytes. Danke an Georgios und Fabian für die Organisation!&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;Eric:&lt;/b&gt; Klar auf der zwischenmenschlichen Ebene oder innerhalb der Teams hat das weiterhin sehr gut funktioniert. Die Teams haben schnell gemerkt, dass sie sich die Zeit nehmen müssen und auch dürfen, auch mal über Dinge außerhalb der Arbeit zu plaudern. Aber trotzdem habe ich persönlich vieles vermisst, was vor Corona selbstverständlich war. Man trifft sich zwar immer noch häufig in Zoom-Meetings, aber da hat man immer eine Agenda. Der kurze Small-Talk am Anfang und am Ende ist für mich kein Ersatz für die längeren Zusammentreffen, die im Büroalltag ständig zustande kommen. Vor Corona ist es schon regelmäßig passiert, dass man sich mal in der Küche über den Weg gelaufen ist und sich dann auch mal länger über irgendein Casual-Thema unterhalten hat. Außerdem sind wir auch ständig gemeinsam zum Mittagessen gegangen. Dabei hat man mehr Zeit gefunden über Dinge zu reden, die über die aktuellen Projektthemen hinausgehen. Und genau diese Feinheiten und Hintergründe braucht es, damit wir auf unsere Kolleg:innen richtig eingehen und bei Bedarf helfen können.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Die Home-Office-Pflicht ist ja vor kurzem ausgelaufen. Trotzdem überlegen viele, wie sie zukünftig arbeiten wollen. Welche Gründe seht ihr, warum die Leute vom Büro aus arbeiten wollen?&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;Gholam:&lt;/b&gt; Die Motivation dazu ist meiner Meinung nach sehr von den individuellen Vorlieben und Voraussetzungen eines jedes Einzelnen abhängig. Wir spüren zum Beispiel, dass viele auch einfach Lust darauf haben, ihre Kolleg:innen wieder häufiger zu sehen um unmittelbarer zusammenarbeiten oder auch mal nur gemeinsam Mittag essen gehen zu können. Man sieht auch, dass nicht bei allen der Platz oder das Umfeld gegeben ist um entspannt von zu Hause aus arbeiten zu können. Wenn ich in meiner Wohnung wenig Platz habe und jeden Mittag die Kinder von der Schule kommen und beschäftigt werden wollen, bin ich wahrscheinlich auch einfach froh darüber einen ruhigen Ort – in dem Fall das Büro – zu haben, von dem aus ich konzentriert arbeiten kann.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Welche konkreten Vorteile seht ihr darin, wenn wieder mehr Kolleg:innen häufiger gemeinsam vom Büro aus arbeiten?&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;Gholam:&lt;/b&gt; Mein Essen am Montag! Das ist ein klarer Vorteil, wenn ich Montags für alle koche (lacht). In Zeiten von Corona mussten wir das leider pausieren. Aber das plane ich auf jeden Fall wieder aufzunehmen.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Eric:&lt;/b&gt; Ja, die Lasagne war genial! Dafür habe ich sogar den Schnitt im Daumen in Kauf genommen (lacht). Das war eine tolle Sache. Aber im Ernst: Ich glaube, dass das komplett vom Typ abhängig ist. Manche Leute wollen auch wieder mehr vom Büro aus arbeiten, weil sie wieder regelmäßig den Austausch mit ihren Kolleg:innen haben wollen. Ich glaube tatsächlich, dass die Social Benefits von zentraler Bedeutung sind.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;//images.ctfassets.net/54dnxp2417nl/6My0fb6gkQvJJ10LwfYUx5/36f1eb762c3c2881ca03dabee30127fe/return-to-office-interview-lasagna.jpg&quot; alt=&quot;Ja, es gab sie wirklich, die Lasagne!&quot;/&gt;&lt;figcaption&gt;Ja, es gab sie wirklich, die Lasagne!&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;Gholam:&lt;/b&gt; Ich stimme da voll mit Eric überein. Ich glaube tatsächlich, dass der Spaß bei der gemeinsamen Zusammenarbeit eine wichtige Voraussetzung dafür war, dass es auch remote so gut geklappt hat. Deswegen sehe ich es als elementar wichtig an, dass man sich auch zukünftig wieder trifft. Dann habe ich auch keine Sorgen, dass die Zusammenarbeit anschließend unabhängig vom Ort gut funktioniert. Klar, kann das auch bedeuten, dass vom Büro aus nicht so effizient gearbeitet wird, als dies im Home-Office der Fall wäre. Aber ich bin bereit diesen Effizienzverlust in Kauf zu nehmen, wenn es bedeutet, dass wir als Team enger zusammen rücken und langfristig besser und zufriedener zusammen arbeiten können.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Eric:&lt;/b&gt; Darüber hinaus hilft natürlich die räumliche Nähe bei der Zusammenarbeit zwischen den Disziplinen. Wenn ich z.B. Felix auf dem Weg in die Küche sehe, fällt es mir wahrscheinlich eher mal ein zu fragen “Hey, brauchst du eigentlich noch eine Design Review? Kann ich dir irgendwie helfen?” Und diese ganzen bilateralen Kleinigkeiten abseits von Terminen lassen so ein schönes Gefühl von Fürsorge entstehen, die nicht nur beruflich, sondern auch privat ein Gemeinsamkeitsgefühl und eine Zusammengehörigkeit entstehen lassen. Davon profitiert jeder. Und wenn man zusammen im Office arbeitet, hat man auch mehr das Gefühl, dass um einen herum was passiert – wie in einem Bienenstock, da hört und sieht und spürt man dieses motivierende Summen.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Habt ihr konkrete Ideen, was ihr tun wollt um die Leute davon zu überzeugen das Home-Office gegen das Büro auszutauschen?&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;Eric:&lt;/b&gt; Wir haben in den letzten Monaten viel Energie in unser Office investiert. Schallschutz, gutes Licht, neue Räume mit Rückzugsmöglichkeiten, damit man in jeder Situation und Konstellation gut arbeiten kann. Und neben den regulären Arbeitsplätzen gibt es jetzt auch mehr coole Bereiche mit Sesseln und Poufs und ein paar Konsolen und Spiele, wo man auch mal entspannen und einen guten Kaffee genießen kann.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;//images.ctfassets.net/54dnxp2417nl/5FUGj8mqFlb0eMUWN3qwcN/c1d83b3e64574c743036d06ba09068b6/return-to-office-interview-office.jpg&quot; alt=&quot;Eric Singhartinger (links) und Gholam Abdol (rechts)&quot;/&gt;&lt;figcaption&gt;Eric Singhartinger (links) und Gholam Abdol (rechts)&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Unsere Kolleg:innen sollen sich da einfach wohlfühlen, sie verbringen ja schließlich fast die Hälfte ihrer wachen Zeit im Office. Deswegen hören wir auch auf ihre Ideen und Bedürfnisse. Wenn Pavel zum Beispiel ein neuer Pizzaschneider hilft eine noch bessere Zeit beim Mittagessen im Büro zu haben, wird einer gekauft (lacht).&lt;/p&gt;&lt;p&gt;&lt;b&gt;Gholam:&lt;/b&gt; Ganz generell schreiben wir den Community-Gedanken ganz groß. Deswegen wird es auch in Zukunft gemeinsame Events geben. Zum Beispiel organisiert Georgios gerade ein virtuelles Exit the Room. Es gab auch schon Brettspielabende mit neuen, spannenden Spielen. So können die Leute, die das möchten, das Office auch als mehr als nur als Arbeitsort erfahren. Das ist natürlich alles freiwillig, aber das Feedback dazu war bisher sehr gut. Darüber hinaus planen wir zukünftig regelmäßig sogenannte “Company Space Days”. Das werden Tage sein, wo man sich gemeinsam mit einem Thema beschäftigt, das einmal nichts mit der Arbeit zu tun hat. Das kann z.B. sein, dass man gemeinsam einen R2D2 baut (beide lachen) … Voraussetzung ist, dass es eine Idee ist, die Abwechslung in den Büroalltag bringt. Das soll gezielt nichts mit den Themen und Technologien zu tun haben, mit denen wir tagtäglich arbeiten.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Welche Gründe glaubt ihr haben eure Kolleg:innen, trotzdem weiter remote arbeiten wollen?&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;Eric:&lt;/b&gt; Ruhe. Zu Hause fällt es vielen einfacher, in den “Tunnel” zu kommen. Ich glaube aber auch, dass es einfach Bequemlichkeit ist bzw. “Convenience”, hört sich schöner an (lacht). Ich muss mich nicht erst morgens duschen, waschen, anziehen, fertig machen und in die Arbeit commuten.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Gholam:&lt;/b&gt; (lacht) Jetzt überträgst du von dir auf andere!&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;//images.ctfassets.net/54dnxp2417nl/1TUqe1SYHKi4t4ZveKfIfP/ec17fe7b5495d37fd0dd62dadb5306a0/return-to-office-interview-felix.png&quot; alt=&quot;Auch virtuell wurde bei Satellytes stets auf ein professionelles Erscheiungsbild geachtet!&quot;/&gt;&lt;figcaption&gt;Auch virtuell wurde bei Satellytes stets auf ein professionelles Erscheiungsbild geachtet!&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;Eric:&lt;/b&gt; Nein, aber mal ehrlich ... Ich kann morgens direkt den Rechner aufklappen und bin voll im Fokus und kann dann Pause und meine Morgenroutine machen, wenn die Konzentration das erste Mal nachlässt. Wenn ich vom Büro aus arbeite, ist mein Morgen weniger flexibel planbar. Allgemeiner gefasst, kann man sagen: Die Remote-Arbeit erlaubt jedem, die eigene Routine zu finden, die am besten geeignet ist um gut und effizient arbeiten zu können.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Gholam:&lt;/b&gt; Darüber hinaus glaube ich, dass vor allem die freie Ortswahl ein Grund ist, dass die Leute Gefallen an der Remote-Arbeit gefunden haben. Arthur z.B. hatte vor der Pandemie jeden Tag 70 Kilometer zur Arbeit gehabt. Das sind bis zu zwei Stunden, die täglich verloren gehen. Nach zwei Jahren funktionierendem Home-Office, stellt sich dann natürlich die Frage: Ist das wirklich jeden Tag nötig? Damit einher geht die bessere Vereinbarkeit von Familie und Beruf. Ich kann mich noch an Projekte erinnern, wo es Pflicht war spätestens um 9:00 Uhr vor Ort zu sein und in die Tasten zu hauen. Zu der Zeit, musste ich jeden Morgen vor der Arbeit meinen Sohn zur Kita bringen. Das hieß morgens mit S-Bahn, Bus und zu Fuß von Milbertshofen im Norden nach Untermenzingen in die Kita. Danach dann mit Bus und S-Bahn zur Arbeit. Das war schon ein brutaler Stress, den ich jeden Morgen hatte. Praktisch hieß das, dass ich spätestens um 7:00 Uhr das Haus verlassen musste, damit ich auch garantiert um 9:00 Uhr pünktlich im Büro sein konnte. Wenn so ein Zwang wegfällt, ist man automatisch entspannter und kann mehr Energie in die Arbeit investieren.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Was plant ihr für die “Rückkehr zum Arbeitsplatz”? Wird es Vorgaben geben, was den Arbeitsort angeht?&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;Gholam:&lt;/b&gt; Das werden wir unseren Kolleg:innen komplett frei stellen. Wir wollen da keine festen Vorgaben machen. Von Vollzeit-Remote, Vollzeit-Büro und allem was dazwischen denkbar ist, werden wir allen die Freiheit geben, ihren Arbeitsrhythmus so zu planen, dass sie gut arbeiten können.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Eric:&lt;/b&gt; Genau. Als Ausnahme sehe ich persönlich Senior- und Manager-Pflichten. Sobald juniorige Mitarbeiter betreut werden, muss sichergestellt sein, dass das bestmöglich klappt. Wenn das rein remote funktioniert – super. Falls nicht, hoffen wir, dass sie einen gemeinsamen Ort finden, an dem zumindest zeitweise Seite an Seite gearbeitet werden kann. Gerade Berufseinsteiger profitieren enorm davon, wenn sie neben erfahrenen Kolleg:innen arbeiten. Sie können so schneller Fragen stellen und Hilfe bekommen. Davon kann ihre Entwicklung sehr profitieren. Wenn du Verantwortung für deine Kolleg:innen hast, musst du sicherstellen, dass das für sie bestmöglich funktioniert. Aber ich glaube, das kommt von ganz alleine. Es ist doch wahnsinnig befriedigend, wenn man den Lerneffekt beim jemandem unmittelbar mitbekommt und sieht wie sie/er sich weiterentwickelt. Insgesamt vertrauen wir, was die Frage angeht, ganz auf unsere Mitarbeiter. Wir helfen gerne mit Rat, aber geben nichts vor. Wichtig ist nur, dass es funktioniert.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Klingt gut. Wie wirkt sich das zukünftig auf die Besetzung offener Stellen aus? Von Vollzeit-Office bis Vollzeit-Remote alles möglich?&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;Gholam:&lt;/b&gt; Definitiv, ja. Du warst ja der erste Angestellte, bei dem bei der Einstellung schon feststand, dass du Vollzeit-Remote von Fulda aus arbeiten wirst. Diesen Monat konnten wir Julian als zweiten Vollzeit-Remote für uns gewinnen. Das funktioniert bisher bestens. Deswegen suchen wir jetzt deutschlandweit nach Mitarbeiter:innen, die nicht in München leben und auch nicht für die Arbeit dorthin umziehen wollen.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Danke, Eric und Gholam für den Einblick in eure Erfahrungen und Erwartungen zur Corona- und Return-to-Office-Situation.&lt;/b&gt; &lt;b&gt;Ich persönlich freue mich schon sehr darauf euch alle bald wieder persönlich im neuen Office sehen zu können!&lt;/b&gt; &lt;b&gt;Dafür fahre ich auch gerne mal wieder nach München!&lt;/b&gt;&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Four ways to improve collaboration in your team]]></title><description><![CDATA[This article depicts a handful of on-field practices around collaborative work, that will either suit you or inspire you to find your own ways.]]></description><link>https://satellytes.com/blog/post/four-ways-to-improve-collaboration-in-your-team/</link><guid isPermaLink="false">https://satellytes.com/blog/post/four-ways-to-improve-collaboration-in-your-team/</guid><pubDate>Wed, 02 Mar 2022 00:00:00 GMT</pubDate><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://satellytes.com/_gatsby/image/7f0ac9406865d8b2239ff1bd64fe9a2d/4be445bf02c55418e404abd8f2a1a674/group-table.jpg?eu=ba69a03840f31414218a9220d862f9fd6e0048488403dbfe352cb916c2518163b2a54487f99fd365a535bcf58599b23bd7a2139873e9567ccd390a3cbd858625e275e00949c4eddac66fa52160034d7322cd08c3f5e84c3c597b455d49bd79835f44328c12f5444fe2a6c131d955b50c0b576425e119b377ce69cded7c2a5f26b89870d339d44b6efd39ab1a38b40e5003143fb629b36548f15e65da21173333e9834e80754bdc660aa34fe0dbbaf5b8c80aedd686a839711ca9a39f18d7beca430ff617679996bc8952466f0c176610&amp;amp;a=w%3D1440%26h%3D760%26fm%3Djpg%26q%3D75&amp;amp;cd=2022-03-18T13%3A49%3A16.890Z&quot; alt=&quot;&quot;/&gt;&lt;figcaption&gt;&lt;a href=&quot;https://unsplash.com/photos/SYTO3xs06fU&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Image by Marvin Meyer&lt;/a&gt;&lt;/figcaption&gt;&lt;/figure&gt; &lt;p&gt;Most of us developers, despite being more or less aware of the benefits of doing more work together, work on our own most of the time. Why? What can we do about it? Let&amp;#39;s dive into it!&lt;/p&gt;&lt;h2&gt;Is it just about programming?&lt;/h2&gt;&lt;p&gt;Short answer: no, it’s not. As software developers we don’t just write code, we also play a crucial role in actively shaping, challenging and clarifying requirements. And this happens in many different flavours: emails, issue tracking systems, chat tools, team meetings, inter-team meetings... Every area of our work can benefit if we approach it in a more collaborative way.&lt;/p&gt;&lt;h2&gt;The good, the bad and the ugly about collaboration&lt;/h2&gt;&lt;p&gt;What is the greatest hesitance when thinking about working more with other colleagues? Well, for some folks it may feel cumbersome in terms of time consumption and efficiency. But if we dig deeper, we will probably find out that this hesitance has a lot to do with the well-known &lt;a href=&quot;https://en.wikipedia.org/wiki/Impostor_syndrome&quot;&gt;impostor syndrome&lt;/a&gt;. Often times we might feel like we are not good enough. The need to ask for help, the idea of someone watching you work and seeing the uncertainty with which you approach problems, the risk of revealing your lack of knowledge in some areas... This is frightening for most of us. Literally “stage fright”.&lt;/p&gt;&lt;p&gt;These fears are common in developers regardless of their degree of expertise. But they shouldn&amp;#39;t stop us from learning from each other. In fact, we are learning all the time, and the more we interact with others, the more we learn. I have the same fears, but I decided to open myself more to collaborative work for three main reasons:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;I was not happy with the amount and quality of collaborative work in my teams&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;I realized that these fears are mostly based on prejudices&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Every time I was approaching work in a more collaborative way, even though it felt unnatural, it showed to be quite powerful&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Don&amp;#39;t get me wrong, I am not talking about overdoing it, but about finding the balance, the sweet spot where collaborative work produces a positive impact in our working life. In order for that to happen, it is crucial to accumulate experiences and get a feeling of which collaboration paradigm is better to apply for each use case. Daily meeting? Knowledge sharing session? Second opinion? Think of a toolbox for team collaboration, this is exactly what is offered to you. Every person, every situation, every topic is different. That&amp;#39;s what makes this journey exciting and why you want to have a variety of options and adapt each time.&lt;/p&gt;&lt;h2&gt;In practice&lt;/h2&gt;&lt;p&gt;In this section, I will present you four fantastic, experience-proved ways to foster collaboration in your team. As you will realize, the common factors of any kind of collaborative work are: clear goals, preparation, focus, continuous challenge of yourself and each other’s thoughts, and a constructive attitude.&lt;/p&gt;&lt;p&gt;Don&amp;#39;t limit yourself to this list, but use it also as inspiration to find your own ways!&lt;/p&gt;&lt;h3&gt;The powerful start 🚀&lt;/h3&gt;&lt;p&gt;When you start working on a task, sometimes it feels intimidating. If you are lacking knowledge and you can find resources on the Internet, that’s the way to go. But if the overwhelming complexity lies in project specifics, or you just have a colleague who is really proficient in that area, the best you can do is to ask for a short meeting. 15 to 30 minutes should suffice, keep it short and don’t enter into too many details. Depending on the situation, this session is either about your colleague sharing their knowledge with you or you both trying to figure out how to tackle the task. In addition, if you both agree and the schedule allows it, you might decide to have an ad-hoc session of pair programming.&lt;/p&gt;&lt;p&gt;I have to admit, most of the time I am shy to ask for these sessions. But after having one of them I always feel amazed about how helpful it was and how much progress we did, and I always regret not doing it more often. Do not hesitate, ask for those sessions.&lt;/p&gt;&lt;h3&gt;The doubtful solution 🤔&lt;/h3&gt;&lt;p&gt;Another very handy chance is to ask for a second opinion about the piece of work you have done on your own. Essentially the same as the previous one, it just happens when there has already been progress in the task, and therefore the discussion revolves around the solution. Imagine you have implemented the code of a new feature, but you are not happy with the solution you are providing so far and don&amp;#39;t know how you could do it differently. Or you have done it in a certain way but the rework you have in mind involves a lot of changes. You might end up doing all that rework, creating a Pull Request and eventually deciding with the team that the initial solution was actually a better option, which is a very unproductive approach. We all have done that. How can we do better?&lt;/p&gt;&lt;p&gt;Kindly ask one of your team colleagues to have a session on that. Here you can discuss with your colleague the solution you have provided and the challenges you are facing, or you can even go a step further and do a pair programming session. Almost every time I do this, I end up asking myself why I spent X hours on my own, when talking 15-30 minutes with a colleague made the landscape so much clearer.&lt;/p&gt;&lt;h3&gt;The knowledge sharing session 📗&lt;/h3&gt;&lt;p&gt;This was already mentioned as a great way to start working on a task. But knowledge sharing is much broader than just that.&lt;/p&gt;&lt;p&gt;Many times we are lacking knowledge in some project areas. This happens often and for various reasons like an extensive codebase, vacations, a high project throughput delivered by a (probably) too large team, which doesn’t allow to keep up with all the changes, etc. Of course you can figure things out out by yourself, this is hands down the best solution for small or simple parts. But in many cases, asking a colleague with knowledge on that is a great idea. You will understand everything much better, you will need less time, and will greatly contribute to a much better solution. The following are some examples of excellent opportunities to play the knowledge sharing card:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;There are many parts involved and you are struggling to figure out how everything works together&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;The quality of the code makes it really difficult to understand it (try to avoid having bad quality code in your project at all costs)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;A concrete part of the codebase (a library, a big feature, etc.) is just new to you and you simply don&amp;#39;t know what is going on&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;You are about to review a Pull Request and you are not familiar with that part of the code&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Keep in mind to open those sessions to other colleagues who might be interested in grabbing the same knowledge. Your team will get even more out of the session in that way, since the knowledge will spread to a longer audience. But don&amp;#39;t overdo it.&lt;/p&gt;&lt;p&gt;How does this additionally improve the team&amp;#39;s strength and flexibility? A lot. Imagine a team fellow who has acquired a much higher amount of knowledge in one area and is the only go-to person when a meeting with stakeholders is needed, or when someone needs to take care of a related issue or bug. That does not help your team. This person will eventually be absent for any reason, like being on vacation or leaving the company. He might someday be overloaded with too much work, or working too long on the same area and silently hating that no one is also taking ownership on that part. Knowledge sharing sessions are the cure for unhealthy team dependency.&lt;/p&gt;&lt;h3&gt;The crowded inter-team meeting 🤷🏽‍♂️&lt;/h3&gt;&lt;p&gt;You are working in a team which is part of a bigger ecosystem. From time to time, there are meetings to discuss and clarify important topics, and it is really difficult to get a second chance for follow-up meetings in the near future. So you want to make sure that you and your team are fully prepared for that meeting, and get the most out of it. After all, probably you have been trying to clarify the issues via written communication for weeks or months, and the call for this meeting is probably the result of piled frustration. Many times, we don’t realise how relevant such meetings are. We just don’t prepare, or do not coordinate preparation efforts with other team members. There is no proper agenda here, there is no structured sequence to present the issues in the meeting. This significantly lowers the chances to have a productive meeting, leading to wasting the time of everyone attending, to not reaching any meaningful improvement and to more frustration and a feeling of powerlessness.&lt;/p&gt;&lt;p&gt;Phew, that’s really bad. What can we do? Nominate 2 (max. 3) team members to attend the meeting and have a preparation meeting to prioritise the topics that need to be discussed, to define what is the right information to provide and the right questions to ask for each of the topics, and to update the meeting agenda if necessary. Consider always the time available for the actual meeting while preparing, since this influences the amount of items you can clarify and how deep you can discuss them.&lt;/p&gt;&lt;h2&gt;Conclusion&lt;/h2&gt;&lt;p&gt;I hope after reading this article you feel inspired and empowered to improve some work practices that are not working quite well in your team at this time.&lt;/p&gt;&lt;p&gt;Your initial reaction to working in a more collaborative way might be rejection, since it can be unpleasant to do something that exposes yourself to others, mostly if you are not used to doing so in a working environment. But there are so many positive consequences, that I firmly believe we should conquer those hesitances. You will be working as part of a team that communicates well, a team that is flexible and strong to overcome any challenge it will face, a team where every one grows and takes ownership, and definitely a team where everyone is engaged and happy. And the cherry on the cake is that you will deliver a much better product. Isn&amp;#39;t that fantastic? 🎉&lt;/p&gt;&lt;p&gt;It is in your hands, start doing more collaborative work today, get out of your silo, you will be amazed.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Boosting developer productivity with GitHub Actions]]></title><description><![CDATA[How to integrate GitHub Actions for some serious productivity boost]]></description><link>https://satellytes.com/blog/post/boosting-developer-productivity-with-github-actions/</link><guid isPermaLink="false">https://satellytes.com/blog/post/boosting-developer-productivity-with-github-actions/</guid><pubDate>Fri, 25 Feb 2022 00:00:00 GMT</pubDate><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://satellytes.com/_gatsby/image/295af0fb065d06adacadfcf5b736b39c/4be445bf02c55418e404abd8f2a1a674/hero.jpg?eu=e868f43912f0151e70d8c4248530ffa23c55491d86528cfc6b74e8179f0a8162ebf51083f99eda36a56fbbf481c9b56e8ff7109274b2537e983d506fba828a72ee2eb15e4bcfe189953ef62135514c75709609c0f2e91f6c587d405c12ed75d34a0671cb1bbb0f47b7f49f319d42e24b0b557362b55ca53a916a8df673764f3cb09b78c8278a4863b56d80736f830b41341602f763a44c59fd421b820f412a6cb98f4ed52816c7602fa66ce3d5e1a0f9ad51dbf9dcdf31230badada15eceb9990e59b44a2ad88eadd000483c41197545e820e1ed07d39e066245d43e815328e4d5333a9111c088&amp;amp;a=w%3D1440%26h%3D760%26fm%3Djpg%26q%3D75&amp;amp;cd=2022-03-25T13%3A17%3A16.471Z&quot; alt=&quot;&quot;/&gt;&lt;figcaption&gt;&lt;a href=&quot;https://unsplash.com/photos/oyXis2kALVg&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Image by fabio&lt;/a&gt;&lt;/figcaption&gt;&lt;/figure&gt; &lt;p&gt;This is going to be a brief introduction to GitHub Actions, followed by a closer look at the two main elements of GitHub Actions: Workflows and Actions.
We will then look at a few examples of how we are using them in one of our client&amp;#39;s project, followed by the attempt to inspire you to start thinking about automation yourself.
&lt;/p&gt;&lt;h2&gt;Terminology&lt;/h2&gt;&lt;p&gt;Let’s start with everyone’s favorite when it comes to new technology: terminology.&lt;/p&gt;&lt;p&gt;Even though it’s called &amp;quot;GitHub Actions&amp;quot;, the main thing that you will deal with are going to be &amp;quot;Workflows&amp;quot;.&lt;/p&gt;&lt;h3&gt;Workflow&lt;/h3&gt;&lt;p&gt;Workflows are what other automation platforms most often refer to as &amp;quot;pipelines&amp;quot;. They are the biggest logical chunk in this architecture and they themselves are made up of 1 or more &amp;quot;jobs&amp;quot;. Each job is itself made up of 1 or more &amp;quot;steps&amp;quot;. These steps can be either arbitrary CLI commands like &lt;code&gt;yarn install&lt;/code&gt; or they can use an &amp;quot;Action&amp;quot;.&lt;/p&gt;&lt;h3&gt;Action&lt;/h3&gt;&lt;p&gt;Actions can be either pure JavaScript, ran using NodeJS or they can be Docker-based. They can be used as the steps in your workflows&amp;#39; jobs. You can mix the types of actions however you like in a single job. So you can easily have a job that runs a CLI command (e.g. &lt;code&gt;npm install&lt;/code&gt;) as a first step, then uses a JavaScript action followed by a Docker action.&lt;/p&gt;&lt;h3&gt;Event&lt;/h3&gt;&lt;p&gt;What we also need is a way to trigger workflows. These are called events and there are different types of them:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&amp;quot;Internal events&amp;quot;: These are events that fire when someone pushes to GitHub or adds a comment to a Pull Request or similar&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&amp;quot;Manual events&amp;quot;: You can manually trigger events by clicking a button in a workflow that says &amp;quot;Run workflow&amp;quot;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&amp;quot;Scheduled events&amp;quot;: You can also have scheduled events based on a cron job that will for example trigger a workflow once a week, every Tuesday morning or whenever you like.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;Runner&lt;/h3&gt;&lt;p&gt;There is one more thing missing to make this whole thing work and that is the actual &amp;quot;Runner&amp;quot; that runs your workflows. The runners are mere applications, running somewhere on a server, listening for your jobs to execute them. GitHub.com provides a lot of these runners that you can use right away. With a free GitHub account you can use up to 2000 minutes of runner time per month in private projects and there is no limit on public projects, so you can start experimenting with them right away, no strings attached. Have a look at &lt;a href=&quot;https://github.com/pricing#compare-features&quot;&gt;their pricing model&lt;/a&gt; for further details.&lt;/p&gt;&lt;p&gt;In case you need a very special environment or would like to have more control over the runner you can also host them yourself. With custom runners you can provide specialized environments to run your nostalgic Windows 95 jobs or to have them integrate particularly well with your existing infrastructure.&lt;/p&gt;&lt;p&gt;Runners can have different labels so they can be easily targeted in a workflow. All publicly available runners have labels like &lt;code&gt;ubuntu-latest&lt;/code&gt; or &lt;code&gt;windows-latest&lt;/code&gt; to reveal the underlying operating system. There can also be other labels like &lt;code&gt;x64&lt;/code&gt; or &lt;code&gt;gpu&lt;/code&gt; to reveal information about the architecture.&lt;/p&gt;&lt;h2&gt;Workflows in detail&lt;/h2&gt;&lt;p&gt;With all that terminology out of the way, let&amp;#39;s talk about workflows in more detail. Where are they stored, what do they look like from the inside and the outside?&lt;/p&gt;&lt;h3&gt;Location of a GitHub Workflow&lt;/h3&gt;&lt;p&gt;Workflows are stored in your repository in a folder called &lt;code&gt;.github/workflows/&lt;/code&gt; in the form of YAML files. Here you can see a schema of this:&lt;/p&gt;
            &lt;figure&gt;
              &lt;pre&gt;&lt;code class=&quot;shell language-shell&quot;&gt;.github
├── ...
└── workflows
    ├── create-release.yml
    ├── housekeeping.yml
    ├── new-issues.yml
    ├── pr-checks.yml
    ├── release-comment-in-issues.yml
    └── stale.yml
...
&lt;/code&gt;&lt;/pre&gt;
              &lt;figcaption&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
          &lt;p&gt;When you add a &lt;code&gt;*.yml&lt;/code&gt; file in that folder it will be picked up by GitHub automatically and will be added to the list of workflows in your repository. There is no additional configuration required.&lt;/p&gt;&lt;h3&gt;Anatomy of a Workflow&lt;/h3&gt;&lt;p&gt;As already mentioned, Workflows are written in the YAML format. Let&amp;#39;s look at a workflow that runs checks on Pull Requests:&lt;/p&gt;
            &lt;figure&gt;
              &lt;p&gt;```yaml{numberLines: true}
name: Pull Request checks&lt;/p&gt;
&lt;p&gt;on:
  pull_request:
    types: [opened, reopened, edited, synchronize]
    branches: [main]&lt;/p&gt;
&lt;p&gt;jobs:
  commitlint-pr-title:
    name: Ensure proper PR title 
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  - uses: actions/setup-node@v2
    with:
      node-version: &apos;16&apos;

  - name: manually install config-conventional commitlint preset
    run: npm install --no-save @commitlint/config-conventional

  - uses: satellytes/commitlint-pr-title@v1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;```&lt;/p&gt;
              &lt;figcaption&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
          &lt;p&gt;&lt;/p&gt;&lt;p&gt;First we add a human-readable name to the workflow (ln. 1). In this case this Workflow is called &amp;quot;Pull Request checks&amp;quot;.&lt;/p&gt;&lt;p&gt;Next we define a list of events that trigger this workflow with the &amp;quot;on&amp;quot; property (ln. 3). In this case we want this workflow to be triggered whenever there is something happening that is related to a Pull Request so we list the &lt;a href=&quot;https://docs.github.com/en/actions/using-workflows/events-that-trigger-workflows#pull_request&quot;&gt;pull_request event&lt;/a&gt; (ln. 4). We want to narrow down the types of &lt;code&gt;pull_request&lt;/code&gt; events that trigger this workflow with a list of &lt;code&gt;types: [opened, reopened, edited, synchronize]&lt;/code&gt; (ln. 5). We also want to only run this workflow when the target branch of the PR is &lt;code&gt;main&lt;/code&gt; so we add another filter for that (ln. 6).&lt;/p&gt;&lt;p&gt;With that set up we now define the jobs that make up this workflow (ln. 8). This workflow consists of only a single job that is called &lt;code&gt;commitlint-pr-title&lt;/code&gt; (ln. 9), or, to make it more human-readable we can give it a &amp;quot;name&amp;quot; property, like &amp;quot;Ensure proper PR title&amp;quot; (ln. 10). This job demands to be run on a runner that is labeled &lt;code&gt;ubuntu-latest&lt;/code&gt; using the &lt;code&gt;runs-on&lt;/code&gt; property (ln. 11).&lt;/p&gt;&lt;p&gt;The job is made up of a list of steps (ln. 12). The first step &lt;code&gt;uses&lt;/code&gt; an action called &lt;code&gt;actions/checkout&lt;/code&gt; (ln. 13). This action will do a lightweight clone of the repository on the runner. Judging by the name of this action you can infer that it can be found at &lt;a href=&quot;https://github.com/actions/checkout&quot;&gt;https://github.com/actions/checkout&lt;/a&gt;. All actions that start with &lt;code&gt;actions/&lt;/code&gt;are part of the &amp;quot;official&amp;quot; actions and are maintained by GitHub. The next step also uses one of the official Actions called &lt;code&gt;actions/setup-node&lt;/code&gt; (ln. 15) and provides an &amp;quot;input&amp;quot; for this action using the &lt;code&gt;with&lt;/code&gt; property (ln. 16) to pass the specific &lt;code&gt;node-version&lt;/code&gt; that we want installed on this runner (ln. 17).&lt;/p&gt;&lt;p&gt;While the previous two steps were using Actions, the next step runs a CLI command to install a dependency using the &lt;code&gt;run&lt;/code&gt; property instead of &lt;code&gt;uses&lt;/code&gt; that we&amp;#39;ve used in the steps before (ln. 20). We will need this dependency in the final step of this job. To improve the readability of the workflow output we explicitly give this step a name (ln. 19). For the steps that don&amp;#39;t receive a &lt;code&gt;name&lt;/code&gt; property, the name in the workflow output will simply be the name of the action or the raw CLI command that was run.&lt;/p&gt;&lt;p&gt;The final step in this job is using another action, called &lt;code&gt;satellytes/commitlint-pr-title&lt;/code&gt; (ln 22).&lt;/p&gt;&lt;p&gt;You might have noticed that whenever we use an action as a step we also specified some kind of version identifier alongside the name of the action: &lt;code&gt;actions/checkout@v2&lt;/code&gt;. The name of the action is &lt;code&gt;actions/checkout&lt;/code&gt; and the &lt;code&gt;@v2&lt;/code&gt; in this case points to the tag &lt;code&gt;v2&lt;/code&gt; in the repository of that action. These version identifiers can be any &lt;a href=&quot;https://git-scm.com/book/en/v2/Git-Internals-Git-References&quot;&gt;Git Reference&lt;/a&gt; that you want. It can be a branch name, a commit hash or a tag. The recommendation is to keep these as precise as possible, so ideally you would avoid having a very imprecise &amp;quot;version&amp;quot; like &lt;code&gt;@main&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;This workflow will produce an output like this:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;//images.ctfassets.net/54dnxp2417nl/IFhUvy3MhUHWocjXrjygG/4d53864294dedb228c60a28b6cf4bba2/workflow-output.jpg&quot; alt=&quot;The output of the workflow&quot;/&gt;&lt;figcaption&gt;The output of the workflow&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;Workflows in a GitHub repository&lt;/h3&gt;&lt;p&gt;All the workflows in your repository can be found in a special tab called &amp;quot;Actions&amp;quot;:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;//images.ctfassets.net/54dnxp2417nl/1aMQWc2sJRfyaxwBdZUsqZ/b01ca5b683e0239347806804abb81a3b/actions-tab.jpg&quot; alt=&quot;The Actions tab&quot;/&gt;&lt;figcaption&gt;The Actions tab&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;In this tab you can take a look at any of the past or ongoing workflow runs and their outputs and results.&lt;/p&gt;&lt;p&gt;Workflows that are run as part of a PR will additionally appear in the &amp;quot;Checks&amp;quot; tab in a Pull Request:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;//images.ctfassets.net/54dnxp2417nl/4RSuGUegSQHb26GPyDUna2/87261bb325cbd36613178fb6ceaffdb4/checks-tab.jpg&quot; alt=&quot;The Checks tab in a Pull Request&quot;/&gt;&lt;figcaption&gt;The Checks tab in a Pull Request&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;Actions in detail&lt;/h2&gt;&lt;p&gt;So now that we&amp;#39;ve talked about where workflows are located and what they look like, let&amp;#39;s go into more detail about the things that make up these workflows: Actions.&lt;/p&gt;&lt;h3&gt;Location of a GitHub Action&lt;/h3&gt;&lt;p&gt;Most of the time a single action corresponds to a single repository. The name of an action is simply its GitHub path. It’s made up of an owner and the name of the repository. Throughout the remainder of this section we will take a more detailed look at an action called &lt;code&gt;satellytes/commitlint-pr-title&lt;/code&gt;. It can be found at &lt;a href=&quot;https://github.com/satellytes/commitlint-pr-title&quot;&gt;https://github.com/satellytes/commitlint-pr-title&lt;/a&gt;, note that the path in the URL matches the name of the action. You can also have multiple actions in a single repository, in which case you would add the subfolder to the name of the repository, like &lt;code&gt;satellytes/actions/my-action&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;To browse available actions you can visit the &lt;a href=&quot;https://github.com/marketplace?type=actions&quot;&gt;GitHub Marketplace&lt;/a&gt; that has more than ten thousand publicly available Actions that are free for you to use. There are quite a lot of &amp;quot;official&amp;quot; actions like &amp;quot;actions/checkout&amp;quot; but there are far more actions provided by the community. They basically cover everything that you could possibly want to do inside a workflow. That means that most of the time when you want to have a specific workflow, it’s just a matter of putting together the right combination of public Actions in the right order.&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;You can very well use actions that are not in the marketplace. Adding them to the marketplace is a voluntary step, but it’s a mere button click away and it makes it easier for others to find your action.&lt;/p&gt;&lt;/blockquote&gt;&lt;h3&gt;Anatomy of an Action&lt;/h3&gt;&lt;p&gt;Each action needs to provide a file called &lt;code&gt;action.yml&lt;/code&gt; in its root folder that provides some metadata for the GitHub Actions Runner.&lt;/p&gt;&lt;h3&gt;The &lt;code&gt;action.yml&lt;/code&gt; file&lt;/h3&gt;&lt;p&gt;Let&amp;#39;s take a look at the &lt;code&gt;action.yml&lt;/code&gt; file of the &lt;code&gt;satellytes/commitlint-pr-title&lt;/code&gt; action:&lt;/p&gt;
            &lt;figure&gt;
              &lt;p&gt;&lt;code&gt;yaml{numberLines: true}
name: &apos;Commitlint PR title&apos;
description: &apos;This action runs your commitlint config against your Pull Request titles&apos;
author: &apos;Felix Hamann &amp;lt;felix.hamann@satellytes.com&amp;gt;&apos;
runs:
  using: &apos;node16&apos;
  main: &apos;dist/index.js&apos;
inputs:
  commitlintConfigFile:
    description: path to commitlint config file
    default: ./commitlint.config.js
    required: false
  helpUrl:
    description: help url for users of this action
    default: &apos;https://www.conventionalcommits.org&apos;
    required: false
&lt;/code&gt;&lt;/p&gt;
              &lt;figcaption&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
          &lt;p&gt;This file contains things like a human-readable name of the action (ln. 1), a description (ln. 2) as well as an author (ln. 3). This file also explains what is required to run this action. This is done using the &lt;code&gt;runs&lt;/code&gt; property (ln. 4). In this case this action requires &lt;code&gt;node 16&lt;/code&gt; (ln. 5) and states a &lt;code&gt;main&lt;/code&gt; entry file of &lt;code&gt;dist/index.js&lt;/code&gt; (ln. 6). That means that when this action is used, the Runner will need to provide node 16 to run this particular Action and it will execute the file &lt;code&gt;dist/index.js&lt;/code&gt; from this action.&lt;/p&gt;&lt;p&gt;As mentioned, there are two main categories of actions. There are JavaScript actions and Docker-based actions. This specific action is a JavaScript action which is executed using the NodeJs runtime. A Docker based Action would specify a value of &amp;quot;docker&amp;quot; as the &lt;code&gt;using&lt;/code&gt; property here and instead of an entry file it would point to a Dockerfile. &lt;a href=&quot;https://docs.github.com/en/actions/creating-actions/creating-a-docker-container-action&quot;&gt;Here&lt;/a&gt; you can find more information about docker-based actions.&lt;/p&gt;&lt;p&gt;Other things that this file also states are inputs that this action might accept (ln. 7) or outputs that it provides (does not apply for this action). In this case we have two inputs: &lt;code&gt;commitlintConfigFile&lt;/code&gt; (ln. 8) and &lt;code&gt;helpUrl&lt;/code&gt;(ln. 12). For each input we can specify a description (ln. 9), a default value (ln. 10) and whether or not this input is required (ln. 11).&lt;/p&gt;&lt;h3&gt;The &lt;code&gt;main&lt;/code&gt; entry file&lt;/h3&gt;&lt;p&gt;This is where we can finally talk about some actual code. In the case of the &lt;code&gt;satellytes/commitlint-pr-title&lt;/code&gt; action the entry file &lt;code&gt;dist/index.js&lt;/code&gt; is compiled and minified from TypeScript sources so it wouldn&amp;#39;t be a lot of fun to look at. So instead of looking at that &lt;code&gt;main&lt;/code&gt; file directly, let&amp;#39;s take a look at &lt;a href=&quot;https://github.com/satellytes/commitlint-pr-title/blob/main/src/main.ts&quot;&gt;the actual TypeScript source&lt;/a&gt;:&lt;/p&gt;
            &lt;figure&gt;
              &lt;p&gt;```ts{numberLines: true}
import core from &apos;@actions/core&apos;;
import github from &apos;@actions/github&apos;;
import { lint, formatResult } from &apos;./lint&apos;;&lt;/p&gt;
&lt;p&gt;(async function run() {
    const title = github.context.payload.pull_request?.title;
    const configFile = core.getInput(&apos;commitlintConfigFile&apos;);&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;core.info(
  `🔎 Checking if the title of this PR &quot;${title}&quot; meets the requirements ...`
);

try {
    const lintResult = await lint(title, configFile);
    if (!lintResult.valid) {
        core.setFailed(`\n ${formatResult(lintResult)}`);
    } else {
        core.info(&apos;✔️ All good&apos;);
    }
} catch (error) {
    core.setFailed(error as Error);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;})();
```&lt;/p&gt;
              &lt;figcaption&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
          &lt;p&gt;We won&amp;#39;t go into a lot of detail about what this code does. I&amp;#39;ll leave this as homework for you to explore.&lt;/p&gt;&lt;p&gt;The main takeaway should be, that there are two important libraries that we are using: &lt;code&gt;@actions/core&lt;/code&gt; and &lt;code&gt;@actions/github&lt;/code&gt; (ln. 1 &amp;amp; 2). These two libraries provide a lot of utilities to interact with the process that is running on the GitHub runner. They allow you to fetch information about the event that triggered this workflow as well as make it easy to report the result of your action. You can get up close and personal with this code and explore the inner workings in &lt;a href=&quot;https://github.com/satellytes/commitlint-pr-title&quot;&gt;the action&amp;#39;s repository&lt;/a&gt;.&lt;/p&gt;&lt;h3&gt;Compiling and bundling an Action&lt;/h3&gt;&lt;p&gt;As we&amp;#39;ve seen in the previous subsection we can have pretty much any code we want, as long as we provide a main entry point for the GitHub runner to execute. In this particular case we not only have to bundle everything into a single file but we also need to take care of compiling the TypeScript sources. There are probably thousands of ways to turn TypeScript into JavaScript and even more ways of producing a single bundle file. After a lot of experimenting with &lt;code&gt;rollup&lt;/code&gt;, &lt;code&gt;webpack&lt;/code&gt;, and other tools, I settled with &lt;a href=&quot;https://github.com/vercel/ncc&quot;&gt;&lt;code&gt;@vercel/ncc&lt;/code&gt;&lt;/a&gt;to transpile, compile and bundle this action. &lt;code&gt;ncc&lt;/code&gt; is a CLI tool that I found surprisingly comfortable to use. It works nicely for regular vanilla JS projects but it also supports TypeScript out of the box and is meant to ship a single file that contains everything that is needed, from your actual source code to everything from inside the depths of your &lt;code&gt;node_modules&lt;/code&gt; folder that is required to run your action.&lt;/p&gt;&lt;p&gt;The TypeScript file shown above is called &lt;code&gt;src/main.ts&lt;/code&gt;. The bundling is done by calling &lt;code&gt;ncc build src/main.ts&lt;/code&gt;. This will produce a file &lt;code&gt;dist/index.js&lt;/code&gt; that we then point to in the &lt;code&gt;action.yml&lt;/code&gt; file, as shown above.&lt;/p&gt;&lt;p&gt;Pitfall: You need to remember to run your build/bundle step whenever you change your source code and commit the new generated artifact alongside your changes. This is important for the compiled code in your repository to not get outdated. I&amp;#39;ve spent more time than I&amp;#39;m comfortable to admit, trying to figure out why a certain change didn&amp;#39;t affect my action until I realized that I didn&amp;#39;t recompile the code before committing.&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;💡 Having a &lt;code&gt;pre-commit&lt;/code&gt; hook that runs your build/bundle step is a great way to automate this.&lt;/p&gt;&lt;/blockquote&gt;&lt;blockquote&gt;&lt;p&gt;💡 Of course, there is no need for you to write your action with TypeScript - that&amp;#39;s just what I feel most comfortable with.&lt;/p&gt;&lt;/blockquote&gt;&lt;h2&gt;Inspiration: example workflows&lt;/h2&gt;&lt;p&gt;Now that you know what workflows and actions look up close, let&amp;#39;s take a look at some of the workflows that we are using in one of our client&amp;#39;s project to make our daily lives more comfortable. We are after all developers and we are known to be lazy, aren&amp;#39;t we?&lt;/p&gt;&lt;h3&gt;Workflow: Pull Request checks&lt;/h3&gt;&lt;p&gt;The workflow and the action that we&amp;#39;ve talked about so far in this blog post are of course one of these examples.&lt;/p&gt;&lt;h4&gt;What problem does it solve?&lt;/h4&gt;&lt;p&gt;In a lot of our projects we are using the &lt;code&gt;squash&lt;/code&gt; method to merge Pull Requests. That means that the title of a Pull Request will end up being the commit message of a commit in our &lt;code&gt;main&lt;/code&gt; branch. For local development we&amp;#39;ve set up a tool called &lt;code&gt;commitlint&lt;/code&gt; to make sure our developers adhere to the rules for commit messages that we agreed on. This is enforced using a git hook, which checks each commit and ensures that the developer provides a valid commit message. However, when creating a Pull Request in GitHub there is no straightforward way to enforce these same rules.&lt;/p&gt;&lt;h4&gt;How does it solve the problem?&lt;/h4&gt;&lt;p&gt;The configuration for &lt;code&gt;commitlint&lt;/code&gt; is stored alongside our code, in the same repository. The &lt;code&gt;commitlint-pr-title&lt;/code&gt; action is used to lint the titles of Pull Request and most importantly it is using the same configuration that we use locally to lint commit messages. This means these configurations will never get out of sync and we only need to maintain them in a single place. In GitHub we&amp;#39;ve set up &lt;a href=&quot;https://docs.github.com/en/repositories/configuring-branches-and-merges-in-your-repository/defining-the-mergeability-of-pull-requests/managing-a-branch-protection-rule&quot;&gt;&amp;quot;branch protection rules&amp;quot;&lt;/a&gt;that requires the workflow to pass successfully before a Pull Request is allowed to be merged. This way we ensure that any squashed commit that arrives in &lt;code&gt;main&lt;/code&gt; will follow the same guidelines that we use during out local development.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;//images.ctfassets.net/54dnxp2417nl/528QGFHfuBf7R9vSzgWJ5p/7e59699b9656c86ddefe8342e3c79cb5/pr-checks.jpg&quot; alt=&quot;A check on a Pull Request to verify that the title passes our commit linting&quot;/&gt;&lt;figcaption&gt;A check on a Pull Request to verify that the title passes our commit linting&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;Workflow: New issues&lt;/h3&gt;&lt;p&gt;This workflow is run for all new issues that are being opened in our repository.&lt;/p&gt;&lt;h4&gt;What problem does it solve?&lt;/h4&gt;&lt;p&gt;We are using a &amp;quot;Project&amp;quot; in GitHub, which is like a Kanban board to organize issues. We only have a single project that we use to organize all our issues. To make this work, we need to add any new issue to this project so that it appears on the project board. During our meetings we mostly look at this project board to triage new issues. Because we forgot to add some of the new issues from time to time, we forgot to talk about them during our refinements and so we never addressed some of them.&lt;/p&gt;&lt;h4&gt;How does it solve the problem?&lt;/h4&gt;&lt;p&gt;This workflow consists entirely of already available actions so it was pretty much a plug &amp;amp; play experience. All it does is, whenever there is a new issue, it adds it to our project. In every meeting in which we look at our project board we can now be sure that all new issues are listed in our backlog. This is especially relieving for issues that got created by some external party that is not aware of our GitHub project.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;//images.ctfassets.net/54dnxp2417nl/1t2okL0NThyYfiMSZZUSgT/eb66d89711457865ff711aa27d12f3ec/new-issues.jpg&quot; alt=&quot;New issue was added to the backlog&quot;/&gt;&lt;figcaption&gt;New issue was added to the backlog&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;Workflow: Create release&lt;/h3&gt;&lt;p&gt;We are also making use of Releases in GitHub. These are meant to keep a neat history of released versions of our libraries. This is particularly nice because GitHub users can &amp;quot;subscribe&amp;quot; to our repository and choose to be notified if there is a new release.&lt;/p&gt;&lt;h4&gt;What problem does it solve?&lt;/h4&gt;&lt;p&gt;Creating releases, so far, has been a manual process. So every time our Jenkins release pipeline ran (yes, we also use Jenkins), it pushed a new release commit with the updated &lt;code&gt;CHANGELOG.md&lt;/code&gt; file and a new tag to our repository but we then had to manually extract the changelog from the commit and manually create a GitHub release. We forgot to do this from time to time so our subscribers did not get notified and missed out on important updates.&lt;/p&gt;&lt;h4&gt;How does it solve the problem?&lt;/h4&gt;&lt;p&gt;The workflow that we are using to do this is a mixture of publicly available actions and a shell script to extract the change in the &lt;code&gt;CHANGELOG.md&lt;/code&gt; file. It get&amp;#39;s triggered whenever the repository receives a new &lt;code&gt;tag&lt;/code&gt; and it automatically creates the release in GitHub. This is just one more thing off our minds, one less thing to worry about when the release panic hits.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;//images.ctfassets.net/54dnxp2417nl/5WjDE6RFjLNg7ptFyDQxEs/587598e26468e86bb231b45d425aff07/release.jpg&quot; alt=&quot;A release created by github-actions&quot;/&gt;&lt;figcaption&gt;A release created by github-actions&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;Workflow: Stale issues&lt;/h3&gt;&lt;p&gt;As part of the issue management we need to keep track of old issues.&lt;/p&gt;&lt;h4&gt;What problem does it solve?&lt;/h4&gt;&lt;p&gt;As our repository grows and evolves so does the number of issues that accumulate. Over time some of these issues become obsolete.&lt;/p&gt;&lt;h4&gt;How does it solve the problem?&lt;/h4&gt;&lt;p&gt;Using a scheduled GitHub Workflow that runs once every night we mark &amp;quot;old&amp;quot; issues (90 days without interaction) as stale. This workflow uses the official &lt;code&gt;actions/stale&lt;/code&gt; action. If a stale issue is not being interacted with within 5 days it will get closed automatically. If an issue gets marked as stale and the team agrees that it&amp;#39;s still relevant during the next refinement meeting, we remove the &lt;code&gt;stale&lt;/code&gt; label.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;//images.ctfassets.net/54dnxp2417nl/1Uv9YoJdD7PWVRH1RQNUF/cd2787d440936664b422c5fbb06ae8e1/stale-issue.jpg&quot; alt=&quot;github-actions marking an issue as stale&quot;/&gt;&lt;figcaption&gt;github-actions marking an issue as stale&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;Workflow: Release comments&lt;/h3&gt;&lt;p&gt;We use keywords in Pull Requests like &lt;code&gt;closes&lt;/code&gt;, &lt;code&gt;fixes&lt;/code&gt;, or &lt;code&gt;resolves&lt;/code&gt; to automatically close issues that are done from a development point of view.&lt;/p&gt;&lt;h4&gt;What problem does it solve?&lt;/h4&gt;&lt;p&gt;With issues being closed when a corresponding Pull Request got closed it&amp;#39;s sometimes hard to keep track of the release that a certain fix or feature got published with.&lt;/p&gt;&lt;h4&gt;How does it solve the problem?&lt;/h4&gt;&lt;p&gt;This GitHub Workflow leaves a comment on released issues that informs any subscriber about the specific release that shipped the changes necessary to close the issue. This is done using a custom bash script that reads the CHANGELOG and extracts all issues that got published as part of the latest release. This list of released issues is then being passed to a custom action that uses GitHub GraphQL API to leave comments on these issues.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;//images.ctfassets.net/54dnxp2417nl/2qC4f9xE93IQkX4EdRRAoO/ca59aa71d4acfa2a00a2f06ca3d836bf/release-comment.jpg&quot; alt=&quot;A comment by github-actions that points to the corresponding release&quot;/&gt;&lt;figcaption&gt;A comment by github-actions that points to the corresponding release&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;Workflow: Housekeeping&lt;/h3&gt;&lt;p&gt;Housekeeping is an important aspect of the fast-paced frontend world. We used to have an issue to remind us to update our dependencies every once in a while. As with a lot of manual processes we forgot to do this from time to time. Especially when it comes to important vulnerability fixes it’s important to keep up to date. We now have a workflow to take care of that once a week using a scheduled event. With integrated tools like &amp;quot;Dependabot&amp;quot; this workflow might be obsolete soon, but so far we enjoy the fact that we are in full control of the workflow and can tweak and configure it to our hearts content.&lt;/p&gt;&lt;h2&gt;Conclusion&lt;/h2&gt;&lt;p&gt;In this blog post you learned the most important things about the terminology that you need to get started as well as got a first technical glimpse at what it means to author workflows and actions. If you&amp;#39;ve made it this far, I really recommend you give it a go. I can&amp;#39;t stop myself from smiling whenever I see something that was done by &lt;code&gt;github-actions [bot]&lt;/code&gt; and I really hope I was able to get you interested in GitHub Actions and automation in general.&lt;/p&gt;&lt;p&gt;Let&amp;#39;s end with some slightly philosophical thoughts about automation.&lt;/p&gt;&lt;h3&gt;Driven by laziness&lt;/h3&gt;&lt;p&gt;Most of the examples that I&amp;#39;ve shown are driven by laziness or the very fact that humans simply forget to do things from time to time. It&amp;#39;s the laziness to not assign a certain project to a new issue or the laziness to not run &lt;code&gt;yarn upgrade&lt;/code&gt; once in a while. Basically the point of this blog post was to inspire you with the inherent laziness that I discovered in myself over the past few years.&lt;/p&gt;&lt;h3&gt;It&amp;#39;s not about the code&lt;/h3&gt;&lt;p&gt;All these examples have one more thing in common: They are not necessarily related to the code in the repository. They rather deal with processes and metadata. They automate the things that we have to deal with on a daily basis that have to do with issue management, release cycles, vulnerabilities in third-party dependencies and so on.&lt;/p&gt;&lt;p&gt;Other external automation platforms like Jenkins, TravisCI or CircleCI are certainly splendid tools when it comes to automation, but from my experience, nothing integrates as smoothly into GitHub as &amp;quot;GitHub Actions&amp;quot; do. This is not particularly surprising, given the name - but it&amp;#39;s still worth mentioning.&lt;/p&gt;&lt;p&gt;While external automation platforms sure provide a lot of value - and will continue to do so - there are aspects of a repository that are easiest automated using GitHub Actions (given that that repository already lives inside GitHub). The convenience with which you can interact with Projects, Issues, Releases and other non-code related features of GitHub have been a crucial deciding factor for me, when choosing where to automate things. I won&amp;#39;t advocate migrating all your pipelines to GitHub Actions. Instead I suggest to start small. Start with the things that would be hard to automate with your existing automation infrastructure and then slowly migrate whatever feels right.&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&amp;quot;A repository is more than the sum of its code. Automate the repository, not the code.&amp;quot;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;There is a lot more to automation then the typical &amp;quot;continuous integration&amp;quot; and &amp;quot;continuous delivery&amp;quot; pipelines. Think outside of the box of CI/CD and be creative.&lt;/p&gt;&lt;h3&gt;What&amp;#39;s next?&lt;/h3&gt;&lt;p&gt;There is no good excuse to not get started right away. If you are interested in writing an action, take a closer look at the &lt;code&gt;satellytes/commitlint-pr-title&lt;/code&gt; action, available in &lt;a href=&quot;https://github.com/satellytes/commitlint-pr-title&quot;&gt;this repository&lt;/a&gt;. If you are interested in creating your first workflow, take a look at the &lt;a href=&quot;https://github.com/marketplace?type=actions&quot;&gt;GitHub Marketplace&lt;/a&gt; for even more inspiration. In case you want to immediately jump into the official documentation and continue learning about the technology itself: You can do so &lt;a href=&quot;https://docs.github.com/en/actions&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Make Gatsby SSR blazing fast with caching on Gatsby Cloud]]></title><description><![CDATA[Learn how to cache Gatsby SSR pages on Gatsby Cloud to boost page speed and scalability - your users won't even see a difference to SSG or DSG pages anymore.]]></description><link>https://satellytes.com/blog/post/cache-gatsby-ssr-pages-on-gatsby-cloud/</link><guid isPermaLink="false">https://satellytes.com/blog/post/cache-gatsby-ssr-pages-on-gatsby-cloud/</guid><pubDate>Tue, 15 Feb 2022 00:00:00 GMT</pubDate><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://satellytes.com/_gatsby/image/1ea2981fd201174ff9fb7223be3f4fe8/4be445bf02c55418e404abd8f2a1a674/gatsby-ssr-caching.jpg?eu=ed62a43a15a24612268f9277d866acac3d5140178101dafe6329b64bcf53d361b5fe1287ffc98132ff31b1fa8299b46edfa5409821e4052dcb6b053ebad18b27eb72ef574c93bb88c63bf87167544026709e59c0a1ec4c3c5e7b445848e971d81e0376c71fe20812b6ff9c3cde0fa60b5719383fe90ca73cd322dab62f7f483ba59c31c96686512de73c973374875f14765209ef3fbb6e05d12e4cd71945644bdaf708a00331893f26d65df9dcbdf4b3cb0cbad7d4a969264aaca7c013d7bc9a5b59e01b248fd8ad8c061f380d1a7703fe24fda31591d4183946876e890c60a2da3132&amp;amp;a=w%3D1440%26h%3D760%26fm%3Djpg%26q%3D75&amp;amp;cd=2022-03-25T14%3A45%3A41.228Z&quot; alt=&quot;&quot;/&gt;&lt;figcaption&gt;&lt;a href=&quot;https://unsplash.com/photos/WR-ifjFy4CI&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Image by Shiro Hatori&lt;/a&gt;&lt;/figcaption&gt;&lt;/figure&gt; &lt;p&gt;Ever since its introduction &lt;a href=&quot;https://gatsbyjs.com/&quot;&gt;Gatsby&lt;/a&gt; has established itself as the standard solution for React-based &lt;a href=&quot;https://jamstack.org/what-is-jamstack/&quot;&gt;Jamstack&lt;/a&gt; architectures. But where this approach has proven to be quite powerful for smaller sites, the restriction to pre-build all pages using Static Site Generation has proven to be a bottleneck &lt;a href=&quot;https://www.gatsbyjs.com/docs/how-to/performance/improving-build-performance/&quot;&gt;for larger websites&lt;/a&gt; or pages with real-time requirements.&lt;/p&gt;&lt;p&gt;Luckily the recent v4 update has added a couple of interesting new tools to the developer toolbox. One of them is &lt;a href=&quot;https://www.gatsbyjs.com/docs/how-to/rendering-options/using-server-side-rendering/&quot;&gt;Server-Side Rendering&lt;/a&gt;. With SSR, pages are rendered on the server at the moment the user visits the page. This allows for greater scaling, as not all content pages need to be pre-rendered. Plus: this allows for additional features, like live-content or user-specific data.&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;While this blog post focuses on Gatsby and Gatbsy Cloud it is applicable to any other SSR framework and hosting solution that supports the use of the caching headers mentioned in this article.&lt;/p&gt;&lt;/blockquote&gt;&lt;h2&gt;Why is caching important?&lt;/h2&gt;&lt;p&gt;When serving a page via SSR, efficient caching becomes crucial as the user won&amp;#39;t see anything until the whole page is rendered on the server and delivered to the browser. If rendering also includes fetching some external data or doing some compute-heavy calculations, this can take multiple seconds. Despite this being generally bad UX, it can also become problematic for scaling and stability. That&amp;#39;s where caching comes in place. Caching can be done on multiple levels, like only heavy computations. But the most impact on speed and scalability has caching at the edge, which means caching the whole rendered page on a CDN, right in front of the user.&lt;/p&gt;&lt;p&gt;If you host your Gatsby page with Gatsby Cloud, you have a CDN out of the box. The CDN is powered by Fastly. Caching for your static (SSG) or deferred (&lt;a href=&quot;https://www.gatsbyjs.com/docs/reference/rendering-options/deferred-static-generation/&quot;&gt;DSG&lt;/a&gt;) pages is done automatically. There is no need to configure anything here. But with SSR, you will need to configure the correct caching behavior by yourself.&lt;/p&gt;&lt;h2&gt;The Cache-Control header&lt;/h2&gt;&lt;p&gt;Caching in Gatsby Cloud can be controlled via the HTTP caching header &lt;code&gt;Cache-Control&lt;/code&gt;. This header has multiple &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Cache-Control#directives&quot;&gt;directives&lt;/a&gt; that can control caching. For our purposes the most important ones are:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;max-age&lt;/code&gt;: The time in seconds for how long the page should be cached by the browser. There won&amp;#39;t be any network requests during this time except the initial fetch.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;s-maxage&lt;/code&gt;: The time in seconds for how long the page should be cached by the CDN. For content that changes frequently, you may want to set a smaller value. If content isn&amp;#39;t expected to change it is safe to set a longer time period. If not set, the CDN will default to &lt;code&gt;max-age&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;stale-while-revalidate&lt;/code&gt; : Similar to &lt;code&gt;s-maxage&lt;/code&gt; header, for the given time period all user-requests are served instantly. But on top, the page is also refreshed in the background. If the requested page has been updated, the cached version will be replaced and all subsequent requests will serve the most up-to-date version of the content. If the content is not crucial, you can set this to a very high value.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;With those 3 directives, you can make your page as fast as with SSG or DSG pages. If the values are set correctly, only the very first user after a deployment will have to wait for the rendering. Everyone else will see a lightning-fast page.&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;This post was inspired by the excellent video from &lt;a href=&quot;https://www.youtube.com/watch?v=bfLFHp7Sbkg&quot;&gt;Remix on Youtube&lt;/a&gt;. If you want to deep dive into CDN caching, Cache-Control header and SSG/SSR, you should have a look!&lt;/p&gt;&lt;/blockquote&gt;&lt;h2&gt;Implement caching with Gatsby&lt;/h2&gt;&lt;p&gt;Now let&amp;#39;s dive into the code and see how the &lt;code&gt;Cache-Control&lt;/code&gt; header can be set with Gatsby.&lt;/p&gt;
            &lt;figure&gt;
              &lt;pre&gt;&lt;code class=&quot;jsx language-jsx&quot;&gt;// pages/ssr.jsx
export default function Cache() {
  return (
      &amp;lt;h1&amp;gt;SSR: Server Side Rendering&amp;lt;/h1&amp;gt;
  )
}

export async function getServerData() {
  return {
    headers: {
      &apos;Cache-Control&apos;: &apos;public, max-age=10, s-maxage=60, stale-while-revalidate=240&apos;,
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;
              &lt;figcaption&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
          &lt;p&gt;Gatsby SSR pages export the &lt;code&gt;getServerData()&lt;/code&gt; function which can be used to fetch data on the server-side or do other tasks necessary for rendering the page. This method is expected to return a &lt;code&gt;props&lt;/code&gt; object, that will be injected into the page for rendering. But more importantly for our purposes, this function returns a &lt;code&gt;headers&lt;/code&gt; object. This object is used to set the &lt;code&gt;Cache-Control&lt;/code&gt; header.&lt;/p&gt;&lt;p&gt;In our case, we set the browser cache (&lt;code&gt;max-age&lt;/code&gt;) to 10 seconds and the CDN cache (&lt;code&gt;s-max-age&lt;/code&gt;) to 1 minute. After 1 minute, the CDN will serve stale content. By adding the &lt;code&gt;stale-while-revalidate&lt;/code&gt;-header we ensure, if there is any request within these 4 minutes, a new page will be rendered in the background while the old page gets served. After the new page is rendered, it will replace the old one on the CDN and the caching time starts again. Let&amp;#39;s check the network tab to see if it works:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;//images.ctfassets.net/54dnxp2417nl/3C6ygqKyKmQKjMoMC1T7Ka/c3067909c46181e37246026cf7579b0c/gatsby-ssr-caching-network-tab.png&quot; alt=&quot;Chrome network tab shows that with proper caching headers only the very first request is slow&quot;/&gt;&lt;figcaption&gt;Chrome network tab shows that with proper caching headers only the very first request is slow&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;You can see: The very first page took 5 seconds to load (for this example, I added an artificial delay of 5 seconds to make the server rendered page more obvious). All other requests were served from CDN within 30ms. That&amp;#39;s super fast! Also, after the stale page was served, the page was re-rendered in the background and replaced. The request after the stale one was super fast again and served the updated content.&lt;/p&gt;&lt;h2&gt;Lessons learned with Gatsby SSR&lt;/h2&gt;&lt;p&gt;Before you jump into cached SSR pages on your production environment, keep in mind:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;SSR functionality is quite new in Gatsby and may not be as mature as in other frameworks.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;The same goes for Gatsby Cloud. It&amp;#39;s quite new and doesn&amp;#39;t feel fully ready for production just yet. E.g. during testing - even with this simplified setup - we encountered a general server error with no feedback for the cause (like server logs). The support of Gatsby is very helpful though. In doubt, you should contact them.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;SSR officially only works with Gatsby Cloud for now. You cannot host it somewhere else. There are third-party plugins though for &lt;a href=&quot;https://github.com/gatsby-uc/plugins/tree/main/packages/gatsby-plugin-fastify&quot;&gt;Fastify&lt;/a&gt; (self-hosting) or &lt;a href=&quot;https://github.com/netlify/netlify-plugin-gatsby&quot;&gt;Netlify&lt;/a&gt; (SAAS).&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;gatsby-plugin-image&lt;/code&gt; doesn&amp;#39;t work with SSR.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;Conclusion&lt;/h2&gt;&lt;p&gt;SSR with proper CDN caching is very powerful and can be used for a lot of scenarios, especially where you hit the limits of SSG and DSG. The integration within Gatsby and Gatsby Cloud is seamless, as you can introduce it on a per-page basis. If you don&amp;#39;t rely on &lt;code&gt;gatsby-plugin-image&lt;/code&gt; too much, you should definitely give it a try.&lt;/p&gt;&lt;p&gt;Thanks for reading and have fun working with Gatsby SSR!&lt;/p&gt;&lt;p&gt;Check out the repository with a full example on &lt;a href=&quot;https://github.com/feedm3/learning-gatsby-cloud-ssr-caching&quot;&gt;Github&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Improve cache efficiency between CloudFront and the browser]]></title><description><![CDATA[Learn how to improve Caching Headers in CloudFront to reduce traffic costs and increase page speed.]]></description><link>https://satellytes.com/blog/post/cloudfront-cache-efficiency/</link><guid isPermaLink="false">https://satellytes.com/blog/post/cloudfront-cache-efficiency/</guid><pubDate>Mon, 14 Feb 2022 00:00:00 GMT</pubDate><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://satellytes.com/_gatsby/image/ab23200bbc06539e329c9fa01fda4877/4be445bf02c55418e404abd8f2a1a674/cover.jpg?eu=b862a53d41a3404275db9371d937ada33905414ad307dbac307bbd44ca548430e4ff11d0fbcbd667f860bef4d79bb56c8aa214c825e3512dc2380468be848421be72e5594dc0badbc86cf72234074c7526cb0bc2a2ea19360f7e160919ba7bdb1202279a4cea5210b5afd220da08ec57425f7a37e308b377c378dfa33a6d5e3cb3c62c827ccc1036b6668b2d3ec35c17290948b05ab24a04dd2c78d23c1f067de7d03c81743b851028be49eed5bff4bec90fbbd387a8697518ada1cb1c85be900d0ce140718d8dfddb0705694d0b7305a32cf4e9&amp;amp;a=w%3D1440%26h%3D760%26fm%3Djpg%26q%3D75&amp;amp;cd=2022-03-25T12%3A50%3A20.421Z&quot; alt=&quot;&quot;/&gt;&lt;figcaption&gt;&lt;a href=&quot;https://unsplash.com/photos/d30sszrW7Vw&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Image by Faris Mohammed&lt;/a&gt;&lt;/figcaption&gt;&lt;/figure&gt; &lt;p&gt;Lately, we were trying out CloudFront to improve our API response and caching times. We wanted to cache the response in the browser for 10 seconds, and on CloudFront for 60 seconds. What sounds like a simple requirement turned out to be more complicated than we thought. What is often said and often right: The devil is in the details.&lt;/p&gt;&lt;h2&gt;The problem&lt;/h2&gt;&lt;p&gt;We want our origin server to control the caching behavior of CloudFront. As with any other CDN, this can be done with the &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Cache-Control&quot;&gt;&lt;code&gt;Cache-Control&lt;/code&gt;&lt;/a&gt; header. So we configured our origin to return &lt;code&gt;Cache-Control: max-age=10, s-maxage=60&lt;/code&gt; with every response.&lt;/p&gt;&lt;p&gt;This &lt;code&gt;Cache-Control&lt;/code&gt; header has 2 directives: &lt;code&gt;max-age&lt;/code&gt; and &lt;code&gt;s-maxage&lt;/code&gt;. &lt;code&gt;max-age&lt;/code&gt; tells the client how long the response should be cached in seconds. &lt;code&gt;s-maxage&lt;/code&gt; does the same, but for the CDN in between our origin and the client. So we can define a different caching time for the CDN and for the client. This is cool, as we can now cache our response on the CDN for a longer time (and update it when we need to or after the defined time), but still cache it on the clients for a shorter time and make sure they are always up-to-date.&lt;/p&gt;&lt;p&gt;In our case the browser should cache the resource for 10 seconds, and the CloudFront for 60 seconds. To test this header, we created a small sample application within AWS Lambda and CloudFront as CDN. The Lambda returns the given caching header and a small JSON body. Let’s check within the browsers network console what happens when we do multiple requests within 70 seconds:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;//images.ctfassets.net/54dnxp2417nl/7JPDm5y8woXjJQPEsACWWx/c1cc5ae7c37ae1f3416b9d01cc5ebdb3/1-problem.png&quot; alt=&quot;Requests are only partially cached&quot;/&gt;&lt;figcaption&gt;Requests are only partially cached&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;What do we see here?&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;The first request hit’s the Lambda function. This takes around 1 second, as the function is cold and uncached by CloudFront. The response gets now cached by the browser and CloudFront.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;The next 3 requests are not sent by the browser, as they are within 10 seconds, which is the &lt;code&gt;max-age&lt;/code&gt;. The browser just returns the cache. The request time is therefore 0 seconds.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;The next 7 requests are all done in the next 50 seconds. They hit the CloudFront cache, the response time is therefore around 20ms.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;60 seconds after the first request, CloudFront clears the cache. The request hits the lambda function, so it takes around 700ms. After that requests, the same procedure starts again.&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;What is wrong here?&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;The browser should cache every request for 10 seconds. But it only caches the first requests for the &lt;code&gt;max-age &lt;/code&gt;and doesn&amp;#39;t cache anything for the rest of the remaining &lt;code&gt;s-maxage&lt;/code&gt; time.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;After 10 seconds the browser requests the same resource again. As there was no change in the response body, CloudFront should only return &lt;code&gt;304&lt;/code&gt;. Instead, the whole body gets returned with a status &lt;code&gt;200&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Those 2 problems will result in&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Additional &lt;b&gt;traffic you have to pay &lt;/b&gt;between the browser and your CDN.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;A &lt;b&gt;slower website&lt;/b&gt;, as the browser has to wait for the request to complete. This problem increases if your response body gets larger or the network speed of your customer decreases (a.e. on mobile plans).&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Additional &lt;b&gt;traffic your customer has to pay &lt;/b&gt;if the data is not free (a.e. on mobile plans).&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;Fixing the browsers cache behavior&lt;/h2&gt;&lt;p&gt;We spend hours and hours figuring out why the browser only caches the response for the &lt;code&gt;max-age&lt;/code&gt; time and then ignores the cache for the rest of the &lt;code&gt;s-maxage&lt;/code&gt; time. As it turns out, we were not the first ones who stumbled upon this problem:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://www.cdnplanet.com/blog/cloudfront-cachability-date-header/&quot;&gt;Browser cachability issues with CloudFront (CDN Planet)&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://forums.aws.amazon.com/thread.jspa?messageID=807813&quot;&gt;CloudFront Date header cached indefinitely (AWS Forum)&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://stackoverflow.com/a/61493383/3141881&quot;&gt;CloudFront &amp;quot;age&amp;quot; header effect on &amp;quot;cache-control: private; max-age=3600&amp;quot; (Stackoverflow)&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;The root of the problem is the &lt;code&gt;date&lt;/code&gt; header returned by CloudFront. It doesn’t change on upcoming requests. As caching times in the &lt;code&gt;Cache-Control&lt;/code&gt; header are relative to the response &lt;code&gt;date&lt;/code&gt; header, only the first request by the browser gets cached for the &lt;code&gt;max-age&lt;/code&gt; time.&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;CDNs usually don&amp;#39;t cache the &lt;code&gt;date&lt;/code&gt; header, it&amp;#39;s only CloudFront that does it.&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;There is no easy way to fix this within some CloudFront settings. Only recently it is possible to solve this problem at all: With a custom CloudFront Function. CloudFront Functions are small Javascript functions that are executed with every request. You can use them to do simple changes to the request or response object. Read more about the possibilities and limitations in the official AWS docs here: &lt;a href=&quot;https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/functions-javascript-runtime-features.html&quot;&gt;https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/functions-javascript-runtime-features.html&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We can use those functions to update the &lt;code&gt;date&lt;/code&gt; header with every request.&lt;/p&gt;
            &lt;figure&gt;
              &lt;pre&gt;&lt;code class=&quot;js language-js&quot;&gt;function handler(event) {
  var response = event.response;

  response.headers[&apos;date&apos;] = {
    value: new Date().toUTCString()
  };
  delete response.headers[&apos;age&apos;];

  return response;
}
&lt;/code&gt;&lt;/pre&gt;
              &lt;figcaption&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
          &lt;p&gt;This code updates the &lt;code&gt;date&lt;/code&gt; header with the current time. It also deletes the &lt;code&gt;age&lt;/code&gt; header, as it turns out that CloudFront is also setting it. The &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Age&quot;&gt;age header&lt;/a&gt; is used to tell how long the cached object is in the cache. If it is set, the browser will compare it against the &lt;code&gt;max-age&lt;/code&gt; time and decide to not cache the object. Which is not what we want.&lt;/p&gt;&lt;p&gt;After deploying the CloudFront function, let’s check the browser console:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;//images.ctfassets.net/54dnxp2417nl/019e0Ukqusxx98oQHMehrA/21cda0b0083db4eae7b695ae9b9f78d6/2-improved.png&quot; alt=&quot;Requests are cached by the browser&quot;/&gt;&lt;figcaption&gt;Requests are cached by the browser&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;What do we see here:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;The first request hits Lambda, so it takes around 700ms.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;The requests within 10 seconds are cached. After that, one request is done to CloudFront. This request takes around 30ms and is cached again for 10 seconds by the browser. CloudFront returns the full response.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Only after 1 minute, the requests hits Lambda again and gets then cached again by CloudFront.&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;This is the behavior we want! Nice!&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;CloudFront Functions are $0.10 for 1 million executions, so they are quite cheap. More about the pricing on the official page: &lt;a href=&quot;https://aws.amazon.com/cloudfront/pricing/#Feature_Pricing&quot;&gt;https://aws.amazon.com/cloudfront/pricing/#Feature_Pricing&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;Next, let’s see how we can return &lt;code&gt;304&lt;/code&gt; if we hit CloudFront and the response hasn&amp;#39;t changed since the last request.&lt;/p&gt;&lt;h2&gt;Return 304 if the object hasn&amp;#39;t changed in CloudFront&lt;/h2&gt;&lt;p&gt;CloudFront always returns &lt;code&gt;200&lt;/code&gt; with the full response body. This results in a lot of unnecessary data sent between the browser and CloudFront. To fix this, we need to set the &lt;code&gt;ETag&lt;/code&gt; header in our Lambda function.&lt;/p&gt;&lt;p&gt;The &lt;code&gt;ETag&lt;/code&gt; is a hash for the response body. The browser will send this hash alongside all upcoming requests to the same resource. The server can then decide if the resource has changed and either return &lt;code&gt;200&lt;/code&gt; with a new resource or &lt;code&gt;304&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;Luckily, when the &lt;code&gt;ETag&lt;/code&gt; header is set, CloudFront will handle &lt;code&gt;200&lt;/code&gt; and &lt;code&gt;304&lt;/code&gt; automatically. We don&amp;#39;t have to configure anything. The &lt;code&gt;ETag&lt;/code&gt; needs to be created in our Lambda function. This is how the generation could look like:&lt;/p&gt;
            &lt;figure&gt;
              &lt;pre&gt;&lt;code class=&quot;js language-js&quot;&gt;const createEtag = (body: string) =&amp;gt; {
  const hash = createHash(&apos;md5&apos;).update(body).digest(&apos;hex&apos;);
  return `W/&quot;${hash}&quot;`
}
&lt;/code&gt;&lt;/pre&gt;
              &lt;figcaption&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
          &lt;p&gt;Depending on your usage, you may want to use different hashing algorithms that are more performant.&lt;/p&gt;&lt;p&gt;Now let’s check again our browser console:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;//images.ctfassets.net/54dnxp2417nl/3XuAOKTkdnDVw6dE56SdVe/7a238f96dd52ec7866269360187d6091/3-solution.png&quot; alt=&quot;CloudFront even returns 304&quot;/&gt;&lt;figcaption&gt;CloudFront even returns 304&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Now it’s perfect!&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;The first request hits Lambda. The response gets cached by the browser for 10 seconds and 60 seconds by CloudFront.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;The next 3 requests are within 10 seconds, so they are not sent over the network.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;After 10 seconds, the request get’s sent to CloudFront. CloudFront return &lt;code&gt;304 &lt;/code&gt;with an empty response body.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;After 60 seconds the request hits Lambda again.&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;Conclusion&lt;/h2&gt;&lt;p&gt;CloudFront is a very good CDN, but you need to know what to do. As CDNs are the most relevant when there is high traffic, mistakes can increase your bill a lot or even lead to downtimes of your API/website/product. That&amp;#39;s why it&amp;#39;s important to have a close look at the details. It gives you the confidence to scale.&lt;/p&gt;&lt;p&gt;If you want to add CloudFront to your API make sure that:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;when you have a different &lt;code&gt;s-maxage&lt;/code&gt; and &lt;code&gt;maxage&lt;/code&gt; you need to overwrite the &lt;code&gt;Date&lt;/code&gt; and &lt;code&gt;Age&lt;/code&gt; header in CloudFront.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;when you want to return &lt;code&gt;304&lt;/code&gt; if the response hasn&amp;#39;t changed since the last request, you need to set the &lt;code&gt;ETag&lt;/code&gt; header in your origin.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;I hope you learned something from this blog post. Thanks for reading :)&lt;/p&gt;&lt;p&gt;Check out the full project - including the CloudFormation template - on Github: &lt;a href=&quot;https://github.com/satellytes/learning-caching-headers&quot;&gt;https://github.com/satellytes/learning-caching-headers&lt;/a&gt;&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Felix Hamann – Senior Frontend Engineer]]></title><description><![CDATA[Felix Hamann ist der erste Angestellte von Satellytes und immer noch glücklich]]></description><link>https://satellytes.com/blog/post/interview-felix-hamann/</link><guid isPermaLink="false">https://satellytes.com/blog/post/interview-felix-hamann/</guid><pubDate>Tue, 01 Feb 2022 00:00:00 GMT</pubDate><content:encoded>&lt;img src=&quot;https://satellytes.com/_gatsby/image/5059b2a48722a403dfd4469ec28cfd9b/4be445bf02c55418e404abd8f2a1a674/felix-hero.jpg?eu=be34f23c17f217167e82c2278031faa33850124dd702defb607bea16c3568032eaa417d7f8cb8135fb60b0f080cce3698cf240cf27e9512fcb6b043eebd2817aeb75e15c1bc7e0dc9538a3203a02442720ce0b96a8ba4f3a0f2e465313b0738d1f5123cc4bbe5a11b9f59e6dc818e21c550e2d3ef019b02a9a2396ab247f5c2db3c621936e825671b77c80736292190f725103ed68fa1008b85a40da441c1425ddca1292751783160cda4a84a8e09cdc8d06c99ad6a86f7119aef69b18d0ebce545bb54823dcdeab8e051b69461b7542e976e0b64984c359335fc96e851068a2da3132&amp;amp;a=w%3D1440%26h%3D760%26fm%3Djpg%26q%3D75&amp;amp;cd=2022-03-25T12%3A42%3A13.108Z&quot; alt=&quot;&quot;/&gt; &lt;h2&gt;Interview mit Felix Hamann&lt;/h2&gt;&lt;p&gt;Felix Hamann ist unser Mitarbeiter #1 und damit seit fast vier Jahren Teil von Satellytes. Wir haben ihn zum Interview eingeladen, um zu erfahren was er erlebt hat und wie er sich weiterentwickeln will.&lt;/p&gt;&lt;p&gt;
&lt;b&gt;Hallo Felix. Schön, dass Du Dir die Zeit nimmst. Stell Dich doch mal kurz vor.
&lt;/b&gt;Hi! Ich bin Felix. Ich habe noch das Piepsgeräusch der 56k Modems im Ohr, bin also schon eine ganze Weile dabei. Seitdem ich denken kann faszinieren mich Computer und Webentwicklung.&lt;/p&gt;&lt;p&gt;
&lt;b&gt;Du bist der erste Angestellte bei Satellytes. Bist Du nach all den Jahren immer noch happy? Highlights? Lowlights?
&lt;/b&gt;Immer noch happy. Mit Ausrufezeichen! Highlights: Immer wieder ins kalte Wasser gestoßen zu werden, weil „Life begins at the end of your comfort zone&amp;quot;. Beispiele für „kaltes Wasser&amp;quot;: Vor kurzem habe ich zum ersten Mal eine Präsentation auf einer Entwickler-Konferenz „eMerge&amp;quot; gehalten und in einem meiner letzten Projekte hatte ich eine Managementrolle inne. Lowlights: Mir fällt eigentlich nur Corona ein, aber ich als introvertiertes Kellerkind bin zu Hause sowieso immer happy... trotzdem finde ich es schade, dass es letztes Weihnachten wieder keine solche legendäre Weihnachtsfeier wie 2019 auf der Hütte geben konnte.&lt;/p&gt;&lt;p&gt;
&lt;b&gt;Du hast den eMerge Talk als Highlight genannt. Wie kam’s dazu?
&lt;/b&gt;Wir benutzen Lattice als Career Development Tool bei Satellytes und dieser eMerge Talk war eines meiner „Goals&amp;quot;. Ich habe mit meinem Manager zusammen beschlossen, dass es eine gute Idee ist das mal auszuprobieren und mich mehr auf die Bühne zu wagen. Das Thema war „Automation mit Github Actions&amp;quot;, weil ich in meinem aktuellen Projekt sehr viel damit gemacht habe.&lt;/p&gt;&lt;p&gt;
&lt;b&gt;Und wie war’s?
&lt;/b&gt;Ich habe zuvor mit meinen Kollegen einige Dryruns gemacht, mit deren Feedbacks ich die Präsentation rund geschliffen habe und am Ende habe ich mich richtig gut damit gefühlt. Beim Talk selbst hatte ich anfangs bestimmt ein Tremolo in meiner Stimme, aber schnell gemerkt, dass ich richtig tief im Thema drinstecke und das daher auch gut erzählen kann. Ich war bei den Proben mit meinen Kollegen aufgeregter als beim Talk selbst. Ich habe sogar die QA-Fragen gut beantworten können vor denen ich ein bisschen Bammel hatte – ich war einfach so gut vorbereitet wie schon lange nicht mehr und das war super!&lt;/p&gt;&lt;p&gt;
&lt;b&gt;Mehr davon?
&lt;/b&gt;Auf jeden Fall.&lt;/p&gt;&lt;p&gt;
&lt;b&gt;Warum mehr?
&lt;/b&gt;Neben mir waren Sprecher von Google, Spotify und Microsoft auf der „Bühne&amp;quot;, da war ich schon ein bisschen stolz ein Teil davon zu sein. In erster Linie geht es mir aber darum, Wissen weiterzugeben. Kurze kompakte Präsentationen auf Meetups und Konferenzen sind meiner Meinung nach ein idealer Einstieg in diverse Themen. Von allen Entwicklerkonferenzen auf denen ich bisher war bin ich mit einer Liste von Technologien und neuen Methoden nach Hause gekommen, die ich unbedingt ausprobieren wollte. Die Vorstellung, dass meine Präsentation diesen Wunsch in anderen Entwicklern auslöst, fühlt sich klasse an.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;//images.ctfassets.net/54dnxp2417nl/3K6HfegIiKmg2glCpaSnmR/7d15421bea4ddd2181444925afbced55/felix-1.jpg&quot; alt=&quot;Felix&quot;/&gt;&lt;figcaption&gt;Felix&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;Programmieren ist im Wesentlichen, wie ich finde, ein äußerst kreativer Prozess.&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;b&gt;Wolltest Du schon immer Developer werden? Wenn Du nicht Entwickler geworden wärst, wärst Du heute ...
&lt;/b&gt;Bäcker, Schreiner, Skater, Bauer, die Bandbreite ist groß. Ich liebe kreative Handarbeit und ich genieße es Dinge zu erschaffen. Programmieren ist im Wesentlichen, wie ich finde, ein äußerst kreativer Prozess. Für jedes Problem gibt es meist eine Vielzahl an Lösungen und man muss kreativ und innovativ denken um die Beste zu finden. In den meisten Fällen gibt es außerdem nicht „die eine, beste Lösung&amp;quot;, das sorgt dafür, dass jede neue Herausforderung spannend bleibt. Es wird nie langweilig.&lt;/p&gt;&lt;p&gt;
&lt;b&gt;Wie haben sich deine Aufgaben in den letzten Jahren bei Satellytes geändert?
&lt;/b&gt;Ich war zuvor selbständig und habe mich nie an so große Projekte getraut wie ich sie hier bei Satellytes bekomme. Mir wurde von Anfang an sehr viel Vertrauen geschenkt und mir ist dadurch erst bewusst geworden was ich überhaupt kann – das ist wieder das Thema „ins kalte Wasser gestoßen zu werden&amp;quot; und „einfach machen&amp;quot;. Dadurch habe ich viel an Selbstsicherheit gewonnen. Die Aufgaben haben sich gar nicht groß geändert, aber ich gehe heute mit mehr Zuversicht an sehr große Aufgaben heran, weil ich mittlerweile aus Erfahrung sagen kann, dass man sie in kleinen Schritten immer bewältigt bekommt.&lt;/p&gt;&lt;p&gt;
&lt;b&gt;Wohin geht die Reise? Evangelist? Manager?
&lt;/b&gt;Ich will auf jeden Fall noch sehr lange programmieren. Leute oder Projekte managen will ich gerade noch nicht – diese abstrakte Managementebene turned mich nicht an. Ich will lieber knietief in Code stecken. Und das Wissen, das ich sammle will ich an andere Entwickler weitergeben. Ich will auch mehr Artikel schreiben, Präsentationen halten – das ganze Thema „Wissenstransfer&amp;quot; finde ich sehr spannend.&lt;/p&gt;&lt;p&gt;
&lt;b&gt;Thema „Wissen an andere Entwickler weitergeben&amp;quot;. Tipps für Einsteiger?
&lt;/b&gt;Einfache Antwort: YouTube und Google. Längere Antwort: Ich habe festgestellt, dass es unterschiedliche Lerner-Typen gibt. Ich selbst installiere einfach eine neue Sprache und fange an zu tippen und dann passiert von alleine irgendwas etwas. Ich programmiere dann einfach einen Taschenrechner oder eine Todo-Liste, irgendwas. Aber nicht alle haben diese Kreativität, oder wissen nicht wie sie geweckt werden kann. Viele Leute brauchen konkret vorgegebene, erreichbare Ziele auf die sie hinarbeiten können. Gerade wenn es darum geht eine neue Sprache/Technologie zu erlernen. Es gibt sehr viele Listen mit großartigen Projekten, die man ausprobieren kann um ein Gefühl zu bekommen. Einfach nach „Beginner Projekte für Einstieg in ...&amp;quot; googeln. Da findet man 1000 Projekte, die man machen kann.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;//images.ctfassets.net/54dnxp2417nl/1ugpi7r5mwlSZDZnIrz52P/feff1f03c3e8245576cfdf41875263b4/felix-2.jpg&quot; alt=&quot;Felix&quot;/&gt;&lt;figcaption&gt;Felix&lt;/figcaption&gt;&lt;/figure&gt;&lt;blockquote&gt;&lt;p&gt;Ich vergesse zu essen, trinken, ich bin immer total im Tunnel.&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;b&gt;Klingt so als wärst Du immer lernhungrig und bräuchtest nie eine Pause ...
&lt;/b&gt;Wenn ich nicht von Jemandem abgelenkt werde (Freundin ❤️), vergesse ich alles um mich herum. Ich vergesse zu essen, trinken, ich bin immer total im Tunnel. Ich überhöre sogar den Pomodoro-Timer, den mir ein Kollege mal dafür empfohlen hat.&lt;/p&gt;&lt;p&gt;
&lt;b&gt;Aber Wochenenden bekommst Du schon mit, oder? Was machst Du dann?
&lt;/b&gt;Wenn’s das Wetter erlaubt gehe ich Gleitschirm fliegen, „Paragliden&amp;quot;. Generell verbringe ich viel Zeit in der Natur, beim Pilze sammeln oder Bergsteigen. Ansonsten programmieren. Zur Zeit beispielsweise machen viele meiner Kollegen und ich bei „Advent of Code&amp;quot; mit. Das ist ein Adventskalender für Nerds mit täglich zwei spannenden Programmier-Herausforderungen. Challenges, die ich unter der Woche nicht geschafft habe, hole ich dann am Wochenende nach. Und (natürlich) viel Quality Time mit meiner Freundin.&lt;/p&gt;&lt;p&gt;
&lt;b&gt;Wie bist Du auf’s Paragliding gekommen? Gibt es Gemeinsamkeiten oder Gegensätze zu deiner Arbeit?
&lt;/b&gt;Durch meinen Bruder. Beim Paragliden kann man sich nur mit viel Erfahrung ein konkretes Ziel setzen, aber meistens fliegt man einfach drauf los und schaut wie Wind und Wetter mitmachen. Man kann schon sagen: „Ich versuche zu diesem und jenem Gebirgskamm zu fliegen.&amp;quot;, aber es ist nicht planbar, nicht systematisch. Man ist der Umwelt ausgeliefert, einer plötzlichen Wolke vor der Sonne, einer anderen Windrichtung wenn man ein bisschen höher oder tiefer fliegt. Man ist im Hier und Jetzt und gibt die Kontrolle ab – ein willkommener Unterschied zum Entwickeln, wo man doch im Großen und Ganzen „Herr der Lage&amp;quot; ist.&lt;/p&gt;&lt;p&gt;
&lt;b&gt;Schön beschrieben, danke dafür. Apropos Hier und Jetzt. Was steht heute noch an?
&lt;/b&gt;Wir sind heute mit einer neuen Version von Satellytes.com live gegangen und haben da noch ein bisschen was zu tun. Außerdem geht einer meiner Kollegen bald für drei Wochen in den Urlaub, deswegen müssen noch zwei Pull Requests von ihm gereviewed und gemerged werden solange er noch da ist – und unbedingt abspülen. Mein Zuhause sieht aktuell aus wie S...&lt;/p&gt;&lt;p&gt;
&lt;b&gt;Zuhause ist ...
&lt;/b&gt;... wo sich mein Handy automatisch mit dem WLAN verbindet. Klingt bisschen klischeehaft, aber der Spruch bewahrheitet sich immer wieder. Ich nehme mir nur dort die Zeit mich mit dem Internet zu verbinden, wo ich es mag und vielleicht nochmal herkommen möchte.&lt;/p&gt;&lt;p&gt;
&lt;b&gt;Letzte Worte?
&lt;/b&gt;Ich freue mich auf die nächsten &lt;code&gt;3.75 * x&lt;/code&gt; Jahre bei Satellytes 🙌&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Getting Started: Gatsby vs. Next.js vs. Remix]]></title><description><![CDATA[We developed a simple blog application in Gatsby, Next.js and Remix. Learn about the differences in the development process and the technical concepts behind these three frameworks.]]></description><link>https://satellytes.com/blog/post/getting-started-gatsby-next-remix/</link><guid isPermaLink="false">https://satellytes.com/blog/post/getting-started-gatsby-next-remix/</guid><pubDate>Thu, 27 Jan 2022 00:00:00 GMT</pubDate><enclosure url="https://images.ctfassets.net/54dnxp2417nl/5fCePk8aewwPIKCj9I5aTj/b652db31186358c555df2db14b65bbb7/gatsby-next-remix-hero.jpg" length="744356" type="image/jpeg" /><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://satellytes.com/_gatsby/image/38d8fb8fe42cc85f9ef7672ad7a1509a/4be445bf02c55418e404abd8f2a1a674/gatsby-next-remix-hero.jpg?eu=b832f56816f1134026d8c6238064acad3a5e45188d068ff96529b745c8518063e3fe43d2adc8db61ff62eca6809ab36d8cf5169277e40328cc3b566ab9858276bb24b15748c4e1dbc039a2256004177320995ec3a4bc496d5e2d165b4eec268d4a01779d4ab9081eecf1c7659c1aee1a550e7533b055f969c33983aa3d6a4b3bfac76d8e65824267a12690296a961e53221114ad7eef5613bc594ad8135f6028ba8c118e694f8e120bc140ee8ce8bbfcab20c3f6dda814771ccdffd649d7ef9a080ab74923d18dfbdd08493f17487211bf22e6bf5280900038458631cf0566f8c3232c9215d59711e5444c2ee4ededde9e85d53b4ad0df&amp;amp;a=w%3D1440%26h%3D760%26fm%3Djpg%26q%3D75&amp;amp;cd=2022-03-25T15%3A00%3A12.598Z&quot; alt=&quot;&quot;/&gt;&lt;figcaption&gt;&lt;a href=&quot;https://unsplash.com/photos/K59MPijxRh0&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Image by Daniel Kudela&lt;/a&gt;&lt;/figcaption&gt;&lt;/figure&gt; &lt;p&gt;Before starting a React based project, the same question often arises: Which framework should be used? Of course, this question cannot be answered in a general way, since each framework has its advantages and disadvantages for specific use cases. Nevertheless, you can compare the frameworks, especially the concepts behind them.&lt;/p&gt;&lt;p&gt;That&amp;#39;s why we decided to develop a simple blog application in Gatsby, Next.js and Remix to compare the frameworks. This application can read data from markdown files, display them and create dynamic routes depending on them. This article will discuss the differences in the development process, as well as the basic technical concepts in the frameworks. The three versions of the comparison blog project were each deployed on Vercel or Netlify and have a public GitHub repository.&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;💡 For simplification, style and images are not included in the examples. The detailed versions are available in the &lt;a href=&quot;https://github.com/satellytes/blog-app-comparison&quot;&gt;GitHub repository&lt;/a&gt; for the comparison blog project.&lt;/p&gt;&lt;/blockquote&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Blog app Gatsby Version:&lt;/b&gt; &lt;a href=&quot;https://gatsby-comparison-blog.vercel.app/&quot;&gt;Preview&lt;/a&gt; and &lt;a href=&quot;https://github.com/satellytes/blog-app-comparison/tree/main/gatsby-comparison-blog&quot;&gt;Repository&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Blog app Next.js Version:&lt;/b&gt; &lt;a href=&quot;https://next-js-comparison-blog.vercel.app/&quot;&gt;Preview&lt;/a&gt; and &lt;a href=&quot;https://github.com/satellytes/blog-app-comparison/tree/main/next-comparison-blog&quot;&gt;Repository&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Blog app Remix Version:&lt;/b&gt; &lt;a href=&quot;https://remix-comparison-blog.netlify.app/&quot;&gt;Preview&lt;/a&gt; and &lt;a href=&quot;https://github.com/satellytes/blog-app-comparison/tree/main/remix-comparison-blog&quot;&gt;Repository&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;figure&gt;&lt;img src=&quot;//images.ctfassets.net/54dnxp2417nl/2xeZZpwBzeh7Tb3OP9FjcU/9aa4661859436f6ab844ee909495b724/gastby-next-remix-screenshot-blog-overview.png&quot; alt=&quot;&quot;/&gt;&lt;figcaption&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;Setting up a project&lt;/h2&gt;&lt;h4&gt;Gatsby&lt;/h4&gt;&lt;p&gt;To start a Gatsby project you have to run &lt;code&gt;npx gatsby new&lt;/code&gt;. The setup process offers many individualization possibilities: Besides the project name and path, a CMS, a styling system (e.g. styled-components, emotion, ...), and additional features with other plugins (e.g. mdx support) can be added optionally. Gatsby has built-in out-of-the-box TypeScript support, so there is no distinction between TypeScript and JavaScript in the project setup.&lt;/p&gt;&lt;h4&gt;Next.js&lt;/h4&gt;&lt;p&gt;The command &lt;code&gt;npx create-next-app@latest&lt;/code&gt; can additionally be extended with the flag &lt;code&gt;--ts&lt;/code&gt; to add direct TypeScript support to a new Next.js project. The following setup process does not provide any customization options apart from the project name.&lt;/p&gt;&lt;h4&gt;Remix&lt;/h4&gt;&lt;p&gt;A Remix project can be set up with the command &lt;code&gt;npx create-remix@latest&lt;/code&gt;. Then you can specify the project name, choose between different host options (e.g. Netlify or Vercel) and between TypeScript and JavaScript.&lt;/p&gt;&lt;h2&gt;Static Site Generation&lt;/h2&gt;&lt;p&gt;With static site generation (SSG), the HTML is generated once at built time and reused for each request. Of the three frameworks in this article, only Remix does not support SSG.&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;⚡️ The options shown below for loading data only works in page/template components (they are bound to a certain url path or directory). To load data in components that do not have their own route, you must use other methods&lt;/p&gt;&lt;/blockquote&gt;&lt;h4&gt;&lt;b&gt;Gatsby&lt;/b&gt;&lt;/h4&gt;&lt;p&gt;In general, there are two ways to create data-dependent pages in Gatsby. In our comparison blog project, pages are implicitly created using the file-based API. Alternatively, you can create pages manually using the &lt;code&gt;create-pages&lt;/code&gt; function in &lt;code&gt;gatsby-node.js&lt;/code&gt;. In the following an example is given for both variants:&lt;/p&gt;&lt;p&gt;&lt;b&gt;With file-based API&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A static generated page with the file-based API consists of two parts: A GraphQL query and the actual React component (here &lt;code&gt;BlogPost&lt;/code&gt;), which must be exported as default. In the GraphQL query, the required data is fetched. In this example, the Gatsby plugin &lt;a href=&quot;https://www.gatsbyjs.com/plugins/gatsby-transformer-remark/&quot;&gt;gatsby-transformer-remark&lt;/a&gt; is used to get the content of the corresponding markdown file. In the actual component, the results of the query can then be accessed via &lt;code&gt;data&lt;/code&gt;.&lt;/p&gt;
            &lt;figure&gt;
              &lt;pre&gt;&lt;code class=&quot;tsx{3,9-18} language-tsx{3,9-18}&quot;&gt;// pages/blog/{markdownRemark.frontmatter__path}.tsx

const BlogPost = ({data}) =&amp;gt; {
    return (
        &amp;lt;div dangerouslySetInnerHTML={{__html: data.markdownRemark.html}}/&amp;gt;
    )
}

export const query = graphql`
    query ($id: String) {
        markdownRemark(id: {eq: $id}) {
            frontmatter {
                title
                path
            }
            html
        }
    }
`

export default BlogPost
&lt;/code&gt;&lt;/pre&gt;
              &lt;figcaption&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
          &lt;p&gt;In our Gatsby blog project, we created a file named &lt;code&gt;{markdownRemark.frontmatter__path}.tsx&lt;/code&gt; to create a route for each blogpost. It is important that the filename consists of the &lt;b&gt;path with the relevant key from the GraphQL query&lt;/b&gt;(here: &lt;code&gt;path&lt;/code&gt;), which later determines the route of the page. In addition, the filename must be enclosed in curly brackets.&lt;/p&gt;&lt;p&gt;For example, the &lt;code&gt;path&lt;/code&gt; field in the markdown file of the first blogposts contains &amp;quot;first-blogpost&amp;quot;. The file-based API implicitly creates a route (&lt;a href=&quot;https://gatsby-comparison-blog.vercel.app/blog/first-blogpost&quot;&gt;https://gatsby-comparison-blog.vercel.app/blog/first-blogpost&lt;/a&gt;) and the remaining data (&lt;code&gt;html&lt;/code&gt;field in the GaphQL query) is loaded into the page.&lt;/p&gt;&lt;p&gt;&lt;b&gt;With create-pages API&lt;/b&gt;&lt;/p&gt;&lt;p&gt;To create a page with the create-pages API, a &lt;code&gt;createPages&lt;/code&gt; function must be defined in &lt;code&gt;gatsby-node.js&lt;/code&gt;. In this function, the data is then loaded with a GraphQL query and passed into a template page. For each entry from the result of the &lt;code&gt;query&lt;/code&gt;the &lt;code&gt;createPage&lt;/code&gt; action is called, in which &lt;code&gt;path&lt;/code&gt;, template &lt;code&gt;component&lt;/code&gt;, and &lt;code&gt;context&lt;/code&gt; are provided. An example from the &lt;a href=&quot;https://www.gatsbyjs.com/docs/creating-and-modifying-pages/#creating-pages-in-gatsby-nodejs&quot;&gt;Gatsby documentation&lt;/a&gt; is given here:&lt;/p&gt;
            &lt;figure&gt;
              &lt;pre&gt;&lt;code class=&quot;tsx{7,8,11,37-45} language-tsx{7,8,11,37-45}&quot;&gt;// gatsby-node.js

const path = require(&quot;path&quot;)

// Implement the Gatsby API “createPages”. This is called once the
// data layer is bootstrapped to let plugins create pages from data.
exports.createPages = async ({ graphql, actions, reporter }) =&amp;gt; {
  const { createPage } = actions

  // Query for markdown nodes to use in creating pages.
  const result = await graphql(
    `
      {
        allMarkdownRemark(limit: 1000) {
          edges {
            node {
              frontmatter {
                path
              }
            }
          }
        }
      }
    `
  )

  // Handle errors
  if (result.errors) {
    reporter.panicOnBuild(`Error while running GraphQL query.`)
    return
  }

  // Create pages for each markdown file.
  const blogPostTemplate = path.resolve(`src/templates/blog-post.js`)
  result.data.allMarkdownRemark.edges.forEach(({ node }) =&amp;gt; {
    const path = node.frontmatter.path
    createPage({
      path,
      component: blogPostTemplate,
      // In your blog post template&apos;s graphql query, you can use pagePath
      // as a GraphQL variable to query for data from the markdown file.
      context: {
        pagePath: path,
      },
    })
  })
}
&lt;/code&gt;&lt;/pre&gt;
              &lt;figcaption&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
          &lt;h4&gt;&lt;b&gt;Next.js&lt;/b&gt;&lt;/h4&gt;&lt;p&gt;The roots of Next.js are in SSR, but relatively soon they also supported SSG. Thus, this framework supports both approaches well.&lt;/p&gt;&lt;p&gt;To create a static generated page in Next.js the &lt;code&gt;async&lt;/code&gt; function &lt;code&gt;getStaticPaths&lt;/code&gt; has to be exported. In the code snippet below, this function calls &lt;code&gt;getAllPostPaths()&lt;/code&gt;, which returns a path for each markdown file.&lt;/p&gt;
            &lt;figure&gt;
              &lt;p&gt;```tsx{3,13-16,18,21-23, 27}
// pages/blog/[path].tsx&lt;/p&gt;
&lt;p&gt;export async function getStaticPaths() {
    // That&apos;s the data format we expect:
    //     paths: [
    //         {params: {path: &apos;first-blogpost&apos;}},
    //         {params: {path: &apos;second-blogpost&apos;}},
    //         …
    //         {params: {path: &apos;fifth-blogpost&apos;}}
    //     ],
    const paths = getAllPostPaths()&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;return {
    paths,
    fallback: false
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;export async function getStaticProps({params}: { params: PostsData }) {
    const postData = await getPostData(params.path)
    return {
        props: {
            postData
        }
    }
}&lt;/p&gt;
&lt;p&gt;export default function Post({postData}: { postData: PostData }) {
    return (
            &lt;div dangerouslySetInnerHTML={{__html: postData.contentHtml}}/&gt;
    )
}
```&lt;/p&gt;
              &lt;figcaption&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
          &lt;p&gt;&lt;code&gt;getStaticPaths&lt;/code&gt; must return an object with the keys:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;path:&lt;/code&gt; This key determines which path will be pre-rendered. In the in-code comment above the structure of &lt;code&gt;path&lt;/code&gt; is given as an example.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;fallback&lt;/code&gt;: You can set the value of fallback to &lt;code&gt;true&lt;/code&gt;, &lt;code&gt;false&lt;/code&gt; or &lt;code&gt;blocking&lt;/code&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;false &lt;/code&gt;→ Any paths not returned by &lt;code&gt;getStaticPaths&lt;/code&gt; will end up in a 404 page&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;true&lt;/code&gt; → On the first request to a not generated path, Next.js will serve a fallback version of the page, instead of a 404 page. The HTML and JSON of this path is now generated in the background and and then the JSON is sent to the requesting browser. Now the fallback page changes into the full page. Next.js will add this path to the pre-rendered pages in order to be able to provide the already generated page for further requests. This is useful if you have a page with a lot of static pages because then not all pages have to be generated at built time, which makes the built much faster.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;blocking &lt;/code&gt;→ Same procedure as for &lt;code&gt;fallback: true&lt;/code&gt;, except that there is no fallback while the HTML is being generated. There are only very special uses cases in which this makes sense, such as AMP.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Remember to name the file after the relevant key from the &lt;code&gt;params&lt;/code&gt; object with square brackets, in our case &lt;code&gt;[path].tsx&lt;/code&gt;. As long as the two names match, you can choose it as you wish. To load the data for a blogpost the function &lt;code&gt;getStaticProps&lt;/code&gt; is needed. This function now receives &lt;code&gt;{params}&lt;/code&gt;, which can be used to determine the path and the depending data. Finally, in the actual page component, the data can be accessed via props (here via &lt;code&gt;{postData}&lt;/code&gt;). The source code above shows how we built our comparison blog project using SSG and the methods just described.&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;💡 The object returned by &lt;code&gt;getStaticProps&lt;/code&gt; can include other keys besides &lt;code&gt;props&lt;/code&gt;, such as &lt;code&gt;revalidate&lt;/code&gt;. &lt;code&gt;revalidate&lt;/code&gt; is set to &lt;code&gt;false&lt;/code&gt; by default, but can also contain the amount in seconds after which a page re-generation can occur. In this way, individual static pages can be changed at a certain interval after being built. This is called &lt;a href=&quot;https://vercel.com/docs/concepts/next.js/incremental-static-regeneration&quot;&gt;Incremental Static Regeneration (ISR)&lt;/a&gt; and also known as &amp;quot;stale-while-revalidate&amp;quot;.&lt;/p&gt;&lt;/blockquote&gt;&lt;h4&gt;&lt;b&gt;Remix&lt;/b&gt;&lt;/h4&gt;&lt;p&gt;Remix only supports server side rendering, but this need not be a disadvantage. This is because CDN with proper caching headers will always be fast, except for cold requests (e.g. the first request). If the backend is too slow on these cold requests, this is a problem from the backend, which should then be improved. Also, it should be assumed that cold requests are rare. If this is not the case, it is a business problem and not a technical problem.&lt;/p&gt;&lt;h2&gt;Server Side Rendering (SSR)&lt;/h2&gt;&lt;p&gt;With server side rendering (SSR), the HTML is built on each request. All three frameworks support SSR. Usually, you use SSR in combination with a CDN to improve performance and responsiveness.&lt;/p&gt;&lt;h4&gt;&lt;b&gt;Gatsby&lt;/b&gt;&lt;/h4&gt;&lt;p&gt;Besides static site generation (SSG) you can also use server side rendering (SSR) for certain use cases in Gatsby since version 4. For this, the function &lt;code&gt;getServerData&lt;/code&gt; must be built into a page, in which the data is requested from the server. This data can then be accessed in the actual page component with &lt;code&gt;serverData&lt;/code&gt;. In the following the example from the &lt;a href=&quot;https://www.gatsbyjs.com/docs/how-to/rendering-options/using-server-side-rendering/&quot;&gt;Gatsby documentation&lt;/a&gt; is considered:&lt;/p&gt;
            &lt;figure&gt;
              &lt;pre&gt;&lt;code class=&quot;tsx{5,14} language-tsx{5,14}&quot;&gt;// pages/ssr.js

import * as React from &quot;react&quot;

const SSRPage = ({ serverData }) =&amp;gt; (
  &amp;lt;main&amp;gt;
    &amp;lt;h1&amp;gt;SSR Page with Dogs&amp;lt;/h1&amp;gt;
    &amp;lt;img alt=&quot;Happy dog&quot; src={serverData.message} /&amp;gt;
  &amp;lt;/main&amp;gt;
)

export default SSRPage

export async function getServerData() {
  try {
    const res = await fetch(`https://dog.ceo/api/breeds/image/random`)

    if (!res.ok) {
      throw new Error(`Response failed`)
    }

    return {
      props: await res.json(),
    }
  } catch (error) {
    return {
      status: 500,
      headers: {},
      props: {}
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;
              &lt;figcaption&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
          &lt;h4&gt;&lt;b&gt;Next.js&lt;/b&gt;&lt;/h4&gt;&lt;p&gt;To use SSR in Next.js you have to use &lt;code&gt;getServerSideProps&lt;/code&gt; instead of &lt;code&gt;getStaticProps&lt;/code&gt; in the SSG variant. This function must load the data and return it, too. The data can then be accessed in the page component (in the example via &lt;code&gt;data&lt;/code&gt;). The following example shows a simple SSR implementation from the &lt;a href=&quot;https://nextjs.org/docs/basic-features/pages#server-side-rendering&quot;&gt;Next.js documentation&lt;/a&gt;.&lt;/p&gt;
            &lt;figure&gt;
              &lt;pre&gt;&lt;code class=&quot;tsx{3,8} language-tsx{3,8}&quot;&gt;// pages/ssr.js

function Page({ data }) {
  // Render data...
}

// This gets called on every request
export async function getServerSideProps() {
  // Fetch data from external API
  const res = await fetch(`https://.../data`)
  const data = await res.json()

  // Pass data to the page via props
  return { props: { data } }
}

export default Page
&lt;/code&gt;&lt;/pre&gt;
              &lt;figcaption&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
          &lt;h4&gt;&lt;b&gt;Remix&lt;/b&gt;&lt;/h4&gt;&lt;p&gt;Remix has an exported &lt;code&gt;loader&lt;/code&gt; function in which the data (e.g. local markdown file) is loaded (similar to &lt;code&gt;getStaticProps&lt;/code&gt;in Next.js). This &lt;code&gt;loader&lt;/code&gt; function can receive a &lt;code&gt;{params}&lt;/code&gt; object. &lt;code&gt;{params}&lt;/code&gt; can be used to access the path with &lt;code&gt;params.slug&lt;/code&gt; and load the corresponding data. If you use the &lt;code&gt;params&lt;/code&gt; object and want to build the route depending on the data, it is important to name your file with a &lt;code&gt;$&lt;/code&gt; character and the key of the pathname. So in our example, it is &lt;code&gt;$slug.tsx&lt;/code&gt;. In the page component (here &lt;code&gt;PostSlug&lt;/code&gt;) the data can then be accessed via the &lt;code&gt;useLoader&lt;/code&gt; hook.&lt;/p&gt;
            &lt;figure&gt;
              &lt;pre&gt;&lt;code class=&quot;tsx{3,9} language-tsx{3,9}&quot;&gt;// routes/blog/$slug.tsx

export const loader: LoaderFunction = async ({params}) =&amp;gt; {
    invariant(params.slug, &quot;expected params.slug&quot;);
    return getPost(params.slug);
};

export default function PostSlug() {
    const post = useLoaderData();
    return (
            &amp;lt;div dangerouslySetInnerHTML={{ __html: post.html }} /&amp;gt;
    );
}
&lt;/code&gt;&lt;/pre&gt;
              &lt;figcaption&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
          &lt;blockquote&gt;&lt;p&gt;💡 Other than Next.js and Gatsby, Remix can&amp;#39;t just return components from the SSR routes. Remix can also return other data, like images or PDF. This feature is called &amp;quot;Resource routes&amp;quot;. You can read more about this in the &lt;a href=&quot;https://remix.run/docs/en/v1/guides/resource-routes&quot;&gt;official documentation&lt;/a&gt;.&lt;/p&gt;&lt;/blockquote&gt;&lt;h2&gt;Adding Page Metadata&lt;/h2&gt;&lt;p&gt;The page header data, such as the html title, meta description and structural data like &lt;a href=&quot;https://ogp.me/&quot;&gt;open graph&lt;/a&gt; are especially important for SEO. In the following examples, some meta tags should be added to the pages. For this, each framework offers its own solution.&lt;/p&gt;&lt;h4&gt;&lt;b&gt;Gatsby&lt;/b&gt;&lt;/h4&gt;&lt;p&gt;To add page metadata in Gatsby, the &lt;code&gt;gatsby-plugin-react-helmet&lt;/code&gt; and &lt;code&gt;React Helmet&lt;/code&gt; are recommended. Generally, Gatsby plugins are installed via a package manager and then have to be added to &lt;code&gt;gatsby-config.js&lt;/code&gt;. So in our example blog we first had to run &lt;code&gt;npm install gatsby-plugin-react-helmet react-helmet&lt;/code&gt; and then add the plugin to &lt;code&gt;gatsby-config.js&lt;/code&gt;:&lt;/p&gt;
            &lt;figure&gt;
              &lt;pre&gt;&lt;code class=&quot;jsx language-jsx&quot;&gt;// gatsby-config.js
{
  plugins: [`gatsby-plugin-react-helmet`]
}
&lt;/code&gt;&lt;/pre&gt;
              &lt;figcaption&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
          &lt;p&gt;After that, you can access the &lt;code&gt;React Helmet&lt;/code&gt; within the JSX of a component, like for example in the index page.&lt;/p&gt;
            &lt;figure&gt;
              &lt;pre&gt;&lt;code class=&quot;tsx{9-13} language-tsx{9-13}&quot;&gt;// pages/blog/index.tsx

//...
import { Helmet } from &quot;react-helmet&quot;

const Index = () =&amp;gt; {
    return (
        &amp;lt;Layout&amp;gt;
            &amp;lt;Helmet&amp;gt;
                &amp;lt;title&amp;gt;Gatsby Blog&amp;lt;/title&amp;gt;
                &amp;lt;meta name=&quot;description&quot; content=&quot;A simple Gatsby blog application&quot; /&amp;gt;
                &amp;lt;meta property=&quot;og:image&quot; content=&quot;https://josiesshakeshack.com/logo.jpg&quot; /&amp;gt;
            &amp;lt;/Helmet&amp;gt;
            {/*content goes here*/}
        &amp;lt;/Layout&amp;gt;
    );
}
&lt;/code&gt;&lt;/pre&gt;
              &lt;figcaption&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
          &lt;h4&gt;&lt;b&gt;Next.js&lt;/b&gt;&lt;/h4&gt;&lt;p&gt;Next.js provides a &lt;code&gt;head&lt;/code&gt; component that can be built into any page to add metadata.&lt;/p&gt;
            &lt;figure&gt;
              &lt;pre&gt;&lt;code class=&quot;tsx{9-13} language-tsx{9-13}&quot;&gt;// pages/blog/index.tsx

//...
import Head from &quot;next/head&quot;;

const Home: NextPage = () =&amp;gt; {
    return (
        &amp;lt;Layout&amp;gt;
            &amp;lt;Head&amp;gt;
                &amp;lt;title&amp;gt;Next.js Blog&amp;lt;/title&amp;gt;
                &amp;lt;meta name=&quot;description&quot; content=&quot;A simple Next.js blog application&quot; /&amp;gt;
                &amp;lt;meta property=&quot;og:image&quot; content=&quot;https://josiesshakeshack.com/logo.jpg&quot; /&amp;gt;
            &amp;lt;/Head&amp;gt;
            {/*content goes here*/}
        &amp;lt;/Layout&amp;gt;
    );
}
&lt;/code&gt;&lt;/pre&gt;
              &lt;figcaption&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
          &lt;h4&gt;&lt;b&gt;Remix&lt;/b&gt;&lt;/h4&gt;&lt;p&gt;To add metadata to Remix projects you have to add the &lt;code&gt;&amp;lt;Meta /&amp;gt;&lt;/code&gt; component in the &lt;code&gt;&amp;lt;head&amp;gt;&lt;/code&gt; part of &lt;code&gt;root.tsx&lt;/code&gt;. After that, a &lt;code&gt;meta&lt;/code&gt; function can be exported to other pages. This must return an object with all relevant metadata.&lt;/p&gt;&lt;p&gt;The meta function automatically distinguishes between three different meta data categories:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;title&lt;/code&gt; renders a &lt;code&gt;&amp;lt;title&amp;gt;&lt;/code&gt; tag&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;OpenGraph&lt;/code&gt; tags (e.g. &lt;code&gt;&amp;quot;og:image”&lt;/code&gt;) will render &lt;code&gt;&amp;lt;meta property content&amp;gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Everything else renders &lt;code&gt;&amp;lt;meta name={key} content={value}/&amp;gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;
            &lt;figure&gt;
              &lt;pre&gt;&lt;code class=&quot;tsx{6-17} language-tsx{6-17}&quot;&gt;// routes/blog/index.tsx

//...
import {MetaFunction} from &quot;remix&quot;;

export const meta: MetaFunction = () =&amp;gt; {
    return {
        // &amp;lt;title&amp;gt;Remix Blog&amp;lt;/title&amp;gt;
        title: &quot;Remix Blog&quot;,

        // &amp;lt;meta name=&quot;description&quot; content=&quot;A simple Remix blog application&quot;&amp;gt;
        description: &quot;A simple Remix blog application&quot;,

        // &amp;lt;meta property=&quot;og:image&quot; content=&quot;https://josiesshakeshack.com/logo.jpg&quot;&amp;gt;
        &quot;og:image&quot;: &quot;https://josiesshakeshack.com/logo.jpg&quot;
    };
};

export default function Index() {
  return (
    &amp;lt;Layout&amp;gt;
          {/*content goes here*/}
    &amp;lt;/Layout&amp;gt;
  );
}
&lt;/code&gt;&lt;/pre&gt;
              &lt;figcaption&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
          &lt;h2&gt;Conclusion&lt;/h2&gt;&lt;p&gt;Next.js and Gatsby have quite a lot in common as they support both SSR and SSG. The differences are more in detail such as incremental static generation in Next.js or incremental builds in Gatsby. However, it is noticeable that SSR in Gatsby is still a relatively new and not as developed feature as it is in Next.js.&lt;/p&gt;&lt;p&gt;Remix is the newest of these three frameworks and only supports SSR. However, with the appropriate headers, SSG is approached very closely, which means that it may be possible to completely replace real SSG. The developers of Remix have published an interesting &lt;a href=&quot;https://www.youtube.com/watch?v=bfLFHp7Sbkg&quot;&gt;video&lt;/a&gt; and &lt;a href=&quot;https://remix.run/blog/remix-vs-next&quot;&gt;blog post&lt;/a&gt; about this.&lt;/p&gt;&lt;p&gt;Thanks for reading my article about the different frameworks. I hope you learned something about the basic concepts behind Gatsby, Next.js and Remix. As I mentioned in the introduction, there is no clear answer to the question &amp;quot;Which framework should be used in my next project?&amp;quot; because every project has its individual requirements.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[How enterprises benefit from scoped npm registries]]></title><description><![CDATA[Why enterprises benefit from scoped npm registries and how to use them]]></description><link>https://satellytes.com/blog/post/enterprises-benefit-from-scoped-npm-registries/</link><guid isPermaLink="false">https://satellytes.com/blog/post/enterprises-benefit-from-scoped-npm-registries/</guid><pubDate>Mon, 17 Jan 2022 00:00:00 GMT</pubDate><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://satellytes.com/_gatsby/image/3bb7f840cd2f0404ddf4af2ec1ac313e/4be445bf02c55418e404abd8f2a1a674/enterprises-benefit-from-scoped-npm-registries.jpg?eu=ee64a76844f241477f8d932d806cabaf6a57481e8503dbfa6375be42ce01d764b6f143d4f8c88530a435ebfa82cbb13ad6fc439c20b2027b9e6c066def868a71e82fe05b4fc4efd9c63ea62c3150137223cb09c7a2bc1d6a0170031e5bfb79c404592f9e4fbf1808ecb3c035d908b30c1e187933f042f56dc462c1b27b2a0a7fae846dd03cd36e3aa04f9f1049c30e4f002604e87de16444fb42198e5d1f317eb3da1bd42518dd620da74ae6ddbefaeec351b88c8ff765231efbba9c4595bfda1c1aed0b779a96aa8d5e4f6c4b093b11ff29e9a31581c9453f43c968900f2afed5263ccc0fc28600bb184333ea&amp;amp;a=w%3D1440%26h%3D760%26fm%3Djpg%26q%3D75&amp;amp;cd=2022-03-25T11%3A10%3A44.561Z&quot; alt=&quot;&quot;/&gt;&lt;figcaption&gt;&lt;a href=&quot;https://unsplash.com/photos/oZMUrWFHOB4&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Image by Paul Esch-Laurent&lt;/a&gt;&lt;/figcaption&gt;&lt;/figure&gt; &lt;h2&gt;What is this all about?&lt;/h2&gt;&lt;p&gt;Nowadays almost every programming language comes with its package management solution, so developers can easily share packages with other developers around the world. For Python it is pip, for .NET it&amp;#39;s NuGet. npm is the package manager solution for JavaScript-based languages. It is used to create and use node packaged modules and is built into the JavaScript platform &lt;a href=&quot;http://www.nodejs.org/&quot;&gt;Node.js&lt;/a&gt;. The central component behind these package managers is a registry. A registry is a database of packages, each comprised of software and metadata. For example, the public registry for npm is &lt;a href=&quot;http://registry.npmjs.org/&quot;&gt;registry.npmjs.org&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Besides using public registries, companies can establish their private registries in their company network. &lt;a href=&quot;https://www.sonatype.com/products/repository-pro&quot;&gt;Nexus&lt;/a&gt;, &lt;a href=&quot;https://jfrog.com/artifactory/&quot;&gt;Artifactory&lt;/a&gt; or &lt;a href=&quot;https://github.com/verdaccio/verdaccio&quot;&gt;verdaccio&lt;/a&gt; only to name some of the well-known. The advantage is that the published packages of that company never leave the company network. Another advantage is that you can set up authentication to additionally secure your internally published packages.&lt;/p&gt;&lt;h2&gt;Real-world challenges for a fictional enterprise&lt;/h2&gt;&lt;p&gt;Jeff the Wombat&lt;span&gt;type: embedded-entry-inline id: 6qrpwh5q7d0RPUOy7QOlIk&lt;/span&gt; is a Frontend developer at &lt;b&gt;&amp;quot;Working Wombats ACME&amp;quot;&lt;/b&gt; and got a letter from his boss that due to security reasons, from now on, the developers have to use the internal company registry for their npm packages. The internal registry can be accessed via username and password. &amp;quot;This is an easy one,&amp;quot; thinks Jeff and starts trying to add the new registry to the configuration. But soon he finds out, that he can only add one default registry. But how should he then get packages from the public npm registry and, on the other side, private packages from the newly setup internal registry at the same time? Time to google...&lt;/p&gt;&lt;p&gt;While searching Jeff stumbles upon the following:&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;All npm packages have a name. Some package names also have a scope. A scope follows the usual rules for package names (URL-safe characters, no leading dots or underscores). When used in package names, scopes are preceded by an &lt;code&gt;@ &lt;/code&gt;symbol and followed by a slash, e.g. &lt;code&gt;@somescope/somepackagename&lt;/code&gt; Scopes are a way of grouping related packages together, and also affect a few things about the way npm treats the package. -- &lt;a href=&quot;https://docs.npmjs.com/cli/v8/using-npm/scope&quot;&gt;npm&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;Packages can be grouped with scopes and for scopes, we can set alternative registries named &lt;code&gt;scoped registries&lt;/code&gt; where npm will lookup the packages instead of the main registry.&lt;/p&gt;&lt;p&gt;&amp;quot;Well, this sounds promising!&amp;quot; Jeff thinks.&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;💡 The usage of scoped packages and scoped registries can also greatly diminish your attack surface for the dependency confusion attack &lt;a href=&quot;https://snyk.io/blog/detect-prevent-dependency-confusion-attacks-npm-supply-chain-security/&quot;&gt;dependency confusion attack&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;h2&gt;How to configure scoped registries&lt;/h2&gt;&lt;p&gt;.npmrc is a configuration file that configures how npm works in your environment. It can be used globally or on a user or project level. &lt;a href=&quot;https://docs.npmjs.com/cli/v8/configuring-npm/npmrc&quot;&gt;Here&lt;/a&gt; are the docs for .npmrc.&lt;/p&gt;&lt;p&gt;&lt;b&gt;&amp;quot;Working Wombats ACME&amp;quot;&lt;/b&gt; already set up the new registry and moved all packages from the public registry into the private registry. Fortunately for the internal packages, they already used scopes (&lt;code&gt;@workingwombats&lt;/code&gt;). The registry can be found internally via the URL &lt;code&gt;registry.working-wombats.rocks&lt;/code&gt;. So Jeff could add a scoped registry with the following line to .npmrc:&lt;/p&gt;
            &lt;figure&gt;
              &lt;pre&gt;&lt;code&gt;@workingwombats:registry=https://registry.working-wombats.rocks/
&lt;/code&gt;&lt;/pre&gt;
              &lt;figcaption&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
          &lt;h2&gt;401 Unauthorized... what? 😱&lt;/h2&gt;&lt;p&gt;Jeff quickly added the configuration for the scoped registries and thought he could knock off work early today and enjoy the rest of the day but then he saw the dreaded 401 error message...&lt;/p&gt;&lt;p&gt;Even if the registry is hosted internally, it is good practice to add authentication to prevent anonymous access to the packages. This can be in form of a username and password or via an access token. For username and password normally basic authentication (&lt;a href=&quot;https://en.wikipedia.org/wiki/Basic_access_authentication&quot;&gt;Basic Authentication&lt;/a&gt;) is used. To create the authentication string Jeff takes the username and password, separated with a colon and then encode it with base64:&lt;/p&gt;&lt;p&gt;&lt;code&gt;username:password&lt;/code&gt; ⇒ base64 encoded ⇒ &lt;code&gt;dXNlcm5hbWU6cGFzc3dvcmQ=&lt;/code&gt;&lt;/p&gt;&lt;p&gt;For encoding you could use the command line &lt;code&gt;echo -n &amp;#39;my-string&amp;#39; | base64&lt;/code&gt; (bash) or an IDE (e.g. vscode with plugin). Or alternatively you could even use a REPL (e.g. &lt;a href=&quot;https://nodejs.dev/learn/how-to-use-the-nodejs-repl&quot;&gt;JS REPL&lt;/a&gt; with the following command in JavaScript &lt;code&gt;Buffer.from(&amp;#39;username:password&amp;#39;, &amp;#39;binary&amp;#39;).toString(&amp;#39;base64&amp;#39;)&lt;/code&gt;).&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;💡 If you use the command-line, the password is saved in plaintext into the command-line history and can be retrieved from there. As a good practice, you should delete the command from the command-line history afterwards.&lt;/p&gt;&lt;/blockquote&gt;&lt;blockquote&gt;&lt;p&gt;💡 There are also base64 encoder websites. You should never enter a productive username and/or password there. Use these only for testing purposes.&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;Jeff remembered, that the mail of his boss also contained the username and password in plaintext to access the registry (yes, even in the best imaginary companies security isn&amp;#39;t always perfect 🤷‍♂️):&lt;/p&gt;&lt;p&gt;&lt;code&gt;sirWombat:theCudd1er!&lt;/code&gt; ⇒ base64 encoded ⇒ &lt;code&gt;c2lyV29tYmF0OnRoZUN1ZGQxZXIh&lt;/code&gt;&lt;/p&gt;&lt;p&gt;So to add basic authentication to the registry, Jeff encodes the username and password with base64 and goes back to the .npmrc file, and adds the following line below the corresponding scoped registry:&lt;/p&gt;
            &lt;figure&gt;
              &lt;pre&gt;&lt;code&gt;@workingwombats:registry=https://registry.working-wombats.rocks/
//registry.working-wombats.org/:_auth=c2lyV29tYmF0OnRoZUN1ZGQxZXIh
&lt;/code&gt;&lt;/pre&gt;
              &lt;figcaption&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
          &lt;blockquote&gt;&lt;p&gt;💡 Note the // without the HTTPS: at the beginning&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;Alternatively, if you have an access token you can put the access token after &lt;code&gt;_authToken&lt;/code&gt;:&lt;/p&gt;
            &lt;figure&gt;
              &lt;pre&gt;&lt;code&gt;@workingwombats:registry=https://registry.working-wombats.rocks/
//registry.working-wombats.org/:_authToken=c2lyd29tYmF0OnRoZWN1ZGQxZXIh
&lt;/code&gt;&lt;/pre&gt;
              &lt;figcaption&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
          &lt;p&gt;Jeff tried it again et voilà it worked! He almost committed the new additions of the project-level .npmrc to git but then his old mentor &amp;quot;Sir Wombat&amp;quot; came into his mind:&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;💡 Remember that it is not a good practice to add credentials to version control e.g. if you have versioned your .npmrc file.&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;and Jeff was asking himself...&lt;/p&gt;&lt;h2&gt;But where should I put the credentials then? 🤷‍♂️&lt;/h2&gt;&lt;p&gt;Jeff doesn&amp;#39;t want to commit the credentials so he decides to put the credentials in an &lt;b&gt;environment variable&lt;/b&gt; and refer to them in the configuration file.&lt;/p&gt;&lt;p&gt;Start by defining the variable:&lt;/p&gt;&lt;p&gt;e.g. for linux &lt;code&gt;$ export NPM_TOKEN=&amp;lt;base64-string&amp;gt;&lt;/code&gt;&lt;/p&gt;&lt;p&gt;We can then add the environment variable in our .npmrc file:&lt;/p&gt;
            &lt;figure&gt;
              &lt;pre&gt;&lt;code&gt;//registry.wombatcorp.org/:_auth=${NPM_TOKEN}
&lt;/code&gt;&lt;/pre&gt;
              &lt;figcaption&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
          &lt;p&gt;The npm CLI will replace this value with the contents of the NPM_TOKEN environment variable.&lt;/p&gt;&lt;h2&gt;Conclusion&lt;/h2&gt;&lt;p&gt;Finally, Jeff could shut down his computer and leave work. Today he learned how to use scoped registries to access different scoped packages. He also learned how to use .npmrc for configuration, what Basic Authentication is and how to use it to access scoped registries.&lt;/p&gt;&lt;p&gt;&amp;quot;In the end...&amp;quot;, thought Jeff, &amp;quot;...this wasn&amp;#39;t too hard.&amp;quot;&lt;/p&gt;&lt;p&gt;As a backend developer myself peeking into the world of frontend, I was standing before the same problem as Jeff. I wish I had found this blog post by then... 😌&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</content:encoded></item><item><title><![CDATA[How we joined the Metaverse with Gather]]></title><description><![CDATA[A few weeks ago, we introduced Gather at Satellytes to fight Zoom Fatigue. Soon after, we saw the magic of the Metaverse happening.]]></description><link>https://satellytes.com/blog/post/gather-metaverse-bump-each-other-2021/</link><guid isPermaLink="false">https://satellytes.com/blog/post/gather-metaverse-bump-each-other-2021/</guid><pubDate>Tue, 21 Dec 2021 00:00:00 GMT</pubDate><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://satellytes.com/_gatsby/image/4c9f1e1da78faaa652a47275cd3278a0/049e3d39284577572c92b7db90eb3e09/teaser.png?eu=e867f73d40f84f16248c92278761f9a33e5445198400defd6079ec13cc0bd162e4f01bd4accfd730fb35bea480cde66fdff444cc7ce9517dcd68046deedfd073bb72e50e49c4e8dec33df2763a0140272cc74887e1ac172014711a0b4ced30c54844249e5ba90e52fce9c831de54e34c09586f26b659f16ece6096f11c7b0322f4bf1ab7429a4034b169862748cf0c67254a06b327e81158b95f4b870d16372eeada4dd6254fd0665fa04ae08fb5f5bb980da7c1d2f02e270fb7e5974c&amp;amp;a=w%3D1440%26h%3D760%26fm%3Dpng%26q%3D75&amp;amp;cd=2022-03-23T14%3A05%3A07.238Z&quot; alt=&quot;&quot;/&gt;&lt;figcaption&gt;&lt;a href=&quot;https://github.com/gathertown/mapmaking&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Image by Made with Gather Tiles&lt;/a&gt;&lt;/figcaption&gt;&lt;/figure&gt; &lt;h2&gt;Introduction&lt;/h2&gt;&lt;p&gt;A few weeks ago, we introduced &lt;a href=&quot;https://www.gather.town/&quot;&gt;Gather&lt;/a&gt; at Satellytes to make our daily remote life more pleasant and to fight &lt;a href=&quot;https://en.wikipedia.org/wiki/Zoom_fatigue&quot;&gt;Zoom Fatigue&lt;/a&gt;. Gather describes itself as a &lt;b&gt;&amp;quot;platform that combines a 2D game-like interface with video-chat&amp;quot;&lt;/b&gt;.&lt;/p&gt;&lt;p&gt;At first glance it might look like a game, but that&amp;#39;s only the visual presentation chosen by gather (although you can run go-karts and play integrated games like Tetris). The core use-cases are actually all focused around office life and human interactions.&lt;/p&gt;&lt;p&gt;Only people you invite can access your world. You pick an avatar and walk around a virtual office. Once you bump into a colleague, a small video window opens near your avatar, and you can start talking. When you walk away from a conversation, the video and voices diminish until the chat closes. When you focus a different window, while not being in a conversation, your video and audio are always muted, but people can still try to approach.&lt;/p&gt;&lt;p&gt;First, we invited a few colleagues just to try out the mechanics together but pretty soon we saw the magic of the &lt;a href=&quot;https://www.gather.town/post/why-the-metaverse-matters&quot;&gt;Metaverse&lt;/a&gt; happening.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;//images.ctfassets.net/54dnxp2417nl/2nAOZm2s1fxtJbiOSBzQKn/10ba12390edbd2cfa52adfd80f7e9839/gather-example-official.png&quot; alt=&quot;Official gather screenshot with people hanging around&quot;/&gt;&lt;figcaption&gt;Official gather screenshot with people hanging around&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;Metaverse&lt;/h2&gt;&lt;p&gt;Phillip Wang, the CEO of Gather, has published a little article to the question &lt;a href=&quot;https://www.gather.town/post/why-the-metaverse-matters&quot;&gt;&amp;quot;What exactly is the Metaverse?&amp;quot;&lt;/a&gt; so I think it&amp;#39;s best to cite him:&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;Traditionally, physical location has dictated how we live. Most of us have been forced to live near where we work, which means we rarely see friends and family who live elsewhere. For many of those without the means to move, location is a barrier to opportunity altogether.&lt;/p&gt;&lt;p&gt;The Metaverse solves this problem: it&amp;#39;s the next iteration of the Internet that brings a sense of place and facilitates rich human connection. In a virtual office you can work alongside your teammates, and strike up casual conversations throughout the day. Together with your friends, you can watch movies in a virtual cinema, enjoy art in a museum, or hang out in a park. You can even go to class with a teacher from halfway across the world, and take a field trip to the pyramids.&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;This sounds a lot like &lt;a href=&quot;https://en.wikipedia.org/wiki/Second_Life&quot;&gt;Second Life&lt;/a&gt;. Probably the earliest, rather forgotten, type of Metaverse out there. The thing that makes Gather much different is the 2D appearance and the limited interactions. It&amp;#39;s not trying to mimic the real world at all. That keeps the focus on the human interactions, which suffered so much during the COVID-19 pandemic when people were forced to move into the home office.&lt;/p&gt;&lt;h2&gt;How we use Gather&lt;/h2&gt;&lt;p&gt;We started using Gather exactly six weeks ago. Your first task is to create your own space. Luckily, they offer plenty of pre-made spaces to pick from. I created a virtual office space, where we could sit at desks or meet at the bar in a kitchen.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;//images.ctfassets.net/54dnxp2417nl/4XxVn5f8FI4JM4MB3ewYn4/aced95bd00568da96ccb37cdc411475d/gather-templates.png&quot; alt=&quot;Pick an existing gather space from plenty of templates&quot;/&gt;&lt;figcaption&gt;Pick an existing gather space from plenty of templates&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;From the beginning, I forced myself to keep Gather running every day to act as a role model. Occasionally, I would invite someone from the team to try out Gather with me.&lt;/p&gt;&lt;h3&gt;All-hands meetings&lt;/h3&gt;&lt;p&gt;Once we reached a &amp;quot;critical mass&amp;quot; of people using Gather, I decided to switch our all-hands meeting on Mondays from Zoom to Gather. We would run our meeting on a small, sunny island. That was also the first time I had to use the &lt;a href=&quot;https://support.gather.town/help/mapmaker&quot;&gt;mapmaker&lt;/a&gt;. Because everything is possible in the Metaverse I decided to build a suburban station to connect the island with our office.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;//images.ctfassets.net/54dnxp2417nl/4zH1xcRBQzLFkd9sCvbBYk/7c43aea94fa1ec0c2598c0141e979447/gather-smm.jpg&quot; alt=&quot;Our Satellytes folks gathering for our all-hands meeting on a Monday&quot;/&gt;&lt;figcaption&gt;Our Satellytes folks gathering for our all-hands meeting on a Monday&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;The actual meeting is held in a specially prepared meeting room (here the island). Everyone who enters a room can talk to each other and see all people&amp;#39;s videos. We start talking and provide the latest company news and people can ask questions and share their thoughts. When the meeting is over people leave the room and start bumping into each other, create random groups, and tell their stories from the weekend — just like in the real world. Compare this with the Zoom dystopia, where everyone usually joins into a single video chat and leave directly after the meeting back into isolation (I exaggerated a little).&lt;/p&gt;&lt;p&gt;The meeting room behavior of Gather is fundamentally different to the rest of the virtual world, where people can only talk to each other when they are close by. That&amp;#39;s called &amp;quot;spatial audio technology&amp;quot;, more on that in the following example.&lt;/p&gt;&lt;h3&gt;Random bumps&lt;/h3&gt;&lt;p&gt;When you walk to someone, while approaching, the video and audio slowly fade in. That technique is called &amp;quot;spatial audio technology&amp;quot; and mimics the way we bump into other people in real life, where someone&amp;#39;s voice is louder while you are near them, and softer as you walk away. This is wonderful because it feels so familiar and natural.&lt;/p&gt;&lt;figure&gt;&lt;video preload=&quot;auto&quot; autoplay=&quot;&quot; loop=&quot;&quot; muted=&quot;&quot; width=&quot;100%&quot;&gt;&lt;source src=&quot;//videos.ctfassets.net/54dnxp2417nl/20UaISY19X8NqQydfs3ggv/a3a08f44fff453b8b95f092e635d9499/video.mp4&quot; type=&quot;video/mp4&quot;/&gt;&lt;/video&gt;&lt;figcaption&gt;People bumping into each other (via gather.town)&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;Pair programming&lt;/h3&gt;&lt;p&gt;A similar effect happens when you sit in the virtual office and suddenly two folks group up on the other side of the table. Instantly you know, &amp;quot;oh, they do some pair programming&amp;quot;. When I asked my colleagues about their session, they said it&amp;#39;s a nice way to meet at some actual (although virtual) location and then just &amp;quot;bump into the other person&amp;quot; to start the session.&lt;/p&gt;&lt;p&gt;This feeling is the promise of the Metaverse. It brings back the informal human interactions and spontaneity. You don&amp;#39;t have to create a video meeting upfront or send some specific invitation. Who would do that in real life? Instead, you just walk over to the desk of your colleague and start talking.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;//images.ctfassets.net/54dnxp2417nl/5Sb0SRtiDnzPk6AMS1cQsW/3993469fb99cac931bba01178e9e81bb/gather-pair.gif&quot; alt=&quot;Our colleagues Jesús &amp;amp; Felix having a pair programming session&quot;/&gt;&lt;figcaption&gt;Our colleagues Jesús &amp;amp; Felix having a pair programming session&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;Hanging around&lt;/h3&gt;&lt;p&gt;While we can gather everyone for some all-hands easily, we have the biggest struggle to motivate people to stay online throughout the day. A few colleagues and I are online most of the day. The other ones are online occasionally or just for the invited events. Sadly, this means our world looks very empty, very often.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;//images.ctfassets.net/54dnxp2417nl/jYpts8W1M9408kll26YfX/85ebcafecf831683c5bcb6a722baaff7/gather-sy-current-world.png&quot; alt=&quot;Our Satellytes space often looks that empty&quot;/&gt;&lt;figcaption&gt;Our Satellytes space often looks that empty&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;What can we do about that? When I ask people, I get various feedback:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;I fear I can&amp;#39;t work focused enough because people will disturb me all the time&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;I don&amp;#39;t trust Gather that the microphone and video is truly switched off every time I focus on another window&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;I&amp;#39;m intimidated with Gather as I don&amp;#39;t play games often&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;I just forget to start Gather on the morning&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;It doesn&amp;#39;t integrate in any way with my work routing / other tools&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;It requires me to spend too much focus on the app itself (the effect &amp;#39;bumping&amp;#39; into someone is rather an active one)&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;I think this list describes people&amp;#39;s issues with their comfort zone. Especially with a tool like Gather, which is so fundamentally different from other communication tools like Slack, Zoom, or Google Meet. The only thing we can do about that is to create situations where people get in touch with Gather and automatically more comfortable.&lt;/p&gt;&lt;p&gt;We already do our all-hands meeting in there. Other folks advocate to run pair programming sessions in Gather or move their plain meetings to Gather rather than running them in a classic video conference. I&amp;#39;m sure this will help our folks out of their comfort zone, so they can start embracing the Metaverse.&lt;/p&gt;&lt;h2&gt;Metaverse Netiquette&lt;/h2&gt;&lt;p&gt;We don&amp;#39;t have a defined &lt;a href=&quot;https://en.wikipedia.org/wiki/Etiquette_in_technology&quot;&gt;netiquette&lt;/a&gt; for our daily work in Slack and related tools. That&amp;#39;s because most people are comfortable and experienced working with the given online chats, videos, and other tools.&lt;/p&gt;&lt;p&gt;That&amp;#39;s problematic with Gather though, as the human interaction is much different in the Metaverse. Ideally, we can answer the following questions through a &lt;b&gt;Netiquette&lt;/b&gt;. Here are some ideas of questions and answers.&lt;/p&gt;&lt;p&gt;&lt;b&gt;What are the signs not to approach someone?&lt;/b&gt; &lt;/p&gt;&lt;p&gt;Check the status message first and then the situation&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;🟢 If the person sits in the kitchen, it&amp;#39;s fine to approach them as this signals an informal working environment&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;🟠 If the person sits at a desk, decide wisely as you still might interrupt them&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;🔴 If it&amp;#39;s red, you rather not interrupt&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;Two people have a chat. Can I just bump into them?&lt;/b&gt; &lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;🟢 If it&amp;#39;s in the hallway, it&amp;#39;s okay for sure&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;🟠 In the kitchen it might be okay&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;🔴 It&amp;#39;s never okay if it&amp;#39;s a meeting room&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;I have a quick question. Write a message or find that person and speak to them?&lt;/b&gt; &lt;/p&gt;&lt;p&gt;This depends on the question as it would in real life&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;🟢 Sensitive topic? Yes please, to prevent any misinterpretations in the text&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;🟠 Urgent? Yes please, or find another adequate channel for the given topic&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;🔴 Random question that has time? Send a text message for an asynchronous answer&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;Do I need to start Gather every day?&lt;/b&gt; &lt;/p&gt;&lt;p&gt;Yes, of course. Otherwise, you can&amp;#39;t participate in the Metaverse and people will miss you&lt;/p&gt;&lt;p&gt;&lt;b&gt;Can I close the Gather application?&lt;/b&gt; &lt;/p&gt;&lt;p&gt;Ideally, you keep it running, but if you have some client meeting through a different channel you might want to close it to prevent any interruptions&lt;/p&gt;&lt;p&gt;&lt;b&gt;We are physically in the office, but others are not. Can we merge reality with the Metaverse?&lt;/b&gt; &lt;/p&gt;&lt;p&gt;That&amp;#39;s tricky because we are dealing with the crossing of two realities. Everyone or at least one person in the physical have to join with their avatar to create a bridge between the two worlds&lt;/p&gt;&lt;p&gt;There are probably many more questions to clarify. I think I will create a living netiquette for Satellytes in 2022. I hope that document will help people to adapt Gather more easily.&lt;/p&gt;&lt;h2&gt;Conclusion&lt;/h2&gt;&lt;p&gt;Satellytes did not start as a remote-only company more than three years ago. People enjoyed going to the office and talking to each other. That&amp;#39;s why our folks had an actual pain when we were forced to work remotely. On the other side, everyone feels the power of remote work, that we want to embrace in the future.&lt;/p&gt;&lt;p&gt;The Metaverse seems to be the glue we have been missing all the time and Gather is an excellent way to dive into it. I became a big fan of Gather in the past weeks. I&amp;#39;m happily tinkering around with their &lt;a href=&quot;https://github.com/gathertown/mapmaking&quot;&gt;mapmaker&lt;/a&gt; and constantly improving our virtual space because I really want our folks to enjoy the Metaverse. Let&amp;#39;s see where we are heading with that experiment in 2022.&lt;/p&gt;&lt;p&gt;Thank you Gather 💙&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Daniel Eißing – Senior Frontend Engineer]]></title><description><![CDATA[Daniel Eißing ist seit einem Monat Senior Frontend Engineer bei Satellytes und das zu 100% remote]]></description><link>https://satellytes.com/blog/post/interview-daniel-eissing/</link><guid isPermaLink="false">https://satellytes.com/blog/post/interview-daniel-eissing/</guid><pubDate>Wed, 20 Oct 2021 00:00:00 GMT</pubDate><content:encoded>&lt;img src=&quot;https://satellytes.com/_gatsby/image/32160499a8de07b5178f5af0e2ed7065/4be445bf02c55418e404abd8f2a1a674/daniel-hero.jpg?eu=ea62f33d47f24113738fc5248333fda86e04481fd7578cfc3778ba449806d137b2f440d0fb998030af60bca6879cb26688f71dc926e6552fc2320a3bba83d121e924e1094cc2ead9c03af72031544f7f62db4c80abf002665679100f58a6209f4d51318c4dae1808e1a2d27b9f4fb21615462562b55aae358f3ad78e116e08788ad125ac51a06e77996a8527768f550f250101b521b8170aea5f1cd4591d6725b8d84ada2349dd625ba34fe689eefdb9d40de9dbdef4316f15fce796058baacf&amp;amp;a=w%3D1440%26h%3D760%26fm%3Djpg%26q%3D75&amp;amp;cd=2022-03-25T09%3A59%3A54.867Z&quot; alt=&quot;&quot;/&gt; &lt;h2&gt;Interview mit Daniel Eißing&lt;/h2&gt;&lt;p&gt;Daniel Eißing ist seit einem Monat Senior Frontend Engineer bei Satellytes und das zu 100% remote. Davor hat er fast zwei Jahre lang als Freelancer für Satellytes gearbeitet. Wir haben ihn zum Interview gebeten, damit er uns mehr über Freelance vs. Festanstellung, 100% remote und seinen ungewöhnlichen Arbeitsalltag erzählt.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Hallo Daniel. Schön, dass Du Dir die Zeit nimmst. Stell Dich doch mal kurz vor.
&lt;/b&gt;Gerne. Ich bin Daniel Eißing, Entwickler. Ich würde mich als Generalist bezeichnen, denn mir macht die Web-Programmierung insgesamt einfach wahnsinnig viel Spaß. Am spannendsten finde ich den Gap zwischen Technik und User Experience – und diesen zu schließen. In der Web-Entwicklung gibt&amp;#39;s dafür die besten Tools, die Entwicklung schreitet extrem schnell voran und so kann man täglich dazulernen um bessere Lösungen zu entwickeln – und mein Glück ist, dass ich sehr gerne dazulerne. In den letzten 8 Jahren habe ich in München gelebt, ein Jahr bei Tomtec gearbeitet und danach fünf Jahre bei SinnerSchrader. Das hat extrem viel Spaß gemacht, ich habe interessante Leute kennen- und viel dazugelernt, aber am Ende gekündigt, um als Freelancer unabhängiger in meinen Entscheidungen zu sein woran ich arbeite.&lt;/p&gt;&lt;p&gt;
&lt;b&gt;Wieso hast du deine freiberufliche Tätigkeit aufgegeben und bei Satellytes angefangen?
&lt;/b&gt;Kurz gesagt: Weil&amp;#39;s einfach gepasst hat. In der Pandemie haben wir ja ein Jahr 100% remote zusammengearbeitet und das hat sich gut angefühlt und das hat perfekt mit meinen Plänen zusammengepasst wieder zurück nach Fulda zu ziehen. Es macht für mich einfach viel Sinn mit Leuten zusammenzuarbeiten bei denen ich weiß, dass es klappt. Und: Das Firmenkonzept passt. Satellytes sind nette Leute mit tollen Projekten. Die Kommunikation ist direkt, absolut transparent und auf Augenhöhe. Mehr noch: Es herrscht eine sehr offene Feedback-Kultur, man wird ermutigt Feedback einzubringen, sowohl fachlich auf Projekten als auch im Unternehmen selbst. Ich finde es gut, dass man tatsächlich Ownership an den Sachen an denen man arbeitet übernehmen kann und Einfluss auf das Ergebnis hat und es nicht ins Leere läuft. Man hat die Möglichkeit das Produkt jenseits seiner Kernverantwortung und -kompetenz voranzubringen. Vertrauen war auch ein Faktor, natürlich beidseitig.&lt;/p&gt;&lt;p&gt;
&lt;b&gt;Gab es positive/negative Reaktionen von Kunden zu 100% remote?
&lt;/b&gt;An sich hat sich ja nichts geändert, wir haben seit Projektanfang nur Remote gearbeitet und zu wichtigen Terminen reise ich gerne nach München.&lt;/p&gt;&lt;p&gt;
&lt;b&gt;Gab es Reaktionen von Kollegen?
&lt;/b&gt;Es wurde &amp;quot;als natürlich&amp;quot; zur Kenntnis genommen, weil viele nach der Pandemie überlegen, ob fünf Tage im Office noch die beste Lösung sind – aus Sicht von Produktivität, Spaß an der Arbeit, Pensum. Man überlegt auf welche Art und Weise man den Arbeitsalltag verbringen kann, der einen ausgeglichen hält und einem gut tut. Für mich persönlich sind Arbeitslast und Ausgleich besser von zu Hause im Einklang.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;//images.ctfassets.net/54dnxp2417nl/3A5rnLnHNdJNw1W5VjurGk/5c87c3971a87690d479d1c6b538121a6/daniel.jpg&quot; alt=&quot;Daniel&quot;/&gt;&lt;figcaption&gt;Daniel&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;Du arbeitest 100% von zu Hause und hast auch sehr ungewöhnliche Arbeitszeiten. Erzähl doch mal wie dein normaler Arbeitsalltag abläuft.
&lt;/b&gt;Ich wache ohne Wecker täglich zwischen 5 und 6 Uhr auf. Dann mache ich mir erst mal einen Kaffee. Danach arbeite ich sehr produktiv 2 bis 3 Stunden, dann frühstücke ich eine Stunde in Ruhe. Nach dem Frühstück fange ich meistens um ca. 9 Uhr wieder an zu arbeiten. Um diese Uhrzeit sind dann auch alle Kollegen aktiv und es wird viel abgestimmt: Requirements Engineering, Tickets schreiben – im Prinzip viel was nicht Programmierarbeit ist, aber trotzdem gemacht werden muss. Manchmal mache ich vormittags sogar noch eine Stunde Sport, andernfalls abends. Um 12:30 bis 13 Uhr mache ich dann Mittag. Von 12 bis 15 Uhr bin ich AFK für Einkaufen, Essen zubereiten, essen und News lesen. In dieser Zeit mache ich auch gerne private Besorgungen, dann springt der Kreislauf wieder an. Ab 17 Uhr bin ich dann wieder am Rechner. So fix ist das aber auch nicht. Ich plane meine Wochen nicht nach 5 x 8 Stunden, sondern nach 7 x N. Im Endeffekt arbeite ich wie ein Freelancer mit fixer Wochenstundenzahl. Meine Tasks und Ziele, die ich in der aktuellen Arbeitswoche erreichen will, habe ich im Kopf. Daran orientiere ich mich, nicht an klassischen 5-Tage-Wochen.&lt;/p&gt;&lt;p&gt;
&lt;b&gt;Einen Arbeitsplatz im Büro brauchst Du ja nicht. Wie sieht deiner zu Hause aus?
&lt;/b&gt;Ich habe ein M1 MacBook bekommen, ein Trackpad und eine Tastatur meiner Wahl. Stuhl und Schreibtisch wurde mir angeboten, brauche ich aber nicht. Aber ein gutes Headset ist wichtig, wenn man mal out-of-home arbeitet.&lt;/p&gt;&lt;p&gt;
&lt;b&gt;Wie bleibst Du mit deinen Kollegen in Kontakt? Wie lernst Du Neues und wie/wo lässt Du Dich inspirieren? Die gemeinsame Küche gibt&amp;#39;s ja nicht mehr für Plaudereien.
&lt;/b&gt;Unser Daily-Coffee-Talk-Hangout hat die Pandemie überlebt und in Meetings sprechen wir am Anfang oder Ende auch immer paar Minuten privat. Ab und zu komme ich nach München, dann mache ich mir Lunch-Termine mit meinen Kollegen. Und wir wollen die Tage mal &amp;quot;Twitter Spaces&amp;quot; versuchen, das ist ähnlich wie bei Slack &amp;quot;Huddle&amp;quot;. Das Format finde ich gut.&lt;/p&gt;&lt;p&gt;
&lt;b&gt;Was vermisst Du bei Home Office vs. Office?
&lt;/b&gt;Gemeinsames Lunch. Lunchen alleine macht weniger Spaß.&lt;/p&gt;&lt;p&gt;
&lt;b&gt;Wie oft reist Du nach München ins Büro und zu welchen Gelegenheiten?
&lt;/b&gt;Das wird sich noch zeigen. Ich bin gerne ab und zu zum Lunch da, zu wichtigen Kundenterminen und zu Satellytes-Events.&lt;/p&gt;&lt;p&gt;
&lt;b&gt;Was steht heute noch an?
&lt;/b&gt;Jetzt geht&amp;#39;s erst mal ins API Alignment, danach gehe ich kurz Einkaufen und dann bastle ich noch ein bisschen am Liveticker für das aktuelle Projekt bis in die Abendstunden. Feierabend: Manchester vs. Villareal.&lt;/p&gt;&lt;p&gt; 
&lt;b&gt;Letzte Worte?
&lt;/b&gt;Peace out! ✌️&lt;/p&gt;</content:encoded></item><item><title><![CDATA[The Modern Code Reviewer]]></title><description><![CDATA[Read about a differentiated way to conduct pull request code reviews to improve the PR throughput.]]></description><link>https://satellytes.com/blog/post/the-modern-code-reviewer-2021/</link><guid isPermaLink="false">https://satellytes.com/blog/post/the-modern-code-reviewer-2021/</guid><pubDate>Wed, 22 Sep 2021 00:00:00 GMT</pubDate><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://satellytes.com/_gatsby/image/421ba1aa08a5780259fd720bbf394890/4be445bf02c55418e404abd8f2a1a674/IBM_Electronic_Data_Processing_Machine_-_GPN-2000-001881.jpg?eu=ba60f53c1bf21713708ac670d462fea93952134c8c578eab6379e8169f508462e7ff4087aa9c8035a536bda1829de53ad8a210cc72b7507f9f6e563fb8d78b20be23b30d1ec7bfd8c76cf4253105112f72cb5d95a2e7193a5929445c1bee258a1b0926c84ee85e1eeef19167994cb51908552d3ef019b02a9a2396ab247f5c2db3c621936e825671b77c80736292190f725103ed68fa1008b85a40da441a2148dffd05b70931a50323fa5abea6c1a9c9ae1ee39a82a365751faff1cf4ad9ed9b0d0ab34821dfd8fad0021c384349754fb923b2eb49abe47805628863831675e3de2836e03fd19b0497665b2ceef0b3c59299dd4a6dc1db7eaa7359133dcfaac6d1c56c750dd4eeb8484f265c878e55a6d3&amp;amp;a=w%3D1440%26h%3D760%26fm%3Djpg%26q%3D75&amp;amp;cd=2022-03-25T09%3A29%3A18.782Z&quot; alt=&quot;&quot;/&gt;&lt;figcaption&gt;&lt;a href=&quot;https://de.m.wikipedia.org/wiki/Datei:IBM_Electronic_Data_Processing_Machine_-_GPN-2000-001881.jpg&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Image by NASA&lt;/a&gt;&lt;/figcaption&gt;&lt;/figure&gt; &lt;h1&gt;Long story short&lt;/h1&gt;&lt;p&gt;In this blog post, I try to propose a differentiated way to conduct pull requests code reviews to improve their &lt;b&gt;throughput&lt;/b&gt;. Let your people choose a code review intensity that matches their experience, confidence, involvement, role, available time, and project timeline. You do this by offering three different pull request review types: &lt;b&gt;shallow review&lt;/b&gt;, &lt;b&gt;common review&lt;/b&gt;, and &lt;b&gt;expert review&lt;/b&gt;.&lt;/p&gt;&lt;p&gt;Your review will be much more accessible to every one of your team, including new team members and the rather shy ones. Additionally, your most involved people, who are usually the bottleneck, will get an instrument to conduct code reviews with reduced intensity in cases where it is sufficient.&lt;/p&gt;&lt;p&gt;The moment you understand that you have a choice when you are requested for a code review, you can distribute your time more evenly and steer away from situations that would cause you to be the bottleneck.&lt;/p&gt;&lt;hr/&gt;&lt;h1&gt;Introduction&lt;/h1&gt;&lt;p&gt;Have you ever heard about the &lt;a href=&quot;https://en.wikipedia.org/wiki/Fagan_inspection&quot;&gt;Fagan inspection&lt;/a&gt;? It&amp;#39;s the first formalized system of a &lt;b&gt;peer review&lt;/b&gt; for documents that include source code. Formal peer code reviews are probably the reason why &lt;a href=&quot;https://www.fastcompany.com/28121/they-write-right-stuff&quot;&gt;space rockets don&amp;#39;t blow up&lt;/a&gt; and hopefully prevent radiation therapy devices from giving overdoses to patients due to a &lt;a href=&quot;https://en.wikipedia.org/wiki/Therac-25&quot;&gt;software bug (Therac-25)&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Creating software for the web is less life-threatening, more forgiving, and happens in much faster development cycles, so we can easily fix bugs and add more features. That&amp;#39;s why we can use less formal ways to inspect the code we are writing day by day. &lt;a href=&quot;https://martinfowler.com/bliki/PairProgramming.html&quot;&gt;Pair programming&lt;/a&gt; and &lt;a href=&quot;https://www.methodsandtools.com/archive/archive.php?id=66&quot;&gt;over-the-shoulder&lt;/a&gt; are two very simple, lightweight and powerful ways to review code, but they are synchronous and require some previous alignment. The majority of code changes we observe these days are going through &lt;a href=&quot;https://martinfowler.com/bliki/PullRequest.html&quot;&gt;pull requests&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Pull requests are a common breeding ground for toxic behavior though. When you see people nitpick and fight over small details like &lt;a href=&quot;https://www.youtube.com/watch?v=SsoOG6ZeyUI&quot;&gt;code indentations&lt;/a&gt;, &lt;a href=&quot;https://github.com/twbs/bootstrap/issues/3057&quot;&gt;semicolons&lt;/a&gt; or &lt;a href=&quot;https://softwareengineering.stackexchange.com/questions/2715/should-curly-braces-appear-on-their-own-line&quot;&gt;curlies&lt;/a&gt; then it&amp;#39;s probably caused by the text-based and asynchronous nature of this peer code review type. Thankfully you can agree on issues like that beforehand and collect them in a &lt;a href=&quot;https://mozillascience.github.io/working-open-workshop/contributing/&quot;&gt;contribution guideline&lt;/a&gt; to focus on the actual problem: Finding the defects in a given code change.&lt;/p&gt;&lt;p&gt;Unfortunately, pull requests can still get pretty frustrating, exhaustive, and ineffective, especially when people are not trained to work with the informal nature of pull requests. The freedom of giving feedback delude people into providing inadequate feedback. They either focus on too many details or people give one-liner feedback, where a proper discussion would be desired.&lt;/p&gt;&lt;p&gt;In addition, people can only spend a limited amount of time on code reviews and entire teams and projects can run into the situation that the pull requests are the bottleneck of their entire development journey. In this post, I want to propose a solution to the throughput problem of pull request code reviews and help people getting more comfortable reviewing code.&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;In order to keep things simple, I will use the names &lt;b&gt;pull request&lt;/b&gt; or its abbreviation &lt;b&gt;PR&lt;/b&gt; as well as &lt;b&gt;code review&lt;/b&gt;, &lt;b&gt;peer review&lt;/b&gt; and &lt;b&gt;review&lt;/b&gt; interchangeably unless said otherwise even though a peer review or a code review represent much wider concepts than a pull request.&lt;/p&gt;&lt;/blockquote&gt;&lt;h1&gt;The throughput problem&lt;/h1&gt;&lt;p&gt;When talking about code reviews, then usually two roles are involved. The &lt;b&gt;reviewee&lt;/b&gt; (author) and one or multiple &lt;b&gt;reviewers&lt;/b&gt; (peers checking the code).&lt;/p&gt;&lt;p&gt;The reviewee creates the PR and should ensure that code changes are relevant, well-described, and ready to be reviewed. On the other hand, the reviewer must check the code which is about to land in the shared codebase for functionality and code quality. One or multiple reviewers will conduct the code review, depending on the size of the team and their agreements. There are two ways to assign reviewers: manual or automated.&lt;/p&gt;&lt;p&gt;The manual assignment is probably okay for small teams, where people don&amp;#39;t have many choices to decide anyway. The automated way is usually orchestrated by a &lt;a href=&quot;https://satellytes.com/blog/monorepo-codeowner-github-enterprise/&quot;&gt;CODEOWNERS&lt;/a&gt; file or you enable &lt;a href=&quot;https://docs.github.com/en/organizations/organizing-members-into-teams/managing-code-review-assignment-for-your-team&quot;&gt;auto assignment&lt;/a&gt; where you can decide between different &lt;a href=&quot;https://docs.github.com/en/organizations/organizing-members-into-teams/managing-code-review-assignment-for-your-team&quot;&gt;routing algorithms&lt;/a&gt; like &amp;quot;Round robin&amp;quot; or &amp;quot;Load balance&amp;quot; to ensure people review the same amount of changes.&lt;/p&gt;&lt;p&gt;Regardless of the way you assign people, often you can observe one problem: the &lt;b&gt;limited throughput&lt;/b&gt; of code reviews which can cause a large backlog of PRs in the end. The moment PRs start to pile up the team is at risk to get frustrated and overwhelmed by the situation. Small and less important code reviews obstruct important PRs which will block people from progressing as their partial work is neither discussed nor approved. As if things weren&amp;#39;t bad enough, the project owner will further increase the pressure on the team once delayed as they don&amp;#39;t understand the reasons for the overall situation.&lt;/p&gt;&lt;p&gt;Although every team and project setup is different, there are similarities in why people struggle with code reviews and limited throughput.&lt;/p&gt;&lt;h1&gt;The struggling reviewer&lt;/h1&gt;&lt;p&gt;Many times you find the assigned reviewers struggling with their assignments for various reasons not always but often being time-related. I have collected and grouped common problems that I encountered in the wild.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Lack of time&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The lack of time is a very obvious reason to struggle with code reviews. It&amp;#39;s not always the pushing timeline of a project. Often it&amp;#39;s a lack of time management and a shifted perception of priorities &amp;amp; responsibilities.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;You are super busy with your project, so you &lt;b&gt;procrastinate&lt;/b&gt; your duty to review. Because it&amp;#39;s easier than starting yet another task.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;You are concerned (without even trying) about pull requests being too time-consuming and preventing you from having a delivery of your actual development work that meets expectations.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;You are busy and you hope that someone else from the team spares some time for the pending PRs. You ignore your responsibility and rely on someone else&amp;#39;s &lt;b&gt;conscientiousness&lt;/b&gt;.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;You are deep into solving a code problem. You just don&amp;#39;t have time to &lt;b&gt;switch the context&lt;/b&gt;. You procrastinate the duty to review a pending PR until you have solved the problem, which unfortunately ended up taking days and in the meantime, a colleague helped out.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;You are a seasoned developer and you make sure to fulfill your duties. Furthermore, it&amp;#39;s sometimes easier &lt;b&gt;just to do the review&lt;/b&gt; instead of reminding the team again. This brings you into the situation that you are constantly busy with reviews and missing the crucial ones due to a lack of time.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Your day is &lt;b&gt;full of meetings&lt;/b&gt; while your colleagues are programming one new feature after the other. Although you use the breaks between the meetings to check mails and reading the review requests you will never ever be able to check the actual pull request. You trust your peers to review and you get back to your meeting.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;Lack of knowledge&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;You can observe a lack of knowledge and confidence usually among new team members, inexperienced colleagues, or in general insecure persons.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;You&amp;#39;re not &lt;b&gt;fully involved&lt;/b&gt; in the topic, therefore you don&amp;#39;t feel suited to review the code.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;You&amp;#39;re &lt;b&gt;new to the team&lt;/b&gt;. and you don&amp;#39;t think it&amp;#39;s appropriate to provide reviews in a codebase you don&amp;#39;t fully understand.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;Lack of confidence&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;You are an &lt;b&gt;inexperienced developer&lt;/b&gt; and the things you see in a PR, just scare you.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;You feel intimidated. You don&amp;#39;t feel comfortable reviewing a given PR, because the PR is created by a seasoned colleague with a much &lt;b&gt;higher level.&lt;/b&gt; Your feedback is not worth nor expected.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;It&amp;#39;s a super &lt;b&gt;complex PR&lt;/b&gt;. You don&amp;#39;t even understand the problem it&amp;#39;s solving. You feel &lt;b&gt;intimidated&lt;/b&gt; and leave the fun to others.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;You&amp;#39;re &lt;b&gt;new to the team&lt;/b&gt;. It&amp;#39;s &lt;b&gt;intimidating&lt;/b&gt; to review and potentially criticize the code of your new colleagues.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;Lack of accessibility&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;There is either &lt;b&gt;no PR description&lt;/b&gt; or just a single sentence for a rather complex change. You are unable to comprehend the changes with the lack of context given. Some instructions would help to follow and to check the significant bits. That&amp;#39;s why you &lt;b&gt;procrastinate&lt;/b&gt; and secretly hope for someone else to fulfill the review duty.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;An opened PR is &lt;b&gt;massive in size&lt;/b&gt;, so you &lt;b&gt;procrastinate&lt;/b&gt; that huge task for days.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;Lack of empathy&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;You don&amp;#39;t &lt;b&gt;feel other people&amp;#39;s pain&lt;/b&gt; when waiting for a PR review. Instead, you focus on your work, create your PR, and expect people to jump in the review right away.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;There are plenty of PRs open. Unfortunately, you have your own set of urgent code changes. That means you must create yet another PR instead of participating in the review to clear the review jam. In addition, you explicitly ask people to review your PR to move to the front of the queue. Otherwise, your PR will lay around for days. Instead of solving or discussing the problem with the team, you are &lt;b&gt;selfish and unfair&lt;/b&gt; to your colleagues by trying to get your stuff covered while ignoring the rest.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;The last time you reviewed a PR you debated and argued with the reviewee. That&amp;#39;s why you don&amp;#39;t feel comfortable providing another review.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h1&gt;The solution&lt;/h1&gt;&lt;p&gt;Did you see yourself or your former self in some of the described situations? We are humans and not perfect after all. It simply happens that we procrastinate, that we are captured &lt;a href=&quot;https://en.wikipedia.org/wiki/Flow_(psychology)&quot;&gt;in the zone&lt;/a&gt; (for better or worse) or intimidated by changes. Instead of changing people, we can offer a better approach to positively influence their habits. That&amp;#39;s where I am keen to introduce a different code review practice.&lt;/p&gt;&lt;p&gt;A contribution guideline rarely describes how to conduct a review, so people typically follow their gut feeling. In such a situation it highly depends on the individuum how to perform the code review.&lt;/p&gt;&lt;p&gt;The alpha geek will dive deep into every single PR, which guarantees them to be the bottleneck. The inexperienced developer spends high amounts of time, because of the overwhelming complexity &amp;amp; size. Newcomers to the team will fear to provide a common review in order not to criticize the colleagues.&lt;/p&gt;&lt;p&gt;&lt;b&gt;The novelty of our approach is the explicitly given choice for a reviewer&lt;/b&gt;. There is a total of three code review types to help your team improving their reviewing throughput. We introduce the &lt;b&gt;shallow review&lt;/b&gt;, the &lt;b&gt;common review&lt;/b&gt;, and the &lt;b&gt;expert review&lt;/b&gt; which primarily differ in the reviewing intensity. The more intense the higher your knowledge requirements and the amount of time you have to invest. Your average code review probably corresponds to the common review and few reviews being of the expert format.&lt;/p&gt;&lt;p&gt;This code review pattern gives you a choice. You can fit more reviews in the same amount of time while dedicating enough time to the crucial changes while reducing your investment on trivial changes.&lt;/p&gt;&lt;h2&gt;The shallow review&lt;/h2&gt;&lt;p&gt;The shallow review is best suited for peers who are in a hurry (lacking time), not deeply involved (lacking knowledge), or feel intimidated by the code or experience of the reviewee (lacking confidence). A majority of pull requests should be suitable for this code review type, as long they have a size small enough. When a code change introduces major architectural changes, people with shallow reviews are still welcome but the reviewee must additionally require in-depth reviews.&lt;/p&gt;&lt;h3&gt;Reviewer&amp;#39;s cost&lt;/h3&gt;&lt;p&gt;Typically such a shallow review should be completed within 5 to 10 minutes. That will allow you to conduct multiple pull request reviews per day. &lt;b&gt;The cognitive load is rather low&lt;/b&gt;, so you can squeeze them in whenever you transition to another task or before or after breaks. The review type is ideal for small features and additions, fixes, and code refactorings.&lt;/p&gt;&lt;h3&gt;How to conduct&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Carefully read the PR description or any linked ticket to understand the problem&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Glimpse through the PR to check in your mind if that indeed could solve the problem or deliver the feature.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Leave some positive comments or any doubts.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Feel free to ask a question for something you don&amp;#39;t understand&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Leave some praise for the good parts or things you learned 👍&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Phrase some summary and then submit to complete the review.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Approve the review or if things are off post your review as a neutral comment. You should not block any code review though. This requires further interaction while you decided not to invest much time and thoughts by choosing a shallow review.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Be transparent and make sure to inform the reviewee that you only conducted a shallow review.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;What the reviewee gets&lt;/h3&gt;&lt;p&gt;The reviewee will get an overall confirmation that their solution works, fits the expectations and that it&amp;#39;s properly tested if necessary. In addition, people might be able to spot mistakes and code quality issues while glimpsing through the files. Curious reviewers will ask questions which is an excellent opportunity for the reviewee to reflect on the chosen solution.&lt;/p&gt;&lt;h3&gt;What the reviewee won&amp;#39;t get&lt;/h3&gt;&lt;p&gt;The reviewee won&amp;#39;t get detailed feedback for their code, extensive discussions around the chosen methodology, or people running the code. It&amp;#39;s a confirmation of the validity and correctness of the change and the reviewee won&amp;#39;t get many insights on &lt;a href=&quot;https://blog.codinghorror.com/code-elegance-code-balance/&quot;&gt;code elegance&lt;/a&gt;, edge cases, or the architectural choices.&lt;/p&gt;&lt;h2&gt;The common review&lt;/h2&gt;&lt;p&gt;The common review is, as the name says, probably the code review you typically conduct. It&amp;#39;s great for people who are involved in the project and who can spend a greater amount of time for a thorough review to reveal logical errors, nasty bugs, or challenge algorithms and the architecture.&lt;/p&gt;&lt;p&gt;This type of review is ideal for people to learn more about the details of a project by reading and understanding the issue at hand and the implementation to solve it. If you have problems understanding things you can easily ask questions in this format to force the reviewee to reflect on their choices while improving your knowledge.&lt;/p&gt;&lt;p&gt;This is probably the type of review most people conduct and which potentially could get individuals and entire teams into trouble because of the required investment of time, lengthy discussion, and necessary feedback iterations.&lt;/p&gt;&lt;h3&gt;The reviewer&amp;#39;s cost&lt;/h3&gt;&lt;p&gt;Typically the common review costs you 20 to 45 minutes (depending on the size of the PR of course). The cognitive load is medium. People have to know the context. Ideally, they worked on similar parts of the project before. This type of review is ideal for difficult bug fixes, large or complex features, and impactful refactorings or test improvements.&lt;/p&gt;&lt;p&gt;This review type can have few iterations of feedback, especially when the underlying concept is discussed.&lt;/p&gt;&lt;h3&gt;How to conduct&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Carefully read the corresponding issue and the PR description&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Make sure to go over every single file. Your task is to have seen every single code change. Your review tool like GitHub or GitLab offers checkboxes to get through any amount of files without becoming lost.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;figure&gt;&lt;img src=&quot;//images.ctfassets.net/54dnxp2417nl/3pSbjeGiXOkalmrDfEJnRU/86e5f2c5ebc018ad857d4c09e9815bd7/github-review-progress.png&quot; alt=&quot;github-review-progress.png&quot;/&gt;&lt;figcaption&gt;github-review-progress.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Make sure you understand every single change. If something is unclear ask through an inline comment.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Lookout for careless mistakes (wrong signs, typos).&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Leave some praise for the good parts or things you learned 👍&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Try to spot irregularities in code that jump to mind. Can be things that are too complex to understand, functions that are too big, or simply things that seem not to fit the existing codebase. Provide a comment to share your doubts.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Challenge the solution. Does it fit the stated problem? Ask questions and fuel a discussion.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Write a note about aspects that could be improved but that are not crucial to the acceptance of the PR.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Look out for tests. Do they test relevant things? Are they present at all?&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Optionally you run the code locally and verify the expected results. Can you break it?&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Write a summary of your findings and if required repeat the important things to change or future things to improve beyond this PR. Such a summary improves the accessibility of your feedback and makes the pull request more enjoyable.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;This type of review requires quite some time and dedication. Depending on the size of a PR you can easily spend 20-45min for the initial review not counting in excessive feedback iterations.&lt;/p&gt;&lt;h3&gt;What the reviewee gets&lt;/h3&gt;&lt;p&gt;The reviewee will get a thorough review of their changes. People will happily discuss, ask questions and provide insights, tips &amp;amp; improvements. The reviewer will make sure that the code changes are good enough to land in the production branch and that the overall architecture is properly extended and obeyed.&lt;/p&gt;&lt;h3&gt;What the reviewee won&amp;#39;t get&lt;/h3&gt;&lt;p&gt;The purpose of this type of review is to provide feedback to shape and approve a rock-solid code change which can include new and additional features but not drastic architectural changes or the introduction of other new concepts and approaches.&lt;/p&gt;&lt;h2&gt;The expert review&lt;/h2&gt;&lt;p&gt;Use this mode wisely. It&amp;#39;s not suited as your regular review type. Most people should stick to the common review. Whenever you introduce entirely new or very abstract concepts, security-related changes, or simply complex algorithms you want to have an in-depth review of your changes.&lt;/p&gt;&lt;p&gt;The involved expert reviews the code changes, carefully verifies the tests for relevance, and also runs the code locally to verify the expected results.&lt;/p&gt;&lt;h3&gt;The reviewer&amp;#39;s cost&lt;/h3&gt;&lt;p&gt;Typically the expert review costs you 30 to 90 minutes. The cognitive load is high and intense. People ideally know the in and outs of the affected code parts and they understand the business domain to put the changes into the right context for evaluation. This type of review is ideal for complex features with new architectural decisions which will influence and shape the future of the project.&lt;/p&gt;&lt;p&gt;This type of review is a great candidate to educate and influence less seasoned developers. Give them a chance to work on some complex project and provide an expert review to accompany them in delivering a future-proof change.&lt;/p&gt;&lt;h3&gt;How to conduct&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Read the PR description carefully. Lookout for specific instructions to test the changes or different scenarios.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Locate the interesting bits of changes &amp;amp; additions in the PR.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;You don&amp;#39;t have to go through every single line of code, focus on the interesting details.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Check out the code locally, verify it&amp;#39;s working locally, tinker around with the code to provoke exceptions or specific edge cases.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Make sure there are meaningful tests and try to run them locally in addition to the automated run to catch system-specific differences. Try to fail the tests by modifying the runtime code to prove the tests&amp;#39; relevance.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Probe the changes in your mind towards different scenarios and ask questions if necessary. &amp;quot;Does it work, if..&amp;quot;, &amp;quot;Will it fail when..&amp;quot;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;You are the expert. Do whatever else is required to make this PR a success.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;The expert review is an in-depth code review. You dedicate a large chunk of focus time to give the reviewee valuable feedback about the changes with details that go far beyond the common review. You can spend easily 60 or even 90 minutes on the initial code review depending on the complexity of the change. Be prepared for follow-up discussions &amp;amp; changes to review and comment on which will require your involvement.&lt;/p&gt;&lt;p&gt;You can&amp;#39;t do this often. Changes with such a high impact and complexity ultimately should happen rarely anyway.&lt;/p&gt;&lt;h3&gt;What the reviewee gets&lt;/h3&gt;&lt;p&gt;The reviewee gets an in-depth discussion of their proposed changes. For a seasoned developer this is a great way to challenge their ideas. Inexperienced developers can tackle a complex feature and work on it step-by-step together with an expert (although a synchronous review format like pair programming is usually much more efficient for this case)&lt;/p&gt;&lt;h3&gt;What the reviewee won&amp;#39;t get&lt;/h3&gt;&lt;p&gt;The expert review is the dream package for any developer as you get so many valuable insights from your expert peers. On the other side be prepared to invest high amounts of time to answer the expert reviewing your code. You will not get a fast lane to land your features in the production branch. Even if you like that format, it&amp;#39;s a rare and costly review type so you won&amp;#39;t get them for every of your PRs even if you think it&amp;#39;s a complex change.&lt;/p&gt;&lt;h1&gt;Which type is the right one for me?&lt;/h1&gt;&lt;p&gt;Most people naturally pick the &lt;b&gt;common review&lt;/b&gt; and don&amp;#39;t realize that you can have differently sized reviews. You are easily overwhelmed by the amount of time you have to spend for such a regular code review if the PRs pile up. The common review can easily take 30 minutes to complete. If you have four reviews you have to spend a quarter of your precious working day already.&lt;/p&gt;&lt;p&gt;Other folks exclude themselves from the &lt;b&gt;common review&lt;/b&gt; because they feel intimidated by their lack of knowledge, the complexity of the code changes, or the superior level of the reviewee. The &lt;b&gt;shallow review&lt;/b&gt; is an excellent instrument to encourage those people in participating in the daily code review routines and start gaining knowledge and experience. A shallow review is additionally a great tool for experienced developers. You can pick it and quickly confirm a change with the expectation that you did not dig as deep as usual.&lt;/p&gt;&lt;p&gt;Finally the &lt;b&gt;expert review&lt;/b&gt; is your instrument to ensure an &lt;b&gt;in-depth review&lt;/b&gt; of content that is pioneering a new approach or introducing security-relevant changes.&lt;/p&gt;&lt;p&gt;&lt;b&gt;The moment you understand that you have a choice when you are requested for a code review, you can distribute your time more evenly and steer away from situations that would cause you to be the bottleneck.&lt;/b&gt; Furthermore, it&amp;#39;s great to clarify expectations while conducting a review. You can tell the reviewee &amp;quot;It&amp;#39;s good, but I only did a shallow review&amp;quot; which makes it clear that the PR will deliver an acceptable change without everything being perfect in terms of architecture or code finesse — which is acceptable in most agile environments anyway.&lt;/p&gt;&lt;p&gt;Being a team, the knowledge of different code review intensities helps to prevent large backlogs of PRs and frustrated reviewees waiting for some feedback. You have a way to motivate people to take part in the review process who previously lacked the necessary confidence.&lt;/p&gt;&lt;h1&gt;Further improvements&lt;/h1&gt;&lt;p&gt;We focused solely on the reviewer and how to conduct the actual review. Being the author of a PR (reviewee), you can increase the chances to receive a review if you make your PR more accessible. Provide a clear description. Repeat parts of any given Jira ticket, make the PR small enough, if it&amp;#39;s big tell the reviewer why and where to focus on. Give clear instructions to run the code and to follow your changes.&lt;/p&gt;&lt;p&gt;This will greatly improve your chances to receive a review as you lower the effort to quickly check into your PR and you will encourage people who lack confidence or knowledge to provide their review too.&lt;/p&gt;&lt;p&gt;I&amp;#39;m planning to provide a follow-up to this blog post describing the ideal pull request which will focus on the reviewer&amp;#39;s duty.&lt;/p&gt;&lt;h1&gt;Conclusion&lt;/h1&gt;&lt;p&gt;If you want to use the described approach, you need a working code review environment where people trust each other. Shallow reviews won&amp;#39;t magically solve your toxic environment. You have to fix the foundation before optimizing your PR throughput.&lt;/p&gt;&lt;p&gt;Encourage the less experienced colleagues to start with shallow code reviews to actively take part in shaping the future of your codebase. Pick your code review type wisely though. If everyone gets lazy and provides only shallow reviews, your overall code quality might suffer, because nobody takes their time to check the important details of a code change.&lt;/p&gt;&lt;p&gt;Choose the common or even expert review too often and you will make yourself the bottleneck for the team and get stressed quickly.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[GitHub CSV Billing Dashboard]]></title><description><![CDATA[Some background information about our self-developed GitHub Billing Dashboard]]></description><link>https://satellytes.com/blog/post/github-billing-dashboard/</link><guid isPermaLink="false">https://satellytes.com/blog/post/github-billing-dashboard/</guid><pubDate>Thu, 15 Jul 2021 00:00:00 GMT</pubDate><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://satellytes.com/_gatsby/image/c165f68c6aa0221ac57538b1623269d3/4be445bf02c55418e404abd8f2a1a674/gh-billing-dashboard-cockpit.jpg?eu=ea34a73c46a61542258a94208536adf968001416d1018eaa302cb8119f02d532ebf612d5fc9b8665a436bcf18291b767d7f0169d74b2537cce38546fef82d471bf2fb45a4ec2eb89c468f52367011774709d5a90f3e64e690929140e12be72d91158368b58a95109a0aecb35cd1ea5560e427137f71ea52dd322d7a73d310e7ca4863a973ad71435bc64dc6e5fc6024c0c2d05d275bc5448c15d67e21b6d0244fb944c8023498c3457a149e6d5e8fcee9f0fb0848ef4697549fff4c81dd6be985c09ab1f7ac4d9a1845c436445507216fe2ee6e10790c2183948876d900b73a2da3132&amp;amp;a=w%3D1440%26h%3D760%26fm%3Djpg%26q%3D75&amp;amp;cd=2022-03-25T08%3A56%3A43.489Z&quot; alt=&quot;&quot;/&gt;&lt;figcaption&gt;&lt;a href=&quot;https://unsplash.com/photos/4VSsq9ErzOs&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Image by Launde Morel&lt;/a&gt;&lt;/figcaption&gt;&lt;/figure&gt; &lt;p&gt;We use CI/CD pipelines and automatizations in every project we are responsible for. Especially GitHub Actions is becoming more popular, as it’s simple to use and growing in functionality. Over the last couple of months, we managed to create multiple projects and repositories that are using GitHub Actions extensively.&lt;/p&gt;&lt;p&gt;GitHub Actions provides a generous free tier, so costs for smaller projects are often nonexistent. Once you reach the free tier limits, every Action (and other services) needs to be &amp;quot;paid by use&amp;quot; at the end of the month. GitHub aggregates all costs and shows them in your settings. But GitHub doesn&amp;#39;t provide charts or a dashboard to get into the details of the costs, for example for historical data.&lt;/p&gt;&lt;p&gt;This can be a problem if you have multiple projects, as it’s not obvious which service causes the costs. If you want to figure that out, you can get a CSV from GitHub, which is hard to read and analyze. We, therefore, decided to create a dashboard to visualize this CSV and show you the costs per repository and month.&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;You can try out the dashboard here: 
&lt;a href=&quot;https://satellytes.github.io/github-billing-dashboard&quot;&gt;https://satellytes.github.io/github-billing-dashboard&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;The following screenshot shows all the billing information you get from the GitHub Settings. No historical data, no expense per service.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;//images.ctfassets.net/54dnxp2417nl/2fWGoNW3iasH9QXkWhF9Cl/18c438ad700181d135f38042b2dec92b/gh-billing-dashboard-screenshot-of-gh-billing-settings.png&quot; alt=&quot;screenshot of the billing settings in a Github account&quot;/&gt;&lt;figcaption&gt;screenshot of the billing settings in a Github account&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;And this is what you get from the GitHub Billing Dashboard. Costs per service per month with historic data:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;//images.ctfassets.net/54dnxp2417nl/3xXVo9SyE1OQgIyKmwAr4/cf3e9cff981fb8a329dc9021297a9dfd/gh-billing-dashboard-screenshot-of-gh-dashboard.png&quot; alt=&quot;screenshot of the Github billing dashboard with some charts&quot;/&gt;&lt;figcaption&gt;screenshot of the Github billing dashboard with some charts&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;This blog post gives you some insights into how we build it.&lt;/p&gt;&lt;h2&gt;Technologies and Libraries&lt;/h2&gt;&lt;p&gt;The dashboard runs locally in the user&amp;#39;s browser and thus does not send any data to external servers, even the most recently used files are stored only in the browser&amp;#39;s local storage. The dashboard was mainly developed with React and Typescript. For the styling of the dashboard, we used styled-components. In addition, we used various libraries:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;papaparse&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;recharts&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;date-fns&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;react-medium-image-zoom&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;In the following, the main functions of these libraries are discussed with concrete examples from our project.&lt;/p&gt;&lt;h3&gt;papaparse&lt;/h3&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/mholt/PapaParse&quot;&gt;papaparse&lt;/a&gt; is a CSV parser that converts CSV to JSON. Besides strings, papaparse can process CSV files directly, whether they are located locally on the computer or accessed via an external URL.&lt;/p&gt;&lt;p&gt;The following example shows how easy the conversion of a CSV file is. The function &lt;code&gt;parse()&lt;/code&gt; is called with a file like &lt;code&gt;billing.csv&lt;/code&gt;. Additionally, it needs as a second input parameter a config object, in which certain options for the parsing can be set. For example, the headings of the individual values are camalized here. The parsing itself, the assignment of the values to the headings, and the transformation into the &lt;code&gt;UsageReportCsvEntry&lt;/code&gt; type are completely handled by papaparse. The parsed object can still be modified. In the sample code, you can see how in addition to the existing CSV file headers &lt;code&gt;totalPrice&lt;/code&gt; is calculated and added to the finished object.&lt;/p&gt;
            &lt;figure&gt;
              &lt;pre&gt;&lt;code&gt;billing.csv

Date,Product,Repository Slug,Quantity,Unit Type,Price Per Unit,Actions Workflow,Notes
2021-06-14,actions,sample-repository1,21,UBUNTU,$0.008,.github/workflows/integration-test.yml,
2021-06-14,shared storage,sample-repository2,20.1028,gb,$0.25,,
2021-06-15,actions,sample-repository3,26,UBUNTU,$0.008,.github/workflows/main.yml,
2021-06-15,actions,sample-repository2,17,UBUNTU,$0.008,.github/workflows/integration-test.yml,
&lt;/code&gt;&lt;/pre&gt;
              Github Dashboard – billing.csv
            &lt;/figure&gt;
          
            &lt;figure&gt;
              &lt;pre&gt;&lt;code class=&quot;tsx language-tsx&quot;&gt;export interface UsageReportCsvEntry {
    date: string;
    product: string;
    repositorySlug: string;
    quantity: string;
    unitType: string;
    pricePerUnit: string;
    actionsWorkflow: string;
    notes: string;
}

export interface UsageReportEntry extends UsageReportCsvEntry {
    totalPrice: number;
}

parse&amp;lt;UsageReportCsvEntry&amp;gt;(file, {
    header: true,
    skipEmptyLines: true,
    transformHeader: (header: string): string =&amp;gt; {
        return camalize(header);
    },
    complete: (result) =&amp;gt; {
            const githubBillingEntries: UsageReportEntry[] = result.data.map(
                (dailyEntry) =&amp;gt; {
                    return {
                    ...dailyEntry,
                    totalPrice: parseFloat(dailyEntry.quantity) * parseFloat(dailyEntry.pricePerUnit),
                };
            }
        );
    },
});
&lt;/code&gt;&lt;/pre&gt;
              Github Dashboard – UsageReportCsvEntry
            &lt;/figure&gt;
          &lt;h3&gt;Recharts&lt;/h3&gt;&lt;p&gt;Probably the most obvious feature of the dashboard is the functionality to display the costs in charts. For this, we used the React library &lt;a href=&quot;https://github.com/recharts/recharts&quot;&gt;Recharts&lt;/a&gt;. This library comes with some handy features that were also important for this project. Besides the possibility to choose between different chart types (e.g. Bar or Line), Recharts also leaves a lot of room for customizing the charts. This includes, for example, various stylings, additional elements (e.g. tooltip, legend, ...), and the possibility to simply add features that are not available.&lt;/p&gt;
            &lt;figure&gt;
              &lt;pre&gt;&lt;code class=&quot;tsx language-tsx&quot;&gt;&amp;lt;BarChart data={currentData} margin={{ bottom: 20 }}&amp;gt;
  &amp;lt;CartesianGrid vertical={false} stroke={&quot;rgba(255, 255, 255, 0.1)&quot;} /&amp;gt;
  &amp;lt;XAxis
    dataKey={groupedBy === &quot;daily&quot; ? &quot;day&quot; : &quot;week&quot;}
    tick={{ fill: &quot;white&quot; }}
    axisLine={false}
    tickLine={false}
    minTickGap={10}
  /&amp;gt;
  &amp;lt;YAxis
    domain={[0, maxValueOfYAxis]}
    unit=&quot; $&quot;
    tickCount={maxValueOfYAxis + 1}
    tick={{ fill: &quot;white&quot; }}
    axisLine={false}
    tickLine={false}
  /&amp;gt;
&amp;lt;/BarChart&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
              Github Dashboard – BarChart Component
            &lt;/figure&gt;
          &lt;h3&gt;date-fns&lt;/h3&gt;&lt;p&gt;For grouping costs by days, weeks and months we had to work a lot with dates. The library &lt;a href=&quot;https://github.com/date-fns/date-fns&quot;&gt;date-fns&lt;/a&gt; made this work easier for us because it brings important functions like &lt;code&gt;startOfMonth()&lt;/code&gt;, &lt;code&gt;getISOWeek()&lt;/code&gt;, or &lt;code&gt;lightFormat()&lt;/code&gt;, which allows you to customize the date format easily. For example, we used the &lt;code&gt;lightFormat()&lt;/code&gt; function to display the start or end date of the data set. Due to the detailed documentation, it was very pleasant to work with date-fns.&lt;/p&gt;
            &lt;figure&gt;
              &lt;pre&gt;&lt;code class=&quot;tsx language-tsx&quot;&gt;isFirstMonth()
    ? ` (from ${lightFormat(new Date(firstDayOfMonth), &quot;dd.MM.&quot;)})`
    : &quot;&quot;
isLastMonth()
    ? ` (till ${lightFormat(new Date(lastDayOfMonth), &quot;dd.MM.&quot;)})`
    : &quot;&quot;
&lt;/code&gt;&lt;/pre&gt;
              Github Dashboard – date-fns
            &lt;/figure&gt;
          &lt;h3&gt;react-medium-image-zoom&lt;/h3&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/rpearce/image-zoom&quot;&gt;React-medium-image-zoom&lt;/a&gt; is a small but very useful library to zoom in images that are clicked. This library also leaves many possibilities for customization, for example, the background of the zoomed image and the zoom effect can be customized very easily. For the basic function of react-medium-image-zoom it is sufficient to just wrap an image or div tag with the &lt;code&gt;&amp;lt;Zoom&amp;gt;&lt;/code&gt; tag as shown in the example below. The customization features can be added via props.&lt;/p&gt;
            &lt;figure&gt;
              &lt;pre&gt;&lt;code class=&quot;tsx language-tsx&quot;&gt;&amp;lt;Zoom&amp;gt;
    &amp;lt;img src=&quot;sample.jpg&quot;/&amp;gt;
&amp;lt;/Zoom&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
              Github Dashboard – Zoom Component
            &lt;/figure&gt;
          &lt;h3&gt;GitHub Pages deployment&lt;/h3&gt;&lt;p&gt;We chose GitHub Pages to host the page, as it&amp;#39;s a simple and free hosting solution. It was important to us that new features are deployed automatically to GitHub Pages. To automate this process, we decided to use the GitHub Actions with &lt;a href=&quot;https://github.com/JamesIves/github-pages-deploy-action&quot;&gt;GitHub Pages Deploy Action&lt;/a&gt;. This ensures that with every commit to a selected branch (in our case to &lt;code&gt;main&lt;/code&gt;), the new version is automatically deployed to the &lt;code&gt;gh-pages&lt;/code&gt; branch. Thereby all changes are immediately visible to the user and can be used directly. By using this plugin we also didn&amp;#39;t need to change any scripts or code we didn&amp;#39;t already have.&lt;/p&gt;&lt;p&gt;So, if you have a React SPA you can just copy &amp;amp; paste the GitHub Action and start deploying to GitHub pages. You only need to change the &lt;code&gt;PUBLIC_URL&lt;/code&gt; variable to your GitHub Pages deployment URL:&lt;/p&gt;
            &lt;figure&gt;
              &lt;pre&gt;&lt;code class=&quot;yaml language-yaml&quot;&gt;name: Deploy to gh-pages

on:
  push:
    branches: [main]

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout 🛎️
        uses: actions/checkout@v2.3.1

      - name: Install and Build 🔧
        run: |
          npm install
          npm run build
        env:
          PUBLIC_URL: /github-billing-dashboard

      - name: Deploy 🚀
        uses: JamesIves/github-pages-deploy-action@4.1.3
        with:
          branch: gh-pages
          folder: build
&lt;/code&gt;&lt;/pre&gt;
              Github Dashboard – Github Action
            &lt;/figure&gt;
          &lt;h2&gt;Conclusion&lt;/h2&gt;&lt;p&gt;The CSV file from GitHub provides a lot of detailed information about the incurred costs but no graphical representation. The GitHub Billing Dashboard makes it possible to present this information in a meaningful and informative way to the user. The libraries discussed here have made the development of the dashboard much easier and have resulted in the project being a lot of fun for us. Any feedback or new ideas on this project would be greatly appreciated.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[How consistency helps you to optimize Gatsby URLs for users and search engines]]></title><description><![CDATA[We did a deep dive into how to work with URLs in Gatsby to improve UX and search engine ranking.]]></description><link>https://satellytes.com/blog/post/how-consistency-helps-you-to-optimize-gatsby-urls/</link><guid isPermaLink="false">https://satellytes.com/blog/post/how-consistency-helps-you-to-optimize-gatsby-urls/</guid><pubDate>Thu, 15 Jul 2021 00:00:00 GMT</pubDate><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://satellytes.com/_gatsby/image/2b91a4f033eacd296df2565eddf63cac/4be445bf02c55418e404abd8f2a1a674/how-to-optimize-gatsby-url-hero.jpg?eu=b933f33b13f7124275d9cf77d966f8ff3203444c8c06dcaf377cba179f54d36fb5a54383ab9f8235aa63ecf7819db33edff343c970e1562b9a3a0a38ba83d621e821e75b479ead98817dfa3b2c5b187671ca4fddf2ab4b6e486b121e58a62d8e5f1f77cb4cb41356bdf39763c417f94d3c075922c73d8a3ed64089f20c59530af4907b8243cc4130b33cc13e6a935a1175535fe223bd140aeb5d1c840819672db9df48d4724fc73901e606a282a0a3fb8f00e5dccdf470251cede69b52ccafda0045ec1d608695a298554d&amp;amp;a=w%3D1440%26h%3D760%26fm%3Djpg%26q%3D75&amp;amp;cd=2022-03-25T08%3A20%3A48.001Z&quot; alt=&quot;&quot;/&gt;&lt;figcaption&gt;&lt;a href=&quot;https://unsplash.com/photos/FwMBtl6IQQA&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Image by Jonny Clow&lt;/a&gt;&lt;/figcaption&gt;&lt;/figure&gt; &lt;p&gt;We did a deep dive into how to work with URLs in Gatsby to improve UX and search engine ranking. See what we have learned and how you can improve your Gatsby site too.&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;Update February 2022: With Gatsby 4.7 an integrated handling of trailing slashes is now supported. Make sure to check the &lt;a href=&quot;https://www.gatsbyjs.com/docs/reference/release-notes/v4.7/#trailingslash-option&quot;&gt;release notes&lt;/a&gt; for more information.&lt;/p&gt;&lt;/blockquote&gt;&lt;h2&gt;The problem&lt;/h2&gt;&lt;p&gt;If you create a page in Gatsby, the page will be created as &lt;code&gt;index.html&lt;/code&gt; in a folder that has the same structure as the URL path itself. For example, our position as Senior Frontend engineer has the path &lt;code&gt;career/325420-senior-frontend-engineer-(mwx)&lt;/code&gt;, which makes Gatsby create an &lt;code&gt;index.html&lt;/code&gt; in a folder with the same name.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;//images.ctfassets.net/54dnxp2417nl/7C4fkjMdmojDqAXcVibJcx/81a4e17ea46e6c6e165ed008ae4ec850/how-to-optimize-gatsby-url-build-folder.png&quot; alt=&quot;images/how-to-optimize-gatsby-url-build-folder.png&quot;/&gt;&lt;figcaption&gt;images/how-to-optimize-gatsby-url-build-folder.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Depending on the webserver you are using, the &lt;code&gt;index.html&lt;/code&gt; file is accessible via different URLs. We are using Netlify which allows 12 different URLs:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://satellytes.com/career/325420-senior-frontend-engineer-(mwx)&quot;&gt;https://satellytes.com/career/325420-senior-frontend-engineer-(mwx)&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://satellytes.com/career/325420-senior-frontend-engineer-(mwx)/&quot;&gt;https://satellytes.com/career/325420-senior-frontend-engineer-(mwx)/&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://satellytes.com/career/325420-senior-frontend-engineer-(mwx)/index.html&quot;&gt;https://satellytes.com/career/325420-senior-frontend-engineer-(mwx)/index.html&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;all 3 links above, but starting with &lt;code&gt;https://www. &lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;all 3 links above, but starting with &lt;code&gt;http:// &lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;all 3 links above, but starting with &lt;code&gt;http://www.&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;In general, it&amp;#39;s good that all links are supported, as it lowers the possibility of a wrong URL entered by the user. But it also comes with downsides:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;We are lost in the freedom of choice and randomly pick any url format because all of them are working.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Degraded performance for the user as only one link returns the HTML file directly. All other links are redirects.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Duplicate content for search engines. A page should only have one URL (or at least one &amp;quot;original&amp;quot; URL)&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;Optimize URLs for the user&lt;/h2&gt;&lt;p&gt;If you use Netlify for hosting, only one URL delivers the actual HTML file, and that&amp;#39;s the URL with &lt;code&gt;https&lt;/code&gt;, no &lt;code&gt;www.&lt;/code&gt; and a trailing slash. All other URLs will be redirected. In the worst case, you have 3 redirects before the user will get the HTML file:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;//images.ctfassets.net/54dnxp2417nl/2hamuHLRoJkLLieYVLyWBJ/d8eeebb4c2d6a28f27688f0fd140d5fc/how-to-optimize-gatsby-url-redirect.png&quot; alt=&quot;images/how-to-optimize-gatsby-url-redirect.png&quot;/&gt;&lt;figcaption&gt;images/how-to-optimize-gatsby-url-redirect.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;307&lt;/code&gt; redirect from &lt;code&gt;http&lt;/code&gt; to &lt;code&gt;https&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;301&lt;/code&gt; redirect from &lt;code&gt;www.&lt;/code&gt; to plain URL&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;301&lt;/code&gt; redirect from missing trailing slash to &lt;code&gt;/&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;200&lt;/code&gt; with the HTML document 🎉&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;The URLs that the users are using are the ones we put on our website. That&amp;#39;s why we should make sure to always render the direct URL on our page, even if the developers or authors put in the wrong one. We did this by creating a general &lt;code&gt;Link&lt;/code&gt;component, that we use for all links we put on our side. It looks something like this:&lt;/p&gt;
            &lt;figure&gt;
              &lt;pre&gt;&lt;code class=&quot;tsx language-tsx&quot;&gt;import { Link as GatsbyLink } from &apos;gatsby&apos;;

export const Link = (props: LinkProps): JSX.Element =&amp;gt; {
  const {
    to,
    children,
    ...rest
  } = props;

  const isExternalLink = to.toString().startsWith(&apos;http&apos;);
  if (isExternalLink) {
    return (
      &amp;lt;a
        href={to}
        target=&quot;_blank&quot;
        rel=&quot;noopener&quot;
        {...rest}
      &amp;gt;
        {children}
      &amp;lt;/a&amp;gt;
    );
  }

  // here we add the traling slash for every URL we put into a link
  const toWithSlash = to.endsWith(&apos;/&apos;) ? to : `${to}/`;

  return (
    &amp;lt;GatsbyLink
      to={toWithSlash}
      {...rest}
    &amp;gt;
      {children}
    &amp;lt;/GatsbyLink&amp;gt;
  );
};
&lt;/code&gt;&lt;/pre&gt;
              &lt;figcaption&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
          &lt;blockquote&gt;&lt;p&gt;Check out the full component implementation on our public website repository: &lt;a href=&quot;https://github.com/satellytes/satellytes.com/blob/main/src/components/links/links.tsx&quot;&gt;https://github.com/satellytes/satellytes.com/blob/main/src/components/links/links.tsx&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;With this component, we get consistency into our URLs as the component makes sure that every link gets rendered with a trailing slash. The means the users don&amp;#39;t have to deal with redirects anymore - at least when they open the link in a new tab or share it to their friends, as client-side routing with &lt;code&gt;GatsbyLink&lt;/code&gt; is not affected by this. Having all URLs aligned also helps us with SEO, which we go into detail in the next paragraph.&lt;/p&gt;&lt;p&gt;The component also takes care of handling &lt;a href=&quot;https://www.gatsbyjs.com/docs/linking-between-pages/&quot;&gt;external and internal links&lt;/a&gt; in a central place, as only internal links need to be wrapped by &lt;code&gt;GatsbyLink&lt;/code&gt;.&lt;/p&gt;&lt;h2&gt;Fix URLs for search engines&lt;/h2&gt;&lt;p&gt;Now that we have consistent URLs on our website, we also want to have consistent URLs for search engines to improve our search ranking. This means we need to put the correct URLs into the &lt;code&gt;sitemap.xml&lt;/code&gt; and in the canonical header on each page.&lt;/p&gt;&lt;h3&gt;sitemap.xml&lt;/h3&gt;&lt;p&gt;A sitemap is a list of all of the pages you have on your website. Using the &lt;code&gt;[gatsby-plugin-sitemap](https://github.com/gatsbyjs/gatsby/tree/master/packages/gatsby-plugin-sitemap)&lt;/code&gt; makes it easy to generate one. The plugin iterates over all pages that were created and puts the path into the &lt;code&gt;sitemap.xml&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;After checking our &lt;code&gt;sitemap.xml&lt;/code&gt;, we figured out that some URLs in there didn&amp;#39;t have a trailing slash. Turns out: We were not using the &lt;code&gt;createPage&lt;/code&gt; consistently. The sitemap plugin takes the &lt;code&gt;path&lt;/code&gt; variable exactly as it is defined in the &lt;code&gt;createPage&lt;/code&gt; function. The fix was to check all function calls (we have them all in &lt;code&gt;gatsby-node.js&lt;/code&gt;) and make sure that a trailing slash was passed:&lt;/p&gt;
            &lt;figure&gt;
              &lt;pre&gt;&lt;code class=&quot;diff language-diff&quot;&gt;createPage({
-  path: &apos;/career&apos;,
+  path: &apos;/career/&apos;,
  component: CAREER_TEMPLATE_PATH,
  context: {
    positions: positions,
  },
});
&lt;/code&gt;&lt;/pre&gt;
              &lt;figcaption&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
          &lt;p&gt;Out sitemap URLs now match all internal links we have on our page.&lt;/p&gt;&lt;p&gt;Bonus: We use the sitemap plugin to check if all pages have a trailing slash. It&amp;#39;s probably not the very best place to do so, but also not the worst. It does its job as all URLs will pass this plugin:&lt;/p&gt;
            &lt;figure&gt;
              &lt;p&gt;&lt;code&gt;``jsx
{
  resolve:&lt;/code&gt;gatsby-plugin-sitemap`,
    options
:
  {
    resolvePagePath: ({ path }) =&amp;gt; {
      if (!path.endsWith(&apos;/&apos;)) {
        console.warn(
          &apos;Path of the page does not end with a slash! For SEO reasons all paths should end with a slash:&apos;,
          path,
        );
      }
      return path;
    },
  }
,
}
,&lt;/p&gt;
              &lt;figcaption&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
          &lt;p&gt;If there is a path without a trailing slash, you will now get a warning in the console during a build. We don&amp;#39;t add the trailing slash here, as the problem should be solved at the root - paths without a trailing slash will lead to potential follow-up problems.&lt;/p&gt;&lt;h3&gt;Canonical&lt;/h3&gt;&lt;p&gt;A canonical URL is like an ID for a page. If your page has multiple URLs for the same page, the search engine uses the canonical URL to match them together. If the document wouldn&amp;#39;t have a canonical URL, the search engine marks the content as duplicate content and lowers the search ranking.&lt;/p&gt;&lt;p&gt;To add a canonical to all our pages, we use the &lt;code&gt;[gatsby-plugin-canonical-urls](https://github.com/gatsbyjs/gatsby/tree/master/packages/gatsby-plugin-canonical-urls)&lt;/code&gt; plugin. Like the sitemap plugin, it takes the path of the page and puts it into the header. As we fixed all our paths already in the sitemap part above, the paths that are used as canonical are all correct now.&lt;/p&gt;&lt;p&gt;With the canonical URL in the header, it&amp;#39;s not a problem anymore for search engines that our pages have multiple URLs to reach them. As Netlify does a redirect for all URLs except one, this should be a problem in the first place. But depending on the webserver, this isn&amp;#39;t always the case and although the redirects are correct in our case, the Google Search Console marked some URLs as duplicated content. You can read more about this topic on the Google documentation: &lt;a href=&quot;https://developers.google.com/search/docs/advanced/guidelines/duplicate-content&quot;&gt;https://developers.google.com/search/docs/advanced/guidelines/duplicate-content&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;Conclusion&lt;/h2&gt;&lt;p&gt;The freedom of choice given by the tools we use is sometimes difficult and has implications that are not obvious. Follow these simple rules in your Gatsby application and you will create uniform links for a better SEO and UX:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;Decide for one URL format - usually, the best format is given by the webserver or hoster&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Create a common &lt;code&gt;Link&lt;/code&gt; component to ensure the URL format of internal links rendered on your website&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Align the URL format in all of your &lt;code&gt;createPage&lt;/code&gt; function calls for a correct &lt;code&gt;sitemap.xml&lt;/code&gt; and canonical URL&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Every big monorepo needs the CODEOWNERS feature]]></title><description><![CDATA[CODEOWNERS file help to split the code responsibilities & ownership in a monorepo.]]></description><link>https://satellytes.com/blog/post/monorepo-codeowner-github-enterprise/</link><guid isPermaLink="false">https://satellytes.com/blog/post/monorepo-codeowner-github-enterprise/</guid><pubDate>Fri, 09 Jul 2021 00:00:00 GMT</pubDate><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://satellytes.com/_gatsby/image/c98984f2da41d000246f945c887aa59e/4be445bf02c55418e404abd8f2a1a674/chang-duong-Sj0iMtq_Z4w-unsplash.jpg?eu=ee33a76b13a2451f268ec42c846dfdf93c50454f8d05ddac602fe84ac80ad637b6f543d2fb98873aaa36b1f48091b06b88a1469b70b5037dc3390a6aead5d07ae07fa31b0d85e3c3de67ad756457063975db5a92e2ac487b4836190f5fa776df4f5e3a8f1aee5a11e1ab891ffd48b7131e754527ee27921ad46d8fa93c5b622eefd120df3adb4667b46dc63f6e965918240355b529e8440ae85c1e845c17362aba941c8a27148f7c0ae444b88aa09fe1cb00c5c1c6ce07760ab4e0975891b6c91f00aa12628e&amp;amp;a=w%3D1440%26h%3D760%26fm%3Djpg%26q%3D75&amp;amp;cd=2022-03-24T14%3A00%3A18.626Z&quot; alt=&quot;&quot;/&gt;&lt;figcaption&gt;&lt;a href=&quot;https://unsplash.com/photos/Sj0iMtq_Z4w&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Image by Chang Duong&lt;/a&gt;&lt;/figcaption&gt;&lt;/figure&gt; &lt;p&gt;Monorepos are en vogue these days for good reasons. It&amp;#39;s also a heated debate, but I want to spare you that discussion for now. Once you have decided to go for monorepos with your team and collaborators, you might want to know about the CODEOWNERS feature of your favorite version control services (being mostly &lt;a href=&quot;https://docs.github.com/en/github/creating-cloning-and-archiving-repositories/creating-a-repository-on-github/about-code-owners&quot;&gt;GitHub.com&lt;/a&gt;, &lt;a href=&quot;https://docs.github.com/en/enterprise-server@3.1/github/creating-cloning-and-archiving-repositories/creating-a-repository-on-github/about-code-owners&quot;&gt;GitHub Enterprise&lt;/a&gt; or &lt;a href=&quot;https://docs.gitlab.com/ee/user/project/code_owners.html&quot;&gt;GitLab&lt;/a&gt;).&lt;/p&gt;&lt;p&gt;I&amp;#39;m speaking with my experience coming from a GitHub Enterprise environment, but the features are either identical (GitHub.com) or very similar (GitLab).&lt;/p&gt;&lt;h2&gt;How to use (place &amp;amp; syntax)&lt;/h2&gt;&lt;p&gt;You place a file named &lt;code&gt;CODEOWNERS&lt;/code&gt; in one of the places where your other &amp;quot;metafiles&amp;quot; are usually placed being the repository root, &lt;code&gt;.github&lt;/code&gt; or &lt;code&gt;docs/&lt;/code&gt;. You use the file to describe who owns a specific part in your repository, and that code ownership knowledge will be used to automatically assign the responsible individual or team for a pull request you open.&lt;/p&gt;&lt;p&gt;Here a carefully crafted example file showing a list of files and folders and their matching owners on the right side.&lt;/p&gt;
            &lt;figure&gt;
              &lt;pre&gt;&lt;code class=&quot;bash language-bash&quot;&gt;# EXAMPLE FILE
# Some comment to clarify
# the content of this file
# this is a constructed example leaning towards reality only

# MONO REPOSITORY OWNER
# everything that is not specified is owned by a specific team
*                            @my-namespace/mono-repo-owner

# FRONTEND TEAM
/apps/                        @my-namespace/frontend-team
/apps/angular-libraries        @my-namespace/collbaorators-angular
/apps/react-website            @my-namespace/collbaorators-react

# BACKEND FOLKS
/server/                    @my-namespace/frontend-team
/docker/                    @my-namespace/frontend-team

# DEV OPS
# That single file belongs to the dev ops folks
Jenkinsfile                    @my-namespace/dev-ops

# PACKAGE MAINTAINERS
# And the root package.json, one of the most crucial parts in a monorepo
# belongs to a specific cross-cutting team to review any changes
package.json                @my-namespace/package-maintainers

# some individual assignments
/experimental/john/            john@example.com
/experimental/jane/            @external-jane
&lt;/code&gt;&lt;/pre&gt;
              &lt;figcaption&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
          &lt;p&gt;There are only ownership statements and the comments.&lt;/p&gt;&lt;p&gt;The ownership is expressed as the combination of a files glob pattern (think of your &lt;code&gt;.gitignore&lt;/code&gt; file) and the owner being a defined GitHub team (&lt;code&gt;@my-namespace/frontend-team&lt;/code&gt;) or an individual user identified by email (&lt;code&gt;john@example.com&lt;/code&gt;) or username (&lt;code&gt;@external-jane&lt;/code&gt;). Comments are introduced with a starting hash sign (&lt;code&gt;#&lt;/code&gt;). If you need to know all details please read the &lt;a href=&quot;https://docs.github.com/en/github/creating-cloning-and-archiving-repositories/creating-a-repository-on-github/about-code-owners&quot;&gt;manual&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;You can&amp;#39;t make many mistakes, but I want to share two things that happened to me.&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;Before introducing it, I tried it in a private repo in the GitHub Enterprise environment, and it didn&amp;#39;t work. I guessed I made some basic syntax errors in the file and tinkered around for quite some time. In the end, I recognized that my private repo wasn&amp;#39;t accessible by any of the assigned teams. This means GitHub and its CODEOWNER algorithm could not assign the required people and teams &lt;b&gt;while their UI did not tell me about that fact&lt;/b&gt;.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Be careful with paths. I wanted to assign &lt;code&gt;docs&lt;/code&gt; and all nested files and folders in the repository&amp;#39;s root to a team. Is it &lt;code&gt;docs&lt;/code&gt;, &lt;code&gt;docs/*&lt;/code&gt;,&lt;code&gt;/docs/&lt;/code&gt; or &lt;code&gt;docs/**/*&lt;/code&gt; assuming glob-like support? Nothing worked, and GitHub UI never showed any indications of a problem. The problem was combined with the first problem outlined here. Long story short, if you want to match any file in the root folder named &lt;code&gt;docs&lt;/code&gt;, your correct matcher is &lt;code&gt;/docs/&lt;/code&gt; and nothing else. Read the manual not to waste time like me.&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;The effect&lt;/h2&gt;&lt;p&gt;You don&amp;#39;t have to add reviewers manually anymore. Instead, you leave the assignment of reviewers empty. You will get the matching code owners assigned and notified once you have the PR created. Unfortunately, there is no preview for the assignment or indication in the UI that this will happen. You need to have explicit contribution guidelines so people won&amp;#39;t continue to assign people manually.&lt;/p&gt;&lt;p&gt;We combine this with the requirements to have at least a specific amount of code reviews to ensure that the code owners review every change to their share of files. This is important for monorepos; otherwise, some team members could change the code of an area they are not suitable for by a mutual review within the team without informing the actually responsible team.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Show actual ownership in the diff&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Assign reviewers&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Display which individual acted for which team&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;Conclusion&lt;/h2&gt;&lt;p&gt;That&amp;#39;s it. The file doesn&amp;#39;t do anything besides this. While this sounds very simple, the knowledge and the favorable implications of this feature, especially for monorepos, are not evident. Once you know it, you won&amp;#39;t ever miss it again but reaching that point is pure luck of having the right peers telling you about that or stumbling over this feature on some other place because it&amp;#39;s not common knowledge.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Going beyond the Abstract Syntax Tree (AST) with the TypeScript Type Checker]]></title><description><![CDATA[How to analyze a typescript file beyond the Abstract Syntax Tree (AST) with the TS type checking utility "checker.ts"]]></description><link>https://satellytes.com/blog/post/typescript-ast-type-checker/</link><guid isPermaLink="false">https://satellytes.com/blog/post/typescript-ast-type-checker/</guid><pubDate>Fri, 18 Jun 2021 00:00:00 GMT</pubDate><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://satellytes.com/_gatsby/image/326c27ab8b8bd8c84e5f7b281c7f2ff8/4be445bf02c55418e404abd8f2a1a674/johann-siemens-EPy0gBJzzZU-unsplash.jpg?eu=ba60f53316a54317738ac322d763f9fd6853121e8705dafd357eec169c508430e7f51581a298db36f964eafb859fb23eddf013cc20e0582acd3f033bb8d5d621ef25e00a48c2ebdbc63ff8203754162e779d0ec0a2e81f370220410c18b977884a0826cc1fea5b44baf09e61ce1fb44f0f552f34bc5ef03f9a64cdb6396d0167ef812f866f86562cb17c953c7f840854344b09e664a51708ed0356c6591b632be5d750d73537da633da11a9f88cf8de1a200e9d4f2e03b1128b6f6cd1c83efcc080db54170dbd8aed103496e414b2f40be7eb7b655d49f026c1fcb6c8f0a66e2de6c26d61edd8a0bbb1b6c13f4a5a7f4b18dc04f758dcd78b06d502d63f8c3fcef8f&amp;amp;a=w%3D1440%26h%3D760%26fm%3Djpg%26q%3D75&amp;amp;cd=2022-03-24T10%3A16%3A17.018Z&quot; alt=&quot;&quot;/&gt;&lt;figcaption&gt;&lt;a href=&quot;https://unsplash.com/photos/EPy0gBJzzZU&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Image by Johann Siemens&lt;/a&gt;&lt;/figcaption&gt;&lt;/figure&gt; &lt;p&gt;We currently develop a &lt;a href=&quot;https://en.wikipedia.org/wiki/Low-code_development_platform&quot;&gt;low-code platform&lt;/a&gt; for an enterprise client where Angular components are arranged and connected based on a given configuration file. The components define data contracts based on &lt;a href=&quot;https://www.typescriptlang.org/docs/handbook/2/generics.html&quot;&gt;generics&lt;/a&gt; so the platform always knows what data can flow between them. In order to perform the actual type check we use a json file that already contains all relevant typing information. We collect the typing data by recursively resolving typescript types down to their primitives and then store the found property names along with their typing name. This post is about how to collect the typing information and why we need to go beyond the AST to achieve this.&lt;/p&gt;&lt;p&gt;You can find the repository on &lt;a href=&quot;https://github.com/georgiee/typescript-type-checker-beyond-ast&quot;&gt;github.com/georgiee/typescript-type-checker-beyond-ast&lt;/a&gt; and you can directly run the given example in your browser with &lt;a href=&quot;https://githubbox.com/georgiee/typescript-type-checker-beyond-ast&quot;&gt;code sandbox&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;Expectations&lt;/h2&gt;&lt;p&gt;Look at the two types below. You can find primitives like &lt;code&gt;string&lt;/code&gt; and &lt;code&gt;number&lt;/code&gt;, types from the standard library such as &lt;code&gt;Date&lt;/code&gt; and type aliases like &lt;code&gt;NestedObjectType&lt;/code&gt; that refers to object types which are assembled types that can contain primitives and other object types.&lt;/p&gt;
            &lt;figure&gt;
              &lt;pre&gt;&lt;code class=&quot;typescript language-typescript&quot;&gt;// we will start our inspection here
type MainObjectType = {
  propertyWithTypeAlias: NestedObjectType;
};

type NestedObjectType = {
  value1: string;
  value2: number;
  value3: Date;
};
&lt;/code&gt;&lt;/pre&gt;
              &lt;figcaption&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
          &lt;p&gt;The ideal output we want to get for the above content is a list of property names and type names separated by a colon, including the hierarchy to visualize where a property belongs to.&lt;/p&gt;
            &lt;figure&gt;
              &lt;pre&gt;&lt;code&gt;MainObjectType:
  propertyWithTypeAlias: NestedObjectType
        value1: string
        value2: number
        value3: Date
&lt;/code&gt;&lt;/pre&gt;
              &lt;figcaption&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
          &lt;p&gt;Those are our rules for the processing:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://www.typescriptlang.org/docs/handbook/2/everyday-types.html#type-aliases&quot;&gt;Type aliases&lt;/a&gt; such as &lt;code&gt;propertyWithTypeAlias: NestedObjectType&lt;/code&gt; need to be resolved into the types that are referred to. This can be other type aliases or primitives.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Primitives itself can&amp;#39;t be processed anymore and should be output as is, such as &lt;code&gt;value1: string&lt;/code&gt; and &lt;code&gt;value2: number&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;We have no interest in type details from the &lt;a href=&quot;https://github.com/microsoft/TypeScript/tree/5afe42e14e61d7e4df5d75cc0022283711cb593a/lib&quot;&gt;standard library&lt;/a&gt; such as &lt;code&gt;value3: Date&lt;/code&gt; or even &lt;code&gt;value1: string&lt;/code&gt; with the &lt;code&gt;length&lt;/code&gt; property. They potentially bring dozens of properties we don&amp;#39;t want to see in our output list.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Let&amp;#39;s find out how we can approach this problem.&lt;/p&gt;&lt;h2&gt;Can we use the AST?&lt;/h2&gt;&lt;p&gt;The &lt;a href=&quot;https://en.wikipedia.org/wiki/Abstract_syntax_tree&quot;&gt;AST (Abstract Syntax Tree)&lt;/a&gt; quickly comes to your mind to approach this problem. The AST is a data structure to represent the structure of your source file in a format readable by machines. Indeed, if I throw the above example in the &lt;a href=&quot;https://ts-ast-viewer.com/&quot;&gt;TypeScript AST Viewer&lt;/a&gt; I get immediate access to the AST.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;//images.ctfassets.net/54dnxp2417nl/7g44rteNhvQy2RIOO7JhWR/38eb92c035b6bc69cc7eba8d33ef7469/ts-ast-viewer.png&quot; alt=&quot;&quot;/&gt;&lt;figcaption&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;That output looks promising. I guess this could work for very simple types 👍&lt;/p&gt;&lt;p&gt;The problem with the AST: it&amp;#39;s a static analysis, which means you&amp;#39;re processing code without executing it. That&amp;#39;s why you are missing information from the runtime. Typescript needs to run the code to understand it and to add additional semantics. You will encounter the following problems when you try to approach the problem with the AST:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt; The AST can&amp;#39;t see imported files, as &lt;code&gt;import&lt;/code&gt; statements are not processed&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://www.typescriptlang.org/docs/handbook/2/types-from-types.html&quot;&gt;Created types&lt;/a&gt; with operands like &lt;code&gt;keyof&lt;/code&gt; &amp;amp; &lt;code&gt;typeof&lt;/code&gt; are constructed only during runtime&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://www.typescriptlang.org/docs/handbook/2/narrowing.html&quot;&gt;Narrowing (type guards)&lt;/a&gt; or &lt;a href=&quot;https://www.typescriptlang.org/docs/handbook/2/conditional-types.html&quot;&gt;conditional types&lt;/a&gt; rely on being processed by typescript otherwise you have no chance to understand and process them&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Eventually, the AST approach is a dead end.&lt;/p&gt;&lt;h2&gt;Walking beyond the AST&lt;/h2&gt;&lt;p&gt;There must be another solution 🤔 Your favourite IDE does this type of processing all day, for instance when you are presented a list of inspections or completions for a given type. See the screenshot below, where I hovered over a type &lt;code&gt;NestedObjectType&lt;/code&gt; in IntelliJ. IntelliJ somehow knows the details of that type, which is exactly what we want to achieve here.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;//images.ctfassets.net/54dnxp2417nl/2b7rmZNCdGjeg8COpVQX78/658e12721ffa9b8843227082792793cd/type-check-intellij.png&quot; alt=&quot;&quot;/&gt;&lt;figcaption&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;That&amp;#39;s a feature we take for granted from any IDE for any language it supports. How does the IDEs do this? Do they develop some magic analysis for every language they are going to support? There must be some tool to support the IDE given by the maintainers of the languages, in our case from the makers of TypeScript.&lt;/p&gt;&lt;h3&gt;Language Services &amp;amp; Checker&lt;/h3&gt;&lt;p&gt;I researched the topic for a few exciting hours and found something important for my cause.&lt;/p&gt;&lt;p&gt;Your favourite IDE can support Typescript because TypeScript offers the &lt;a href=&quot;https://github.com/Microsoft/TypeScript/wiki/Standalone-Server-%28tsserver%29&quot;&gt;tsserver&lt;/a&gt; which is a node executable that encapsulates the TypeScript compiler and language services.&lt;/p&gt;&lt;p&gt;Have you ever restarted an ominous Typescript Server in IntelliJ or VSCode from time to time while debugging typing or tsconfig issues with typescript? That server is based on &lt;code&gt;tsserver&lt;/code&gt; and offers optimized code completion support based on some technique we want to use to solve our problem.&lt;/p&gt;&lt;p&gt;&lt;code&gt;tsserver&lt;/code&gt; is as the name says a server though it is not suited to process single files. If you look careful through the &lt;a href=&quot;https://github.com/microsoft/TypeScript/wiki/Architectural-Overview&quot;&gt;typescript architecture overview&lt;/a&gt; you will notice a &lt;code&gt;checker.ts&lt;/code&gt; at the foundation of the diagram — the core of typescript.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;//images.ctfassets.net/54dnxp2417nl/3UJoi5g7De7FmVNV7D8uHg/db709420731d0b3e2d15203b7026a86d/typescript-architecture.png&quot; alt=&quot;&quot;/&gt;&lt;figcaption&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/microsoft/TypeScript/blob/5afe42e14e61d7e4df5d75cc0022283711cb593a/src/compiler/checker.ts&quot;&gt;checker.ts&lt;/a&gt; is a huge file in the typescript repository. Right now there are 42.000 lines of code, and it has a size of 2.5 MB 😳 This is probably the amount of code you would have to write atop of AST to properly process a given TypeScript file with the typings in its full glory.&lt;/p&gt;&lt;p&gt;I&amp;#39;m glad we finally found this magic ingredient, let&amp;#39;s explore it.&lt;/p&gt;&lt;h3&gt;The Type Checker (checker.ts)&lt;/h3&gt;&lt;p&gt;Let&amp;#39;s dive into the type checker and see how it can help us with the given challenge. Unfortunately I couldn&amp;#39;t find any documentation about the type checker which made it pretty difficult to get started. I mostly searched GitHub for some code examples, glimpsed through the file &lt;code&gt;checker.ts&lt;/code&gt; itself and used the node &lt;code&gt;debugger&lt;/code&gt; a lot to examine the content of the involved data.&lt;/p&gt;&lt;p&gt;The following code shows the most crucial parts of type introspection with TS. Create a program, derive the checker and then use that checker for your analysis.&lt;/p&gt;
            &lt;figure&gt;
              &lt;pre&gt;&lt;code class=&quot;typescript language-typescript&quot;&gt;const program: ts.Program = ts.createProgram(files, tsConfig);
const checker: ts.TypeChecker = program.getTypeChecker();

// Later involve the checker somehow 
const classSymbol = checker.getSymbolAtLocation(node.name);
// ...
&lt;/code&gt;&lt;/pre&gt;
              &lt;figcaption&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
          &lt;h2&gt;Type Checker Usage&lt;/h2&gt;&lt;p&gt;Getting the checker setup is pretty straightforward, but as usually it gets complicated with all the details. Let&amp;#39;s tackle it step by step. We start by preparing a file &lt;code&gt;file-with-types.ts&lt;/code&gt; that should contain the types we want to examine.&lt;/p&gt;
            &lt;figure&gt;
              &lt;pre&gt;&lt;code class=&quot;typescript language-typescript&quot;&gt;// file-with-types.ts

type MainObjectType = {
  propertyWithTypeAlias: NestedObjectType;
};

type NestedObjectType = {
  value1: string;
  value2: number;
  value3: Date;
};
&lt;/code&gt;&lt;/pre&gt;
              &lt;figcaption&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
          &lt;p&gt;Together with this file, we want to answer the following question:&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;Using &lt;code&gt;checker.ts&lt;/code&gt;, how can we access the details of the type &lt;code&gt;NestedObjectType &lt;/code&gt;so we know that the property &lt;code&gt;propertyWithTypeAlias &lt;/code&gt;on &lt;code&gt;MainObjectType&lt;/code&gt; has three distinctive nested properties?&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;First step is to create our type checker and retrieve the source file with &lt;code&gt;program.getSourceFile&lt;/code&gt; which returns an instance of  &lt;code&gt;ts.SourceFile&lt;/code&gt;.&lt;/p&gt;
            &lt;figure&gt;
              &lt;pre&gt;&lt;code class=&quot;typescript language-typescript&quot;&gt;import * as ts from &quot;typescript&quot;;

const files: string[] = [&apos;file-with-types.ts&apos;]
const program: ts.Program = ts.createProgram(files, {});
const checker: ts.TypeChecker = program.getTypeChecker();

const mySourceFile: ts.SourceFile = program.getSourceFile(&apos;file-with-types.ts&apos;);
&lt;/code&gt;&lt;/pre&gt;
              &lt;figcaption&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
          &lt;p&gt;With our source file at hands we can dive into the file content. We have to use the AST first to reach the specific parts in the file and to tell the type checker about the parts we are interested in. When you invoke &lt;code&gt;ts.forEachChild((node: ts.Node) =&amp;gt; {/*...*/})&lt;/code&gt; you create a loop over all nodes (&lt;code&gt;ts.Node&lt;/code&gt;) of your AST. Each node represents a specific position in the file together with all statically available information about that place (is it a &lt;code&gt;variable&lt;/code&gt;, a &lt;code&gt;bracket&lt;/code&gt;, where is the start, where the end; this is pretty common AST stuff).&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;👉 You should tinker around with &lt;a href=&quot;https://ts-ast-viewer.com/&quot;&gt;ts-ast-viewer.com&lt;/a&gt; to get a better feeling for the AST structure&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;We want to start our type analysis at the type named &lt;code&gt;MainObjectType&lt;/code&gt;. We can accomplish this by looking for the AST node named &lt;code&gt;MainObjectType&lt;/code&gt; while looping over of all nodes in the file.&lt;/p&gt;
            &lt;figure&gt;
              &lt;pre&gt;&lt;code class=&quot;typescript language-typescript&quot;&gt;ts.forEachChild(mySourceFile, node =&amp;gt; {
  if (ts.isTypeAliasDeclaration(node) &amp;amp;&amp;amp; node.name.escapedText === &quot;MainObjectType&quot;) {
    // [...process that type]
  }
});
&lt;/code&gt;&lt;/pre&gt;
              &lt;figcaption&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
          &lt;p&gt;&lt;code&gt;node&lt;/code&gt; has the type &lt;code&gt;ts.Node&lt;/code&gt; which doesn&amp;#39;t have the property &lt;code&gt;node.name&lt;/code&gt;. Instead you can check for the inherited type &lt;code&gt;TypeAliasDeclaration&lt;/code&gt; with the method &lt;code&gt;ts.isTypeAliasDeclaration(node)&lt;/code&gt;. This will type guard accessing &lt;code&gt;node.name&lt;/code&gt; so typescript won&amp;#39;t throw a typing error for &lt;code&gt;node.name&lt;/code&gt; as you ensure the correct content.&lt;/p&gt;&lt;p&gt;By finding that AST node we have found the exact place in the source file to ask the type checker for more information. We can do this with the method &lt;code&gt;checker.getTypeAtLocation(node)&lt;/code&gt;. We pass in the node and in return we get an instance of &lt;code&gt;ts.Type&lt;/code&gt; from the checker. This is a specific object that contains added semantics, which we need to go beyond the AST.&lt;/p&gt;
            &lt;figure&gt;
              &lt;pre&gt;&lt;code class=&quot;typescript language-typescript&quot;&gt;// Don&apos;t get confused, the `name` is not a string but an object with many more information
// That&apos;s why this works even for things that are named the same
const mainObjectType = checker.getTypeAtLocation(node.name);
&lt;/code&gt;&lt;/pre&gt;
              &lt;figcaption&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
          &lt;p&gt;This is it, we arrive in type checking land 🌈&lt;/p&gt;&lt;h2&gt;Analyzing the properties&lt;/h2&gt;&lt;p&gt;We can access every property of the given type through &lt;code&gt;mainObjectType.getProperties()&lt;/code&gt; and then find the name of the property as well as the name of the type.&lt;/p&gt;
            &lt;figure&gt;
              &lt;pre&gt;&lt;code class=&quot;typescript language-typescript&quot;&gt;const [propertyWithTypeAlias] = mainObjectType.getProperties();
/**
 * `propertyType` will contain &amp;amp; reference everything
 * we can know about the type `NestedObjectType`
 */
const propertyType = checker.getTypeOfSymbolAtLocation(propertyWithTypeAlias, node);
const propertyTypeName = checker.typeToString(propertyType);
&lt;/code&gt;&lt;/pre&gt;
              &lt;figcaption&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
          &lt;p&gt;Remember we are currently processing the first level:&lt;/p&gt;
            &lt;figure&gt;
              &lt;pre&gt;&lt;code class=&quot;typescript language-typescript&quot;&gt;type MainObjectType = {
  propertyWithTypeAlias: NestedObjectType;
};
&lt;/code&gt;&lt;/pre&gt;
              &lt;figcaption&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
          &lt;p&gt;On that level we only have one property &lt;code&gt;propertyWithTypeAlias: NestedObjectType&lt;/code&gt; in our original type definition, so we can save us one loop and simply extract the first element and name it &lt;code&gt;propertyWithTypeAlias&lt;/code&gt;. The value has the type &lt;code&gt;ts.Symbol&lt;/code&gt; which is similar to &lt;code&gt;ts.Type&lt;/code&gt;, a value with added semantics compared to the AST-related &lt;code&gt;ts.Node&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;We can use the symbol, to access the name of the variable and the actual name of the type. The type checker gives us the methods &lt;code&gt;getTypeOfSymbolAtLocation&lt;/code&gt; and &lt;code&gt;typeToString&lt;/code&gt; to do that, and we can print the final result to the console.&lt;/p&gt;
            &lt;figure&gt;
              &lt;pre&gt;&lt;code class=&quot;typescript language-typescript&quot;&gt;// prints `propertyWithTypeAlias: NestedObjectType`
console.log(`${propertyWithTypeAlias.name}: ${propertyTypeName}`)
&lt;/code&gt;&lt;/pre&gt;
              &lt;figcaption&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
          &lt;p&gt;What&amp;#39;s left is to dive one level deeper to finally extract the types from the nested &lt;code&gt;propertyWithTypeAlias: NestedObjectType&lt;/code&gt;. This is basically &amp;quot;rinse &amp;amp; repeat&amp;quot; as you will see in the following code example. Instead of extracting the first element we use a for-loop though in order to find all properties.&lt;/p&gt;
            &lt;figure&gt;
              &lt;pre&gt;&lt;code class=&quot;typescript language-typescript&quot;&gt;// remember we are now processing `ImportantValue` which is stored in `propertyType`
for (const nestedProperty of propertyType.getProperties()) {
  const nestedPropertyType = checker.getTypeOfSymbolAtLocation(nestedProperty, node);
  const nestedPropertyTypeName = checker.typeToString(nestedPropertyType);
  /** prints the following
   ├── value1: string
   ├── value2: number
   ├── value3: Date
   */
  console.log(`     ├── ${nestedProperty.name}: ${nestedPropertyTypeName}`)
}
&lt;/code&gt;&lt;/pre&gt;
              &lt;figcaption&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
          &lt;details&gt;&lt;summary&gt;Full Example&lt;/summary&gt;&lt;/details&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;Real-world adjustments&lt;/h2&gt;&lt;p&gt;The basic demonstration was specifically crafted to focus on the type extraction process. There are some important real-world issues left to tackle:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;We don&amp;#39;t know the depth of our analysis, so it&amp;#39;s a perfect match for recursion although you could construct a loop too I guess.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;We need to prevent diving into properties that are coming from the standard library like &lt;code&gt;Date&lt;/code&gt; and methods or values of primitives like &lt;code&gt;string&lt;/code&gt; because we are usually not interested in those properties. Same for external libraries (think of rxjs &amp;amp; friends)&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;Recursion&lt;/h3&gt;&lt;p&gt;First, let&amp;#39;s make the analysis recursive to find every property in any given file.&lt;/p&gt;
            &lt;figure&gt;
              &lt;pre&gt;&lt;code class=&quot;typescript language-typescript&quot;&gt;function processProperty(type: ts.Type, node: ts.Node, level = 0) {
  if(level === 0) {
    console.group(`.\n└──Processing &apos;${checker.typeToString(type)}&apos;`)
  }

  for (const property of type.getProperties()) {
    const propertyType = checker.getTypeOfSymbolAtLocation(property, node);
    const propertyTypeName = checker.typeToString(propertyType);

    processProperty(propertyType, node, level + 1)
    console.log(`  ├── ${property.name}: ${propertyTypeName}`)

  }
  console.groupEnd();

}

ts.forEachChild(myComponentSourceFile, node =&amp;gt; {
  if (ts.isTypeAliasDeclaration(node) &amp;amp;&amp;amp; node.name.escapedText === &quot;MainObjectType&quot;) {
    const mainObjectType = checker.getTypeAtLocation(node.name);
    processProperty(mainObjectType, node);
  }
});
&lt;/code&gt;&lt;/pre&gt;
              &lt;figcaption&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
          &lt;p&gt;This will find every single property, no matter how deep it&amp;#39;s nested. That&amp;#39;s because &lt;code&gt;processProperty()&lt;/code&gt; is used recursively on all nested properties.&lt;/p&gt;&lt;p&gt;When you run this code, you will be lost in noise. See the log below and try to spot our types (marked with &lt;code&gt;👉&lt;/code&gt;) within the ocean of properties pouring in from the standard library.&lt;/p&gt;&lt;details&gt;&lt;summary&gt;Output with the noise of the standard library&lt;/summary&gt;&lt;/details&gt;&lt;p&gt;That&amp;#39;s the &amp;quot;standard library&amp;quot; issue described earlier. The &lt;code&gt;Date&lt;/code&gt; and &lt;code&gt;string&lt;/code&gt; types causes this drama, and we need to stop our processing before entering those types.&lt;/p&gt;&lt;h3&gt;Exclude the standard types&lt;/h3&gt;&lt;p&gt;TypeScript gives us plenty of tools to do that. Here is a helper method &lt;code&gt;isTypeLocal&lt;/code&gt; I have built for our use cases.&lt;/p&gt;
            &lt;figure&gt;
              &lt;pre&gt;&lt;code class=&quot;typescript language-typescript&quot;&gt;function isTypeLocal(symbol: ts.Symbol) {
  const sourceFile = symbol?.valueDeclaration?.getSourceFile();
  const hasSource = !!sourceFile;
  const isStandardLibrary = hasSource &amp;amp;&amp;amp; program.isSourceFileDefaultLibrary(sourceFile!)
  const isExternal = hasSource &amp;amp;&amp;amp; program.isSourceFileFromExternalLibrary(sourceFile!);
  const hasDeclaration = !!symbol?.declarations?.[0];

  return !(isStandardLibrary || isExternal) &amp;amp;&amp;amp; hasDeclaration;
}
&lt;/code&gt;&lt;/pre&gt;
              &lt;figcaption&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
          &lt;p&gt;The method will detect if a given symbol belongs to a &lt;a href=&quot;https://www.typescriptlang.org/tsconfig#lib&quot;&gt;standard library&lt;/a&gt; (&lt;code&gt;Date&lt;/code&gt;), to an external library (whatever you use from &lt;code&gt;node_modules&lt;/code&gt;) and everything that doesn&amp;#39;t have an actual declaration like primitive types (&lt;code&gt;string&lt;/code&gt;, &lt;code&gt;number&lt;/code&gt;).&lt;/p&gt;&lt;p&gt;We will use that helper to prevent our recursion from branching into those unwanted types:&lt;/p&gt;
            &lt;figure&gt;
              &lt;pre&gt;&lt;code class=&quot;typescript language-typescript&quot;&gt;if(isTypeLocal(propertySymbol)) {
  // It&apos;s a type we have defined, so print it
  // and then process its nested properties
  console.group(`  └── ${property.name}: ${propertyTypeName}`)
  processProperty(propertyType, node, level + 1)
}else {
  // It&apos;s not a local type, so print it but don&apos;t do anything further
  console.log(`  ├── ${property.name}: ${propertyTypeName}`)
}
&lt;/code&gt;&lt;/pre&gt;
              &lt;figcaption&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
          &lt;p&gt;The updated code can process the initial file, but it&amp;#39;s much more flexible. Let&amp;#39;s process a much deeper nested type &lt;code&gt;MainObjectType&lt;/code&gt; and watch the console.&lt;/p&gt;&lt;details&gt;&lt;summary&gt;Updated file `file-with-types.ts`&lt;/summary&gt;&lt;/details&gt;&lt;p&gt;The following values are printed for the given file. Every standard library type is skipped, but the values are probably traversed and listed with the correct name and type name.&lt;/p&gt;
            &lt;figure&gt;
              &lt;pre&gt;&lt;code&gt;.
└──Processing &apos;MainObjectType&apos;
    ├── value1: string
    ├── value2: number
    ├── value3: Date
    └── propertyWithTypeAlias: NestedObjectType
      ├── value1: string
      ├── value2: number
      ├── value3: Date
      └── value4: SomethingElse
        └── value2: PrettyNestedType
          ├── value1: string
          ├── value2: number
          ├── value3: Date
&lt;/code&gt;&lt;/pre&gt;
              &lt;figcaption&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
          &lt;p&gt;Task completed ✅&lt;/p&gt;&lt;details&gt;&lt;summary&gt;Full Source Example&lt;/summary&gt;&lt;/details&gt;&lt;h2&gt;Conclusion&lt;/h2&gt;&lt;p&gt;Interacting with the type checker is similarly difficult as interacting with the AST. That&amp;#39;s because you usually don&amp;#39;t have a complete visual representation in your mind what data is given to you by typescript, which makes this task super hard.&lt;/p&gt;&lt;p&gt;Don&amp;#39;t let you fool from this blog post, to this day I still rely on &lt;code&gt;debugger&lt;/code&gt; and &lt;code&gt;console.log&lt;/code&gt; to find my way through solving a specific challenge with the type checker. After a while you experience kicks in, and you will be more fluent handling &lt;code&gt;ts.Symbol&lt;/code&gt;, &lt;code&gt;ts.Type&lt;/code&gt; or &lt;code&gt;ts.Node&lt;/code&gt;. Then it&amp;#39;s more and more fun to interact with your own written code from such a refreshing and exciting perspective ✨&lt;/p&gt;</content:encoded></item><item><title><![CDATA[The "Inject the Injector" pattern]]></title><description><![CDATA[A coding pattern to prevent breaking changes when dealing with injections in base classes used in distributed libraries]]></description><link>https://satellytes.com/blog/post/angular-inject-the-injector/</link><guid isPermaLink="false">https://satellytes.com/blog/post/angular-inject-the-injector/</guid><pubDate>Tue, 08 Jun 2021 00:00:00 GMT</pubDate><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://satellytes.com/_gatsby/image/8a84701d54f60c261e2b420470d7593f/4be445bf02c55418e404abd8f2a1a674/georgios-kaleadis-aBTfTMsOCOI-unsplash.jpg?eu=ea32a86c11a3101373dc962cd460a9ab6f03151e865581a93229eb43c950dd37b6a24383a3958233ac33eca3809db13a8ca615cb27e351719939003deb858a77ea27b40a1ec3e088c536a42734564724269e069be5ab5d7c0137580346e9248e581e218b4ebb1855eab3d57ac41ea25758027338fc1df26d913bd7ae662d573896ac14ad4cb7125be56b970b7994391974092dac72ba1a0ebb5e4a855a4a667fe8dd4cd07719dc305ef319efd8ebfab2cb0bbc8d98f6382d0ffefc9658ccb1c9000de51c7b9a96a9aa644c5e6f0e5934c20fa9fb0891d6593b548c288a1260&amp;amp;a=w%3D1440%26h%3D760%26fm%3Djpg%26q%3D75&amp;amp;cd=2022-03-18T09%3A15%3A30.023Z&quot; alt=&quot;&quot;/&gt;&lt;figcaption&gt;&lt;a href=&quot;https://unsplash.com/photos/aBTfTMsOCOI&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Image by Georgios Kaleadis&lt;/a&gt;&lt;/figcaption&gt;&lt;/figure&gt; &lt;p&gt;We maintain a successful proprietary enterprise library based on Angular. One challenge while doing so is how to deal with breaking changes. Those occur naturally while we improve and extend the library. There was one particular type of breaking change that caused us some trouble, and we want to show you how we tackled it for good.&lt;/p&gt;&lt;h2&gt;In a nutshell&lt;/h2&gt;&lt;p&gt;We have discovered a pattern specific to Angular&amp;#39;s dependency injection system in combination with subclasses. The pattern makes our &lt;code&gt;constructor&lt;/code&gt; signature more generic and by doing so, it prevents future breaking changes on subclasses, as we change our constructor signature less often. This pattern is used in our enterprise project since Angular version 10, so we consider it safe for production.
&lt;/p&gt;&lt;p&gt;&lt;b&gt;The pattern&lt;/b&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;Replace your injected content (being a service, token etc.) with the injector itself and manually retrieve the singleton instance through &lt;code&gt;injector.get(TOKEN)&lt;/code&gt;. That way, your constructor signature is more stable which will prevent breaking changes on your subclasses.&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;b&gt;Example&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Instead of injecting the services through the constructor we inject the Injectorand derive the actual instances in the body of the constructor. &lt;/p&gt;
            &lt;figure&gt;
              &lt;pre&gt;&lt;code class=&quot;typescript language-typescript&quot;&gt;import { Directive, Inject, Injector } from &apos;@angular/core&apos;;

@Directive()
export class MyAbstractBaseComponent implements OnInit {
  private mySubscribeService: MySubscribeService;
  private myTrackingService: MyTrackingService;
  public myRemoteHomeService: MyRemoteHomeService;

  constructor(@Inject(Injector) injector: Injector) {
    this.mySubscribeService = injector.get&amp;lt;AclService&amp;gt;(MySubscribeService)!;
    this.myTrackingService = injector.get&amp;lt;AclService&amp;gt;(MyTrackingService)!;
    this.myRemoteHomeService =  injector.get&amp;lt;AclService&amp;gt;(MyRemoteHomeService)!;
  }
}
&lt;/code&gt;&lt;/pre&gt;
              &lt;figcaption&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
          &lt;p&gt;Every subclass can safely extend from &lt;code&gt;MyAbstractBaseComponent&lt;/code&gt; and define additional services. The base class itself can add additional injected services without ever breaking the subclass. We literally inject every possible value by providing the injector itself which acts as the bucket for any future service we might want to access. That generalization is the core of this pattern.   
&lt;/p&gt;
            &lt;figure&gt;
              &lt;pre&gt;&lt;code class=&quot;typescript language-typescript&quot;&gt;@Component({
  selector: &apos;my-selector&apos;,
  template: `...`
})
export class UnsubscribeToolComponent extends MyAbstractBaseComponent {
  constructor(
    @Inject(Injector) injector: Injector,
    @Inject(MyService) myService: MyService
  ) {
    super(injector)
  }
}
&lt;/code&gt;&lt;/pre&gt;
              &lt;figcaption&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
          &lt;h2&gt;Our starting point&lt;/h2&gt;&lt;p&gt;In order to understand the problem we will look at the following Angular base class that acts as the functional foundation for derived concrete components.&lt;/p&gt;
            &lt;figure&gt;
              &lt;pre&gt;&lt;code class=&quot;typescript language-typescript&quot;&gt;@Directive()
export class MyAbstractBaseComponent implements OnInit {
  constructor(
    @Inject(MySubscribeService) private mySubscribeService: MySubscribeService,
    @Inject(MyTrackingService) private  myTrackingService: MyTrackingService
  ) { }

  ngOnInit(){
    this.myTrackingService.trigger();
  }

  subscribe() {
    this.mySubscribeService.doSomething();
  }
}
&lt;/code&gt;&lt;/pre&gt;
              &lt;figcaption&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
          &lt;p&gt;That base class provides default functionality for any other component extending from it in the future. This not only saves repeated work on the side of the component authors, but also acts as an alignment &amp;amp; contract between all derived components.&lt;/p&gt;&lt;p&gt;The &lt;code&gt;MyAbstractBaseComponent&lt;/code&gt; will be delivered through a core library and extended by dozens of other components like the following imaginary subscription component:&lt;/p&gt;
            &lt;figure&gt;
              &lt;pre&gt;&lt;code class=&quot;typescript language-typescript&quot;&gt;@Component({
  selector: &apos;my-subscription&apos;,
  template: `&amp;lt;button (click)=&quot;subscribe()&quot;&amp;gt;subscribe now&amp;lt;/button&amp;gt;`
})
export class SubscriptionComponent extends MyAbstractBaseComponent {
}
&lt;/code&gt;&lt;/pre&gt;
              &lt;figcaption&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
          &lt;p&gt;The &lt;code&gt;SubscriptionComponent&lt;/code&gt; is guaranteed to invoke the one service through &lt;code&gt;ngOnInit&lt;/code&gt; as described by the parent class plus it can access the &lt;code&gt;subscribe&lt;/code&gt; method from the parent class as the service &lt;code&gt;mySubscribeService&lt;/code&gt; is readily available to be invoked by &lt;code&gt;subscribe()&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;Things get complicated the moment library authors implement slightly more advanced use cases, like in the following component.&lt;/p&gt;
            &lt;figure&gt;
              &lt;pre&gt;&lt;code class=&quot;typescript language-typescript&quot;&gt;@Component({
  selector: &apos;my-unsubscribe-tool&apos;,
  template: `&amp;lt;button (click)=&quot;unsubscribe()&quot;&amp;gt;unsubscribe&amp;lt;/button&amp;gt;`
})
export class UnsubscribeToolComponent extends MyAbstractBaseComponent {
  constructor(
    @Inject(MySubscribeService) mySubscribeService: MySubscribeService,
    @Inject(MyTrackingService)  myTrackingService: MyTrackingService,
    @Inject(MyUnsubscribeService) private myUnsubscribeService: MyUnsubscribeService
  ) {
    super(mySubscribeService, myTrackingService)
  }

  unsubscribe() {
    this.myUnsubscribeService.trigger();
  }
}
&lt;/code&gt;&lt;/pre&gt;
              &lt;figcaption&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
          &lt;p&gt;The class &lt;code&gt;UnsubscribeToolComponent&lt;/code&gt; is in desperate need to access a custom service &lt;code&gt;MyUnsubscribeService&lt;/code&gt; whose functionality is not provided by the base class. Fair enough, they chose to inject that service. The injection itself looks complicated though, because the author needs to repeat the injection to forward the two service instances &lt;code&gt;mySubscribeService&lt;/code&gt; &amp;amp; &lt;code&gt;myTrackingService&lt;/code&gt; to the parent class.&lt;/p&gt;&lt;p&gt;Besides, the solution works pretty well. Great.&lt;/p&gt;&lt;h2&gt;The problem&lt;/h2&gt;&lt;p&gt;The core team decides to extend the functionality of the base class. They want to ship a new service &lt;code&gt;MyRemoteHomeService&lt;/code&gt; to all subclasses and offer a new method &lt;code&gt;lightsOff&lt;/code&gt; ready to be used. This is adding some new feature and shouldn&amp;#39;t cause much trouble, should it?&lt;/p&gt;&lt;p&gt;Let&amp;#39;s look at the base class again and its added functionality in the following diff.&lt;/p&gt;
            &lt;figure&gt;
              &lt;pre&gt;&lt;code class=&quot;diff-typescript language-diff-typescript&quot;&gt;@Directive()
export class MyAbstractBaseComponent implements OnInit {
  constructor(
    @Inject(MySubscribeService) private mySubscribeService: MySubscribeService,
    @Inject(MyTrackingService) private  myTrackingService: MyTrackingService,
+   @Inject(MyRemoteHomeService) public  myRemoteHomeService: MyRemoteHomeService
  ) { }

   /* [... redacted methods] */

+  lightsOff() {
+    this.myRemoteHomeService.lightsOff();
+  }
}
&lt;/code&gt;&lt;/pre&gt;
              &lt;figcaption&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
          &lt;p&gt;You can clearly see the appearance of &lt;code&gt;MyRemoteHomeService&lt;/code&gt; and the method &lt;code&gt;lightsOff()&lt;/code&gt; using it.&lt;/p&gt;&lt;p&gt;The team decides not to mark it as a &lt;code&gt;BREAKING CHANGE&lt;/code&gt;, because, well it can&amp;#39;t break anything because it &lt;b&gt;adds &lt;/b&gt;functionality. They will ship it as version &lt;code&gt;V1.1&lt;/code&gt;. Soon after the release the maintainers of the advanced component &lt;code&gt;UnsubscribeToolComponent&lt;/code&gt; complain that their component fails to compile.&lt;/p&gt;&lt;p&gt;The reason gets obvious pretty quickly. The local team didn&amp;#39;t know about the service added by the core team. On the other side they rely on repeating the constructor signature in order to provide all expected dependencies.&lt;/p&gt;&lt;p&gt;The team&amp;#39;s fix is simple, but it came by surprise and it created a lot of confusion.&lt;/p&gt;
            &lt;figure&gt;
              &lt;pre&gt;&lt;code class=&quot;diff-typescript language-diff-typescript&quot;&gt;@Component({
  selector: &apos;my-unsubscribe-tool&apos;,
  template: `&amp;lt;button (click)=&quot;unsubscribe()&quot;&amp;gt;unsubscribe&amp;lt;/button&amp;gt;`
})
export class UnsubscribeToolComponent extends MyAbstractBaseComponent {
  constructor(
    @Inject(MySubscribeService) mySubscribeService: MySubscribeService,
    @Inject(MyTrackingService)  myTrackingService: MyTrackingService,
+   @Inject(MyRemoteHomeService) public  myRemoteHomeService: MyRemoteHomeService,
    @Inject(MyUnsubscribeService) myUnsubscribeService: MyUnsubscribeService
  ) {
+    super(mySubscribeService, myTrackingService, myRemoteHomeService)
  }

  unsubscribe() {
    this.myUnsubscribeService.trigger();
  }
}
&lt;/code&gt;&lt;/pre&gt;
              &lt;figcaption&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
          &lt;p&gt;What did they do? They had to repeat the injection of &lt;code&gt;MyUnsubscribeService&lt;/code&gt; to forward the instance through the &lt;code&gt;super()&lt;/code&gt; invocation.&lt;/p&gt;&lt;p&gt;The core team created a breaking change by adding an innocent new feature because they did not recognize that slightly more advanced users of their library are overriding the constructor. The team could stop here, because they are now aware of the problem and the next change of the constructor will be marked as a breaking change.&lt;/p&gt;&lt;p&gt;This will still create trouble for the local team, because they would have to update their components for every upstream change in the constructor. Luckily there is a solution.&lt;/p&gt;&lt;h2&gt;The solution&lt;/h2&gt;&lt;p&gt;We have gone through this various times in different places. We announced the breaking change carefully, we even wrote migrations to automatically fix or at least warn the user about the problem. It remained a cumbersome experience, so we pursued another solution: &lt;b&gt;Inject the Injector&lt;/b&gt;.&lt;/p&gt;&lt;p&gt;Let&amp;#39;s start with the solution:&lt;/p&gt;
            &lt;figure&gt;
              &lt;pre&gt;&lt;code class=&quot;typescript language-typescript&quot;&gt;import { Directive, Inject, Injector } from &apos;@angular/core&apos;;

@Directive()
export class MyAbstractBaseComponent implements OnInit {
  private mySubscribeService: MySubscribeService;
  private myTrackingService: MyTrackingService;
  public myRemoteHomeService: MyRemoteHomeService;

  constructor(@Inject(Injector) injector: Injector) {
    this.mySubscribeService = injector.get&amp;lt;AclService&amp;gt;(MySubscribeService)!;
    this.myTrackingService = injector.get&amp;lt;AclService&amp;gt;(MyTrackingService)!;
    this.myRemoteHomeService =  injector.get&amp;lt;AclService&amp;gt;(MyRemoteHomeService)!;
  }
}
&lt;/code&gt;&lt;/pre&gt;
              &lt;figcaption&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
          &lt;p&gt;Can you see the elegance here? We inject the injector, which is the engine of the dependency injection (DI) system in Angular itself and then request the singleton instances of our desired services to assign them to the local variables as before.&lt;/p&gt;&lt;p&gt;We need to use the &lt;a href=&quot;https://www.typescriptlang.org/docs/handbook/release-notes/typescript-2-0.html#non-null-assertion-operator&quot;&gt;non-null assertion operator (!)&lt;/a&gt; to tell TypeScript that we guarantee to receive a value, because the typing of the injector correctly states that the result might be undefined. That&amp;#39;s possible because we control the environment, and the services are guaranteed to be available as they are provided in the root (&lt;code&gt;@Injectable({providedIn: &amp;#39;root&amp;#39; })&lt;/code&gt;).&lt;/p&gt;&lt;p&gt;In case we decide to add a fourth or fifth service in the base class, we can now add it and request it directly from the injector without breaking any subclass as the constructor signature stays the same. See how many lines of random services, in which the feature teams are not even interested in, can now be replaced:&lt;/p&gt;
            &lt;figure&gt;
              &lt;pre&gt;&lt;code class=&quot;diff-typescript language-diff-typescript&quot;&gt;@Component({
  selector: &apos;my-unsubscribe-tool&apos;,
  template: `&amp;lt;button (click)=&quot;unsubscribe()&quot;&amp;gt;unsubscribe&amp;lt;/button&amp;gt;`
})
export class UnsubscribeToolComponent extends MyAbstractBaseComponent {
  constructor(
    @Inject(Injector) injector: Injector
-   @Inject(MySubscribeService) mySubscribeService: MySubscribeService,
-   @Inject(MyTrackingService)  myTrackingService: MyTrackingService,
-   @Inject(MyRemoteHomeService) public  myRemoteHomeService: MyRemoteHomeService,
    @Inject(MyUnsubscribeService) myUnsubscribeService: MyUnsubscribeService
  ) {
-    super(mySubscribeService, myTrackingService, myRemoteHomeService)
+    super(injector)
  }

  unsubscribe() {
    this.myUnsubscribeService.trigger();
  }
}
&lt;/code&gt;&lt;/pre&gt;
              &lt;figcaption&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
          &lt;p&gt;The result is a much more compact version of the original constructor.&lt;/p&gt;
            &lt;figure&gt;
              &lt;pre&gt;&lt;code class=&quot;typescript language-typescript&quot;&gt;@Component(/*...*/)
export class UnsubscribeToolComponent extends MyAbstractBaseComponent {
  constructor(
    @Inject(Injector) injector: Injector,
    @Inject(MyUnsubscribeService) myUnsubscribeService: MyUnsubscribeService
  ) {
    super(injector)
  }

  /*...*/
}
&lt;/code&gt;&lt;/pre&gt;
              &lt;figcaption&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
          &lt;h2&gt;Conclusion&lt;/h2&gt;&lt;p&gt;Handling breaking changes is an act of empathy 💛. You want to protect your users from struggling with your changes. The &amp;quot;inject the injector&amp;quot; pattern we have introduced here helped us a lot and made it very easy to extend our base class without breaking things.&lt;/p&gt;&lt;p&gt;Introducing a pattern like this might not be necessary or even beneficial if you are not working with a large codebase and distributed teams in a typical enterprise organization. Never use this pattern only to save a few lines of code, you will make your code less understandable.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Angular Advanced Workshop (2018)]]></title><description><![CDATA[Our Open Source 3-day Angular Advanced Workshop we conducted for KaiserX (Allianz).]]></description><link>https://satellytes.com/blog/post/angular-workshop-kaiserx-allianz-2018/</link><guid isPermaLink="false">https://satellytes.com/blog/post/angular-workshop-kaiserx-allianz-2018/</guid><pubDate>Sat, 01 Dec 2018 00:00:00 GMT</pubDate><content:encoded>&lt;img src=&quot;https://satellytes.com/_gatsby/image/09378e003d8635891470fb5059c0b3be/049e3d39284577572c92b7db90eb3e09/angular.png?eu=ed64a93b14f1121626db922c836df9ac6955491dd65189fb6b29bf469e02d661eba246d3ac98d662ff31eef28b9ae6688dfd169826e8042bce3d576fe8dfd025ef25e25a4d93b8d49538f47566024c7124ce0f97f5be1d6d5d2c125b4feb7bdc18057bc612b21f52ffb49c7b8512bb190a536478e719a638d37fdcb63a30552db4c777d36c8d5d72e03cc26a629b427212282cf253dd5046ef3540dd2e5f3179e9f03ed0691ed8695ba71de58bb5febe9f5dead7d3a2387549fcf3cb4ed2b9cb5450b64027c6daa68f45466b50536619ea&amp;amp;a=w%3D1440%26h%3D760%26fm%3Dpng%26q%3D75&amp;amp;cd=2022-03-24T09%3A40%3A55.314Z&quot; alt=&quot;&quot;/&gt; &lt;p&gt;This is about the technical project of our 3-day Angular Advanced Workshop we gave for KaiserX (Allianz) to teach advanced topics of Angular v7 in a unique &amp;amp; playful way by implementing a card game called Skip-Bo. The workshop covered the six chapters, Modules, Components, Routing, RxJS, Testing &amp;amp; Animations, split into theory &amp;amp; challenges.&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;Note (2021): The concepts are still very valid, even though the version Angular v7 is outdated today.&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;This week an intense month of planning, preparing &amp;amp; developing an Advanced Angular Workshop ended with the workshop itself. Over three days, 15 developers listened to six chapters, each with a theory and a challenge. Every theory part (~1h) is accompanied by a challenge (~2h ) to implement a full card game application. I chose &lt;a href=&quot;https://en.wikipedia.org/wiki/Skip-Bo&quot;&gt;Skip-Bo&lt;/a&gt; as it&amp;#39;s a well-known game, and the rules are easy to grasp.&lt;/p&gt;&lt;p&gt;The workshop was a huge success. I&amp;#39;m so &lt;b&gt;proud&lt;/b&gt; of every single participant. They were so focused during my theory part and successfully completed all six chapters 💪 I can tell you those challenges were pretty tricky. I planted nifty bugs to fix. There were RxJS streams to create and animations to build.&lt;/p&gt;&lt;h2&gt;Try it&lt;/h2&gt;&lt;p&gt;You can play with the final project online under &lt;a href=&quot;https://skipbo-angular-workshop.netlify.com/&quot;&gt;skipbo-angular-workshop.netlify.com&lt;/a&gt; and access the complete source &amp;amp; challenges under &lt;a href=&quot;https://github.com/georgiee/angular-workshop-skipbo&quot;&gt;github.com/georgiee/angular-workshop-skipbo&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Below a gif preview. Additionally, I have prepared a &lt;a href=&quot;https://www.youtube.com/embed/xKlta_T3qgs&quot;&gt;short video&lt;/a&gt; of the gameplay part on YouTube.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;//images.ctfassets.net/54dnxp2417nl/n04S7QJ0tyml9rqXUaVw5/1f068461a4353ecd6fdbf111a3896a8f/preview-angular-skipbo.gif&quot; alt=&quot;&quot;/&gt;&lt;figcaption&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;It&amp;#39;s Open Source 🎉&lt;/h2&gt;&lt;p&gt;The workshop is Open Source, because we don&amp;#39;t want to lock away valuable information — it&amp;#39;s about teaching Angular to the community.&lt;/p&gt;&lt;p&gt;We decided to put the workshop on &lt;a href=&quot;https://github.com/georgiee/angular-workshop-skipbo&quot;&gt;GitHub&lt;/a&gt; and make it Open Source. That way, many more people can go through the workshop on their own. Other fellow developers can even take the workshop and create their own ones too!&lt;/p&gt;&lt;p&gt;We hope you enjoy it.&lt;/p&gt;&lt;h2&gt;Workshop Content&lt;/h2&gt;&lt;p&gt;Please check the linked &lt;a href=&quot;https://github.com/georgiee/angular-workshop-skipbo&quot;&gt;GitHub project&lt;/a&gt; for all details. I will only give a brief summary of the content.&lt;/p&gt;&lt;p&gt;The &lt;a href=&quot;https://github.com/georgiee/angular-workshop-skipbo&quot;&gt;workshop project&lt;/a&gt; gives you access to all six chapters (theory &amp;amp; challenge). Here the &lt;a href=&quot;https://www.slideshare.net/GeorgiosKaleadis/angular-advanced-workshop-challenges&quot;&gt;slides&lt;/a&gt; from the workshop.&lt;/p&gt;&lt;p&gt;Inside the project, you will find a git submodule &lt;code&gt;skipbo-angular&lt;/code&gt; — that&amp;#39;s the actual Angular project. This project includes around 50 branches in the following structure.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;workshop/04-rxjs-start&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;workshop/04-rxjs-progress-01&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;workshop/04-rxjs-progress-02&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;workshop/04-rxjs-progress-03&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;workshop/04-rxjs-end&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;workshop/05-testing-start&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;...&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Those branches help struggling participants to quickly catch up. In addition, by creating mandatory branches to check out, I can fast-forward to specific milestones (chapters) without leaving people behind.&lt;/p&gt;&lt;p&gt;The following content lists the chapter introductions for the participants, so you can feel how we proceeded through the workshop.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;Chapter I - Modules&lt;/h3&gt;&lt;p&gt;We start slowly with a recap of what Modules are and their special role in Angular. The Injection System is tightly bound to the module world, so it&amp;#39;s a good moment to revise them in this chapter.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/georgiee/angular-workshop-skipbo/blob/master/docs/theory/01-modules.md&quot;&gt;Theory&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/georgiee/angular-workshop-skipbo/blob/master/docs/challenges/01-modules.md&quot;&gt;Challenge&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://5c01159cf6d5ea7fb5133562--skipbo-angular-workshop.netlify.com/&quot;&gt;Preview&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;Theory&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Providers&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Declarations&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Imports/Exports&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;EntryComponents&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Bootstrap&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Schema&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;Challenge&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Create our GameService&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Provide expected interface (TDD)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Inject the GameService&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Break the Injection and fix it&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Answer a quick question&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;Chapter II: Components&lt;/h3&gt;&lt;p&gt;Learn about Directive vs. Components, things you can do in templates, ChangeDetection, and the difference between presentational and smart components. In the challenge, we will create our first components and fix a component bug.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/georgiee/angular-workshop-skipbo/blob/master/docs/theory/02-components.md&quot;&gt;Theory&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/georgiee/angular-workshop-skipbo/blob/master/docs/challenges/02-components.md&quot;&gt;Challenge&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://5c0115b29a063f180bf0dcf5--skipbo-angular-workshop.netlify.com/&quot;&gt;Preview&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;Theory&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Introduction&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;preserveWhitespaces&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Selectors on existing elements&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;View Encapsulation&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Smart &amp;amp; Dumb Components&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;OnPush&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Template References&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;Challenge&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Create Components&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Use Gameplay Component&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Use CardPile Component&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Fix Bug in the CardPile&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Inject parent component&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;Chapter III: Routing&lt;/h3&gt;&lt;p&gt;We will get serious by providing a bunch of new pages like the rulebook, welcome and game over page. In the challenge, you will map routes, introduce lazy loading and routing guards.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/georgiee/angular-workshop-skipbo/blob/master/docs/theory/03-routing.md&quot;&gt;Theory&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/georgiee/angular-workshop-skipbo/blob/master/docs/challenges/03-routing.md&quot;&gt;Challenge&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://5c01469405c41743336caefd--skipbo-angular-workshop.netlify.com/&quot;&gt;Preview&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;Theory&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Router Outlet&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Lazy Load&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Manual Loading a Module&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Guards&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Resolver&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;Challenge&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Route to the new pages&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Make GameModule lazy load&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Routing Guards: CanActivate&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Routing Guards: CanDeactivate with prompt&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;Chapter IV: RxJS&lt;/h3&gt;&lt;p&gt;Learn the difference between cold &amp;amp; hot, some important rxjs operators and how to test. In the challenge, we will build Oscar 🐙 a card playing AI with the power of RxJS.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/georgiee/angular-workshop-skipbo/blob/master/docs/theory/04-rxjs.md&quot;&gt;Theory&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/georgiee/angular-workshop-skipbo/blob/master/docs/challenges/04-rxjs.md&quot;&gt;Challenge&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://5c03b6c1e5cd161924fc7252--skipbo-angular-workshop.netlify.com/welcome&quot;&gt;Preview&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;Theory&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Introduction&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Debugging&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;About Dollar Signs&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Cold vs Hot Observables&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Make Cold Observables Hot&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;RxJS in the wild&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Testing&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;Challenge&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Redirect to the Gameover Page&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;AI 🐙 Autoplay V1&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;AI 🐙 Autoplay V2&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;AI 🐙 Autoplay V3&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Stop the AI after game is over&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;Chapter V: Testing&lt;/h3&gt;&lt;p&gt;This is all about testing. How to enable headless browsers, use hosting/wrapper components and learn important details of the change detection system and how it impacts your testing (tick, fakeSync, micro, macro tasks). In the challenge we will fix a nasty component bug and test Oscar&amp;#39;s 🐙 async rxjs stream.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/georgiee/angular-workshop-skipbo/blob/master/docs/theory/05-testing.md&quot;&gt;Theory&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/georgiee/angular-workshop-skipbo/blob/master/docs/challenges/05-testing.md&quot;&gt;Challenge&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://5c0115fa9a063f180bf0dd48--skipbo-angular-workshop.netlify.com/welcome&quot;&gt;Preview&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;Theory&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Setup&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Component Testing&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Micro &amp;amp; Macro Tasks (Theory)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Testing Async Code&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Change Detection&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Testing Routing&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;Challenge&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Stock Bug (Investigate) 🐛&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Stock Bug — Part 1, 2, 3&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Test RxJS w/ Oscar 🐙 — CPUs&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Test RxJS w/ Oscar 🐙 — Humans&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Can Oscar play multiple cards ?&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;Chapter VI: Animation&lt;/h3&gt;&lt;p&gt;Learn about animations in Angular, how to apply and control them. In the challenge, we will flip some cards 🙌&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/georgiee/angular-workshop-skipbo/blob/master/docs/theory/06-animation.md&quot;&gt;Theory&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/georgiee/angular-workshop-skipbo/blob/master/docs/challenges/06-animation.md&quot;&gt;Challenge&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://5c0115fa9a063f180bf0dd48--skipbo-angular-workshop.netlify.com/welcome&quot;&gt;Preview&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;Theory&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Animation Basics&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Appear &amp;amp; Disappear&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Numeric Triggers&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Disable&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Router Animations&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Animate Children&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;Challenge&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;First Flip - Part 1 &amp;amp; 2&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Flip Party&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Flip with Style&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Make the Hand Cards flip&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Animate Stock Flip&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;Conclusion&lt;/h2&gt;&lt;p&gt;Preparing a new workshop is time-consuming, especially if you want to craft a unique and challenging experience beyond the typical tutorials. After endless hours of preparations, we were able to deliver and fulfill the expectations. We did not repeat the workshop since then, as we focused on our project-based business, but we are happy to talk about any future possibility if you would like to enjoy a similar experience.&lt;/p&gt;</content:encoded></item></channel></rss>